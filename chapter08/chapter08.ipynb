{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第8章: ニューラルネット"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第7章で取り組んだポジネガ分類を題材として、ニューラルネットワークで分類モデルを実装する。なお、この章ではPyTorchやTensorFlow、JAXなどの深層学習フレームワークを活用せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最初の5単語:\n",
      "<PAD>, ベクトル: [0. 0. 0. 0. 0.]...\n",
      "discovered, ベクトル: [-0.07910156  0.15917969 -0.01464844  0.05859375 -0.05395508]...\n",
      "mermaid, ベクトル: [ 0.17675781 -0.06054688 -0.140625    0.02819824 -0.15429688]...\n",
      "anonymous, ベクトル: [ 0.1796875   0.12011719 -0.14550781 -0.33203125 -0.12597656]...\n",
      "fairies, ベクトル: [ 0.2734375   0.04980469 -0.10791016  0.16308594 -0.21386719]...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "70. 単語埋め込みの読み込み\n",
    "事前学習済み単語埋め込みを活用し、|V| * d_{emb} の単語埋め込み行列 E を作成せよ。\n",
    "ここで、d_{emb} は単語埋め込みの語彙数、|V|は単語埋め込みの次元数である。\n",
    "ただし、単語埋め込み行列の先頭の行ベクトルE_{0}は、将来的にパディング（<PAD>）トークンの埋め込みベクトルとして用いたいので、ゼロベクトルとして予約せよ。\n",
    "ゆえに、E の2行目以降に事前学習済み単語埋め込みを読み込むことになる。\n",
    "\n",
    "もし、Google Newsデータセットの学習済み単語ベクトル（300万単語・フレーズ、300次元）を全て読み込んだ場合、\n",
    "|V| = 3000001,d_{emb} = 300になるはずである（ただ、300万単語の中には、殆ど用いられない稀な単語も含まれるので、語彙を削減した方がメモリの節約になる）。\n",
    "\n",
    "また、単語埋め込み行列の構築と同時に、単語埋め込み行列の各行のインデックス番号（トークンID）と、単語（トークン）への双方向の対応付けを保持せよ。\n",
    "\n",
    "\"\"\"\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def\textract_vocab(data):\n",
    "    all_words = set()\n",
    "    for sentence in data['sentence']:\n",
    "        words = sentence.split()\n",
    "        all_words.update(word.lower() for word in words)\n",
    "    return all_words\n",
    "\n",
    "def create_matrix(model_path, train_data, dev_data):\n",
    "    train_words = extract_vocab(train_data)\n",
    "    dev_words = extract_vocab(dev_data)\n",
    "    all_words = train_words.union(dev_words)\n",
    "\n",
    "    word2vec = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "    embedding_dim = word2vec.vector_size\n",
    "\n",
    "    embedding_matrix = [np.zeros(embedding_dim)]\n",
    "    word_to_id = {\"<PAD>\": 0}\n",
    "    id_to_word = {0: \"<PAD>\"}\n",
    "\n",
    "    idx = 1\n",
    "    for word in all_words:\n",
    "        if word in word2vec:\n",
    "            embedding_matrix.append(word2vec[word])\n",
    "            word_to_id[word] = idx\n",
    "            id_to_word[idx] = word\n",
    "            idx += 1\n",
    "\n",
    "    embedding_matrix = np.array(embedding_matrix)\n",
    "\n",
    "    return embedding_matrix, word_to_id, id_to_word\n",
    "\n",
    "sst2_train = pd.read_csv('SST-2/train.tsv', sep='\\t')\n",
    "sst2_dev = pd.read_csv('SST-2/dev.tsv', sep='\\t')\n",
    "file = 'data/GoogleNews-vectors-negative300.bin.gz'\n",
    "embedding_matrix, word_to_id, id_to_word = create_matrix(file, sst2_train, sst2_dev)\n",
    "print(\"\\n最初の5単語:\")\n",
    "for i in range(5):\n",
    "    print(f\"{id_to_word[i]}, ベクトル: {embedding_matrix[i][:5]}...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([9071, 4483,  407, 9085, 7860, 1760, 4795]),\n",
      " 'label': tensor([0.]),\n",
      " 'text': 'hide new secretions from the parental units '}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "71. データセットの読み込み\n",
    "General Language Understanding Evaluation (GLUE) ベンチマークで配布されているStanford Sentiment Treebank (SST) をダウンロードし、\n",
    "訓練セット（train.tsv）と開発セット（dev.tsv）のテキストと極性ラベルと読み込み、全てのテキストをトークンID列に変換せよ。\n",
    "\n",
    "このとき、単語埋め込みの語彙でカバーされていない単語は無視し、トークン列に含めないことにせよ。\n",
    "また、テキストの全トークンが単語埋め込みの語彙に含まれておらず、空のトークン列となってしまう事例は、訓練セットおよび開発セットから削除せよ\n",
    "（このため、第7章の実験で得られた正解率と比較できなくなることに注意せよ）。\n",
    "\n",
    "事例の表現方法は任意でよいが、例えば”contains no wit , only labored gags”がネガティブに分類される事例は、次のような辞書オブジェクトで表現すればよい。\n",
    "\n",
    "{'text': 'contains no wit , only labored gags',\n",
    " 'label': tensor([0.]),\n",
    " 'input_ids': tensor([ 3475,    87, 15888,    90, 27695, 42637])}\n",
    "この例では、textはテキスト、labelは分類ラベル（ポジティブならtensor([1.])、ネガティブならtensor([0.])）、input_idsはテキストのトークン列をID列で表現している。\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "train_df = pd.read_csv(\"SST-2/train.tsv\", sep=\"\\t\")\n",
    "dev_df = pd.read_csv(\"SST-2/dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "def text_to_ids(df, word_to_id):\n",
    "    dct_lst = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sentence = row[\"sentence\"]\n",
    "        label = torch.tensor([float(row[\"label\"])])\n",
    "\n",
    "        words = sentence.split()\n",
    "        ids = torch.tensor([word_to_id[token.lower()] for token in words if token in word_to_id])\n",
    "        \n",
    "        if len(ids) != 0 :\n",
    "            dct_lst.append({'text':sentence,\n",
    "                'label':label,\n",
    "                'input_ids': ids\n",
    "            })\n",
    "        \n",
    "    return dct_lst\n",
    "\n",
    "train_ids_list  = text_to_ids(train_df, word_to_id)\n",
    "dev_ids_list = text_to_ids(dev_df, word_to_id)\n",
    "pprint(train_ids_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "72. Bag of wordsモデルの構築\n",
    "単語埋め込みの平均ベクトルでテキストの特徴ベクトルを表現し、重みベクトルとの内積でポジティブ及びネガティブを分類する\n",
    "ニューラルネットワーク（ロジスティック回帰モデル）を設計せよ。\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, embedding_matrix, vec_dim, output_dim, freeze=True):\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_weights = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_weights, freeze=freeze)\n",
    "\n",
    "        self.linear = nn.Linear(vec_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_ids_list):\n",
    "        batch_vectors = []\n",
    "        \n",
    "        for input_ids in input_ids_list:\n",
    "            emb = self.embedding(input_ids)\n",
    "            avg_vec = torch.mean(emb, dim=0)\n",
    "            batch_vectors.append(avg_vec)\n",
    "\n",
    "        batch_tensor = torch.stack(batch_vectors)\n",
    "        out = torch.sigmoid(self.linear(batch_tensor))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 1 / 1000 epoch ===================\n",
      "Train  loss: 0.6948, acc: 0.48\n",
      "Valid  loss: 0.6934, acc: 0.50\n",
      "=================== 2 / 1000 epoch ===================\n",
      "Train  loss: 0.6935, acc: 0.50\n",
      "Valid  loss: 0.6929, acc: 0.53\n",
      "=================== 3 / 1000 epoch ===================\n",
      "Train  loss: 0.6922, acc: 0.53\n",
      "Valid  loss: 0.6924, acc: 0.54\n",
      "=================== 4 / 1000 epoch ===================\n",
      "Train  loss: 0.6910, acc: 0.55\n",
      "Valid  loss: 0.6919, acc: 0.54\n",
      "=================== 5 / 1000 epoch ===================\n",
      "Train  loss: 0.6897, acc: 0.57\n",
      "Valid  loss: 0.6914, acc: 0.54\n",
      "=================== 6 / 1000 epoch ===================\n",
      "Train  loss: 0.6885, acc: 0.58\n",
      "Valid  loss: 0.6910, acc: 0.54\n",
      "=================== 7 / 1000 epoch ===================\n",
      "Train  loss: 0.6873, acc: 0.58\n",
      "Valid  loss: 0.6905, acc: 0.54\n",
      "=================== 8 / 1000 epoch ===================\n",
      "Train  loss: 0.6861, acc: 0.59\n",
      "Valid  loss: 0.6900, acc: 0.53\n",
      "=================== 9 / 1000 epoch ===================\n",
      "Train  loss: 0.6849, acc: 0.59\n",
      "Valid  loss: 0.6896, acc: 0.53\n",
      "=================== 10 / 1000 epoch ===================\n",
      "Train  loss: 0.6838, acc: 0.59\n",
      "Valid  loss: 0.6891, acc: 0.52\n",
      "=================== 11 / 1000 epoch ===================\n",
      "Train  loss: 0.6826, acc: 0.59\n",
      "Valid  loss: 0.6887, acc: 0.52\n",
      "=================== 12 / 1000 epoch ===================\n",
      "Train  loss: 0.6815, acc: 0.59\n",
      "Valid  loss: 0.6883, acc: 0.52\n",
      "=================== 13 / 1000 epoch ===================\n",
      "Train  loss: 0.6804, acc: 0.59\n",
      "Valid  loss: 0.6878, acc: 0.52\n",
      "=================== 14 / 1000 epoch ===================\n",
      "Train  loss: 0.6793, acc: 0.59\n",
      "Valid  loss: 0.6874, acc: 0.52\n",
      "=================== 15 / 1000 epoch ===================\n",
      "Train  loss: 0.6782, acc: 0.59\n",
      "Valid  loss: 0.6870, acc: 0.52\n",
      "=================== 16 / 1000 epoch ===================\n",
      "Train  loss: 0.6771, acc: 0.59\n",
      "Valid  loss: 0.6865, acc: 0.51\n",
      "=================== 17 / 1000 epoch ===================\n",
      "Train  loss: 0.6760, acc: 0.59\n",
      "Valid  loss: 0.6861, acc: 0.51\n",
      "=================== 18 / 1000 epoch ===================\n",
      "Train  loss: 0.6750, acc: 0.59\n",
      "Valid  loss: 0.6857, acc: 0.51\n",
      "=================== 19 / 1000 epoch ===================\n",
      "Train  loss: 0.6739, acc: 0.59\n",
      "Valid  loss: 0.6853, acc: 0.51\n",
      "=================== 20 / 1000 epoch ===================\n",
      "Train  loss: 0.6729, acc: 0.59\n",
      "Valid  loss: 0.6848, acc: 0.51\n",
      "=================== 21 / 1000 epoch ===================\n",
      "Train  loss: 0.6719, acc: 0.59\n",
      "Valid  loss: 0.6844, acc: 0.51\n",
      "=================== 22 / 1000 epoch ===================\n",
      "Train  loss: 0.6709, acc: 0.59\n",
      "Valid  loss: 0.6840, acc: 0.51\n",
      "=================== 23 / 1000 epoch ===================\n",
      "Train  loss: 0.6698, acc: 0.59\n",
      "Valid  loss: 0.6835, acc: 0.51\n",
      "=================== 24 / 1000 epoch ===================\n",
      "Train  loss: 0.6688, acc: 0.59\n",
      "Valid  loss: 0.6831, acc: 0.51\n",
      "=================== 25 / 1000 epoch ===================\n",
      "Train  loss: 0.6678, acc: 0.60\n",
      "Valid  loss: 0.6826, acc: 0.51\n",
      "=================== 26 / 1000 epoch ===================\n",
      "Train  loss: 0.6669, acc: 0.60\n",
      "Valid  loss: 0.6822, acc: 0.51\n",
      "=================== 27 / 1000 epoch ===================\n",
      "Train  loss: 0.6659, acc: 0.60\n",
      "Valid  loss: 0.6818, acc: 0.51\n",
      "=================== 28 / 1000 epoch ===================\n",
      "Train  loss: 0.6649, acc: 0.60\n",
      "Valid  loss: 0.6813, acc: 0.51\n",
      "=================== 29 / 1000 epoch ===================\n",
      "Train  loss: 0.6639, acc: 0.60\n",
      "Valid  loss: 0.6809, acc: 0.51\n",
      "=================== 30 / 1000 epoch ===================\n",
      "Train  loss: 0.6630, acc: 0.60\n",
      "Valid  loss: 0.6804, acc: 0.51\n",
      "=================== 31 / 1000 epoch ===================\n",
      "Train  loss: 0.6620, acc: 0.60\n",
      "Valid  loss: 0.6799, acc: 0.51\n",
      "=================== 32 / 1000 epoch ===================\n",
      "Train  loss: 0.6611, acc: 0.60\n",
      "Valid  loss: 0.6795, acc: 0.51\n",
      "=================== 33 / 1000 epoch ===================\n",
      "Train  loss: 0.6601, acc: 0.61\n",
      "Valid  loss: 0.6790, acc: 0.51\n",
      "=================== 34 / 1000 epoch ===================\n",
      "Train  loss: 0.6592, acc: 0.61\n",
      "Valid  loss: 0.6785, acc: 0.52\n",
      "=================== 35 / 1000 epoch ===================\n",
      "Train  loss: 0.6583, acc: 0.61\n",
      "Valid  loss: 0.6781, acc: 0.52\n",
      "=================== 36 / 1000 epoch ===================\n",
      "Train  loss: 0.6573, acc: 0.61\n",
      "Valid  loss: 0.6776, acc: 0.52\n",
      "=================== 37 / 1000 epoch ===================\n",
      "Train  loss: 0.6564, acc: 0.61\n",
      "Valid  loss: 0.6771, acc: 0.52\n",
      "=================== 38 / 1000 epoch ===================\n",
      "Train  loss: 0.6555, acc: 0.62\n",
      "Valid  loss: 0.6767, acc: 0.52\n",
      "=================== 39 / 1000 epoch ===================\n",
      "Train  loss: 0.6546, acc: 0.62\n",
      "Valid  loss: 0.6762, acc: 0.52\n",
      "=================== 40 / 1000 epoch ===================\n",
      "Train  loss: 0.6537, acc: 0.62\n",
      "Valid  loss: 0.6757, acc: 0.52\n",
      "=================== 41 / 1000 epoch ===================\n",
      "Train  loss: 0.6528, acc: 0.62\n",
      "Valid  loss: 0.6752, acc: 0.52\n",
      "=================== 42 / 1000 epoch ===================\n",
      "Train  loss: 0.6519, acc: 0.62\n",
      "Valid  loss: 0.6747, acc: 0.52\n",
      "=================== 43 / 1000 epoch ===================\n",
      "Train  loss: 0.6510, acc: 0.63\n",
      "Valid  loss: 0.6743, acc: 0.52\n",
      "=================== 44 / 1000 epoch ===================\n",
      "Train  loss: 0.6501, acc: 0.63\n",
      "Valid  loss: 0.6738, acc: 0.53\n",
      "=================== 45 / 1000 epoch ===================\n",
      "Train  loss: 0.6492, acc: 0.63\n",
      "Valid  loss: 0.6733, acc: 0.53\n",
      "=================== 46 / 1000 epoch ===================\n",
      "Train  loss: 0.6483, acc: 0.63\n",
      "Valid  loss: 0.6728, acc: 0.53\n",
      "=================== 47 / 1000 epoch ===================\n",
      "Train  loss: 0.6474, acc: 0.63\n",
      "Valid  loss: 0.6723, acc: 0.53\n",
      "=================== 48 / 1000 epoch ===================\n",
      "Train  loss: 0.6466, acc: 0.64\n",
      "Valid  loss: 0.6719, acc: 0.53\n",
      "=================== 49 / 1000 epoch ===================\n",
      "Train  loss: 0.6457, acc: 0.64\n",
      "Valid  loss: 0.6714, acc: 0.54\n",
      "=================== 50 / 1000 epoch ===================\n",
      "Train  loss: 0.6448, acc: 0.64\n",
      "Valid  loss: 0.6709, acc: 0.54\n",
      "=================== 51 / 1000 epoch ===================\n",
      "Train  loss: 0.6440, acc: 0.64\n",
      "Valid  loss: 0.6704, acc: 0.54\n",
      "=================== 52 / 1000 epoch ===================\n",
      "Train  loss: 0.6431, acc: 0.65\n",
      "Valid  loss: 0.6699, acc: 0.54\n",
      "=================== 53 / 1000 epoch ===================\n",
      "Train  loss: 0.6423, acc: 0.65\n",
      "Valid  loss: 0.6695, acc: 0.55\n",
      "=================== 54 / 1000 epoch ===================\n",
      "Train  loss: 0.6414, acc: 0.65\n",
      "Valid  loss: 0.6690, acc: 0.55\n",
      "=================== 55 / 1000 epoch ===================\n",
      "Train  loss: 0.6406, acc: 0.65\n",
      "Valid  loss: 0.6685, acc: 0.55\n",
      "=================== 56 / 1000 epoch ===================\n",
      "Train  loss: 0.6397, acc: 0.65\n",
      "Valid  loss: 0.6680, acc: 0.56\n",
      "=================== 57 / 1000 epoch ===================\n",
      "Train  loss: 0.6389, acc: 0.66\n",
      "Valid  loss: 0.6676, acc: 0.56\n",
      "=================== 58 / 1000 epoch ===================\n",
      "Train  loss: 0.6381, acc: 0.66\n",
      "Valid  loss: 0.6671, acc: 0.56\n",
      "=================== 59 / 1000 epoch ===================\n",
      "Train  loss: 0.6372, acc: 0.66\n",
      "Valid  loss: 0.6666, acc: 0.56\n",
      "=================== 60 / 1000 epoch ===================\n",
      "Train  loss: 0.6364, acc: 0.66\n",
      "Valid  loss: 0.6661, acc: 0.56\n",
      "=================== 61 / 1000 epoch ===================\n",
      "Train  loss: 0.6356, acc: 0.67\n",
      "Valid  loss: 0.6657, acc: 0.56\n",
      "=================== 62 / 1000 epoch ===================\n",
      "Train  loss: 0.6348, acc: 0.67\n",
      "Valid  loss: 0.6652, acc: 0.56\n",
      "=================== 63 / 1000 epoch ===================\n",
      "Train  loss: 0.6340, acc: 0.67\n",
      "Valid  loss: 0.6647, acc: 0.56\n",
      "=================== 64 / 1000 epoch ===================\n",
      "Train  loss: 0.6332, acc: 0.67\n",
      "Valid  loss: 0.6643, acc: 0.57\n",
      "=================== 65 / 1000 epoch ===================\n",
      "Train  loss: 0.6324, acc: 0.67\n",
      "Valid  loss: 0.6638, acc: 0.57\n",
      "=================== 66 / 1000 epoch ===================\n",
      "Train  loss: 0.6316, acc: 0.67\n",
      "Valid  loss: 0.6634, acc: 0.57\n",
      "=================== 67 / 1000 epoch ===================\n",
      "Train  loss: 0.6308, acc: 0.68\n",
      "Valid  loss: 0.6629, acc: 0.56\n",
      "=================== 68 / 1000 epoch ===================\n",
      "Train  loss: 0.6300, acc: 0.68\n",
      "Valid  loss: 0.6624, acc: 0.57\n",
      "=================== 69 / 1000 epoch ===================\n",
      "Train  loss: 0.6292, acc: 0.68\n",
      "Valid  loss: 0.6620, acc: 0.57\n",
      "=================== 70 / 1000 epoch ===================\n",
      "Train  loss: 0.6284, acc: 0.68\n",
      "Valid  loss: 0.6615, acc: 0.57\n",
      "=================== 71 / 1000 epoch ===================\n",
      "Train  loss: 0.6276, acc: 0.68\n",
      "Valid  loss: 0.6611, acc: 0.57\n",
      "=================== 72 / 1000 epoch ===================\n",
      "Train  loss: 0.6269, acc: 0.69\n",
      "Valid  loss: 0.6606, acc: 0.57\n",
      "=================== 73 / 1000 epoch ===================\n",
      "Train  loss: 0.6261, acc: 0.69\n",
      "Valid  loss: 0.6602, acc: 0.57\n",
      "=================== 74 / 1000 epoch ===================\n",
      "Train  loss: 0.6253, acc: 0.69\n",
      "Valid  loss: 0.6598, acc: 0.58\n",
      "=================== 75 / 1000 epoch ===================\n",
      "Train  loss: 0.6245, acc: 0.69\n",
      "Valid  loss: 0.6593, acc: 0.58\n",
      "=================== 76 / 1000 epoch ===================\n",
      "Train  loss: 0.6238, acc: 0.69\n",
      "Valid  loss: 0.6589, acc: 0.58\n",
      "=================== 77 / 1000 epoch ===================\n",
      "Train  loss: 0.6230, acc: 0.70\n",
      "Valid  loss: 0.6584, acc: 0.58\n",
      "=================== 78 / 1000 epoch ===================\n",
      "Train  loss: 0.6223, acc: 0.70\n",
      "Valid  loss: 0.6580, acc: 0.58\n",
      "=================== 79 / 1000 epoch ===================\n",
      "Train  loss: 0.6215, acc: 0.70\n",
      "Valid  loss: 0.6576, acc: 0.58\n",
      "=================== 80 / 1000 epoch ===================\n",
      "Train  loss: 0.6208, acc: 0.70\n",
      "Valid  loss: 0.6571, acc: 0.58\n",
      "=================== 81 / 1000 epoch ===================\n",
      "Train  loss: 0.6200, acc: 0.70\n",
      "Valid  loss: 0.6567, acc: 0.58\n",
      "=================== 82 / 1000 epoch ===================\n",
      "Train  loss: 0.6193, acc: 0.70\n",
      "Valid  loss: 0.6563, acc: 0.59\n",
      "=================== 83 / 1000 epoch ===================\n",
      "Train  loss: 0.6186, acc: 0.71\n",
      "Valid  loss: 0.6559, acc: 0.59\n",
      "=================== 84 / 1000 epoch ===================\n",
      "Train  loss: 0.6178, acc: 0.71\n",
      "Valid  loss: 0.6554, acc: 0.59\n",
      "=================== 85 / 1000 epoch ===================\n",
      "Train  loss: 0.6171, acc: 0.71\n",
      "Valid  loss: 0.6550, acc: 0.59\n",
      "=================== 86 / 1000 epoch ===================\n",
      "Train  loss: 0.6164, acc: 0.71\n",
      "Valid  loss: 0.6546, acc: 0.59\n",
      "=================== 87 / 1000 epoch ===================\n",
      "Train  loss: 0.6157, acc: 0.71\n",
      "Valid  loss: 0.6542, acc: 0.59\n",
      "=================== 88 / 1000 epoch ===================\n",
      "Train  loss: 0.6149, acc: 0.71\n",
      "Valid  loss: 0.6537, acc: 0.59\n",
      "=================== 89 / 1000 epoch ===================\n",
      "Train  loss: 0.6142, acc: 0.71\n",
      "Valid  loss: 0.6533, acc: 0.59\n",
      "=================== 90 / 1000 epoch ===================\n",
      "Train  loss: 0.6135, acc: 0.71\n",
      "Valid  loss: 0.6529, acc: 0.60\n",
      "=================== 91 / 1000 epoch ===================\n",
      "Train  loss: 0.6128, acc: 0.72\n",
      "Valid  loss: 0.6525, acc: 0.60\n",
      "=================== 92 / 1000 epoch ===================\n",
      "Train  loss: 0.6121, acc: 0.72\n",
      "Valid  loss: 0.6521, acc: 0.60\n",
      "=================== 93 / 1000 epoch ===================\n",
      "Train  loss: 0.6114, acc: 0.72\n",
      "Valid  loss: 0.6517, acc: 0.60\n",
      "=================== 94 / 1000 epoch ===================\n",
      "Train  loss: 0.6107, acc: 0.72\n",
      "Valid  loss: 0.6513, acc: 0.60\n",
      "=================== 95 / 1000 epoch ===================\n",
      "Train  loss: 0.6100, acc: 0.72\n",
      "Valid  loss: 0.6509, acc: 0.60\n",
      "=================== 96 / 1000 epoch ===================\n",
      "Train  loss: 0.6093, acc: 0.72\n",
      "Valid  loss: 0.6504, acc: 0.60\n",
      "=================== 97 / 1000 epoch ===================\n",
      "Train  loss: 0.6086, acc: 0.72\n",
      "Valid  loss: 0.6500, acc: 0.61\n",
      "=================== 98 / 1000 epoch ===================\n",
      "Train  loss: 0.6079, acc: 0.72\n",
      "Valid  loss: 0.6496, acc: 0.60\n",
      "=================== 99 / 1000 epoch ===================\n",
      "Train  loss: 0.6073, acc: 0.73\n",
      "Valid  loss: 0.6492, acc: 0.60\n",
      "=================== 100 / 1000 epoch ===================\n",
      "Train  loss: 0.6066, acc: 0.73\n",
      "Valid  loss: 0.6488, acc: 0.60\n",
      "=================== 101 / 1000 epoch ===================\n",
      "Train  loss: 0.6059, acc: 0.73\n",
      "Valid  loss: 0.6484, acc: 0.60\n",
      "=================== 102 / 1000 epoch ===================\n",
      "Train  loss: 0.6052, acc: 0.73\n",
      "Valid  loss: 0.6480, acc: 0.61\n",
      "=================== 103 / 1000 epoch ===================\n",
      "Train  loss: 0.6046, acc: 0.73\n",
      "Valid  loss: 0.6476, acc: 0.61\n",
      "=================== 104 / 1000 epoch ===================\n",
      "Train  loss: 0.6039, acc: 0.73\n",
      "Valid  loss: 0.6472, acc: 0.61\n",
      "=================== 105 / 1000 epoch ===================\n",
      "Train  loss: 0.6032, acc: 0.73\n",
      "Valid  loss: 0.6468, acc: 0.61\n",
      "=================== 106 / 1000 epoch ===================\n",
      "Train  loss: 0.6026, acc: 0.73\n",
      "Valid  loss: 0.6465, acc: 0.61\n",
      "=================== 107 / 1000 epoch ===================\n",
      "Train  loss: 0.6019, acc: 0.73\n",
      "Valid  loss: 0.6461, acc: 0.61\n",
      "=================== 108 / 1000 epoch ===================\n",
      "Train  loss: 0.6013, acc: 0.74\n",
      "Valid  loss: 0.6457, acc: 0.62\n",
      "=================== 109 / 1000 epoch ===================\n",
      "Train  loss: 0.6006, acc: 0.74\n",
      "Valid  loss: 0.6453, acc: 0.62\n",
      "=================== 110 / 1000 epoch ===================\n",
      "Train  loss: 0.6000, acc: 0.74\n",
      "Valid  loss: 0.6449, acc: 0.62\n",
      "=================== 111 / 1000 epoch ===================\n",
      "Train  loss: 0.5993, acc: 0.74\n",
      "Valid  loss: 0.6445, acc: 0.62\n",
      "=================== 112 / 1000 epoch ===================\n",
      "Train  loss: 0.5987, acc: 0.74\n",
      "Valid  loss: 0.6441, acc: 0.62\n",
      "=================== 113 / 1000 epoch ===================\n",
      "Train  loss: 0.5981, acc: 0.74\n",
      "Valid  loss: 0.6437, acc: 0.62\n",
      "=================== 114 / 1000 epoch ===================\n",
      "Train  loss: 0.5974, acc: 0.74\n",
      "Valid  loss: 0.6434, acc: 0.62\n",
      "=================== 115 / 1000 epoch ===================\n",
      "Train  loss: 0.5968, acc: 0.74\n",
      "Valid  loss: 0.6430, acc: 0.62\n",
      "=================== 116 / 1000 epoch ===================\n",
      "Train  loss: 0.5962, acc: 0.74\n",
      "Valid  loss: 0.6426, acc: 0.63\n",
      "=================== 117 / 1000 epoch ===================\n",
      "Train  loss: 0.5955, acc: 0.74\n",
      "Valid  loss: 0.6422, acc: 0.63\n",
      "=================== 118 / 1000 epoch ===================\n",
      "Train  loss: 0.5949, acc: 0.75\n",
      "Valid  loss: 0.6418, acc: 0.63\n",
      "=================== 119 / 1000 epoch ===================\n",
      "Train  loss: 0.5943, acc: 0.75\n",
      "Valid  loss: 0.6415, acc: 0.63\n",
      "=================== 120 / 1000 epoch ===================\n",
      "Train  loss: 0.5937, acc: 0.75\n",
      "Valid  loss: 0.6411, acc: 0.63\n",
      "=================== 121 / 1000 epoch ===================\n",
      "Train  loss: 0.5930, acc: 0.75\n",
      "Valid  loss: 0.6407, acc: 0.63\n",
      "=================== 122 / 1000 epoch ===================\n",
      "Train  loss: 0.5924, acc: 0.75\n",
      "Valid  loss: 0.6403, acc: 0.63\n",
      "=================== 123 / 1000 epoch ===================\n",
      "Train  loss: 0.5918, acc: 0.75\n",
      "Valid  loss: 0.6400, acc: 0.63\n",
      "=================== 124 / 1000 epoch ===================\n",
      "Train  loss: 0.5912, acc: 0.75\n",
      "Valid  loss: 0.6396, acc: 0.64\n",
      "=================== 125 / 1000 epoch ===================\n",
      "Train  loss: 0.5906, acc: 0.75\n",
      "Valid  loss: 0.6392, acc: 0.64\n",
      "=================== 126 / 1000 epoch ===================\n",
      "Train  loss: 0.5900, acc: 0.75\n",
      "Valid  loss: 0.6389, acc: 0.64\n",
      "=================== 127 / 1000 epoch ===================\n",
      "Train  loss: 0.5894, acc: 0.75\n",
      "Valid  loss: 0.6385, acc: 0.64\n",
      "=================== 128 / 1000 epoch ===================\n",
      "Train  loss: 0.5888, acc: 0.75\n",
      "Valid  loss: 0.6381, acc: 0.64\n",
      "=================== 129 / 1000 epoch ===================\n",
      "Train  loss: 0.5882, acc: 0.75\n",
      "Valid  loss: 0.6378, acc: 0.64\n",
      "=================== 130 / 1000 epoch ===================\n",
      "Train  loss: 0.5876, acc: 0.75\n",
      "Valid  loss: 0.6374, acc: 0.64\n",
      "=================== 131 / 1000 epoch ===================\n",
      "Train  loss: 0.5870, acc: 0.75\n",
      "Valid  loss: 0.6370, acc: 0.64\n",
      "=================== 132 / 1000 epoch ===================\n",
      "Train  loss: 0.5865, acc: 0.76\n",
      "Valid  loss: 0.6367, acc: 0.64\n",
      "=================== 133 / 1000 epoch ===================\n",
      "Train  loss: 0.5859, acc: 0.76\n",
      "Valid  loss: 0.6363, acc: 0.64\n",
      "=================== 134 / 1000 epoch ===================\n",
      "Train  loss: 0.5853, acc: 0.76\n",
      "Valid  loss: 0.6360, acc: 0.64\n",
      "=================== 135 / 1000 epoch ===================\n",
      "Train  loss: 0.5847, acc: 0.76\n",
      "Valid  loss: 0.6356, acc: 0.65\n",
      "=================== 136 / 1000 epoch ===================\n",
      "Train  loss: 0.5841, acc: 0.76\n",
      "Valid  loss: 0.6352, acc: 0.65\n",
      "=================== 137 / 1000 epoch ===================\n",
      "Train  loss: 0.5836, acc: 0.76\n",
      "Valid  loss: 0.6349, acc: 0.65\n",
      "=================== 138 / 1000 epoch ===================\n",
      "Train  loss: 0.5830, acc: 0.76\n",
      "Valid  loss: 0.6345, acc: 0.65\n",
      "=================== 139 / 1000 epoch ===================\n",
      "Train  loss: 0.5824, acc: 0.76\n",
      "Valid  loss: 0.6342, acc: 0.65\n",
      "=================== 140 / 1000 epoch ===================\n",
      "Train  loss: 0.5819, acc: 0.76\n",
      "Valid  loss: 0.6338, acc: 0.65\n",
      "=================== 141 / 1000 epoch ===================\n",
      "Train  loss: 0.5813, acc: 0.76\n",
      "Valid  loss: 0.6335, acc: 0.65\n",
      "=================== 142 / 1000 epoch ===================\n",
      "Train  loss: 0.5808, acc: 0.76\n",
      "Valid  loss: 0.6331, acc: 0.65\n",
      "=================== 143 / 1000 epoch ===================\n",
      "Train  loss: 0.5802, acc: 0.76\n",
      "Valid  loss: 0.6328, acc: 0.65\n",
      "=================== 144 / 1000 epoch ===================\n",
      "Train  loss: 0.5796, acc: 0.76\n",
      "Valid  loss: 0.6324, acc: 0.66\n",
      "=================== 145 / 1000 epoch ===================\n",
      "Train  loss: 0.5791, acc: 0.76\n",
      "Valid  loss: 0.6321, acc: 0.66\n",
      "=================== 146 / 1000 epoch ===================\n",
      "Train  loss: 0.5785, acc: 0.76\n",
      "Valid  loss: 0.6318, acc: 0.66\n",
      "=================== 147 / 1000 epoch ===================\n",
      "Train  loss: 0.5780, acc: 0.77\n",
      "Valid  loss: 0.6314, acc: 0.66\n",
      "=================== 148 / 1000 epoch ===================\n",
      "Train  loss: 0.5774, acc: 0.77\n",
      "Valid  loss: 0.6311, acc: 0.67\n",
      "=================== 149 / 1000 epoch ===================\n",
      "Train  loss: 0.5769, acc: 0.77\n",
      "Valid  loss: 0.6307, acc: 0.67\n",
      "=================== 150 / 1000 epoch ===================\n",
      "Train  loss: 0.5764, acc: 0.77\n",
      "Valid  loss: 0.6304, acc: 0.67\n",
      "=================== 151 / 1000 epoch ===================\n",
      "Train  loss: 0.5758, acc: 0.77\n",
      "Valid  loss: 0.6301, acc: 0.67\n",
      "=================== 152 / 1000 epoch ===================\n",
      "Train  loss: 0.5753, acc: 0.77\n",
      "Valid  loss: 0.6297, acc: 0.67\n",
      "=================== 153 / 1000 epoch ===================\n",
      "Train  loss: 0.5748, acc: 0.77\n",
      "Valid  loss: 0.6294, acc: 0.67\n",
      "=================== 154 / 1000 epoch ===================\n",
      "Train  loss: 0.5742, acc: 0.77\n",
      "Valid  loss: 0.6290, acc: 0.67\n",
      "=================== 155 / 1000 epoch ===================\n",
      "Train  loss: 0.5737, acc: 0.77\n",
      "Valid  loss: 0.6287, acc: 0.67\n",
      "=================== 156 / 1000 epoch ===================\n",
      "Train  loss: 0.5732, acc: 0.77\n",
      "Valid  loss: 0.6284, acc: 0.67\n",
      "=================== 157 / 1000 epoch ===================\n",
      "Train  loss: 0.5726, acc: 0.77\n",
      "Valid  loss: 0.6280, acc: 0.67\n",
      "=================== 158 / 1000 epoch ===================\n",
      "Train  loss: 0.5721, acc: 0.77\n",
      "Valid  loss: 0.6277, acc: 0.67\n",
      "=================== 159 / 1000 epoch ===================\n",
      "Train  loss: 0.5716, acc: 0.77\n",
      "Valid  loss: 0.6274, acc: 0.67\n",
      "=================== 160 / 1000 epoch ===================\n",
      "Train  loss: 0.5711, acc: 0.77\n",
      "Valid  loss: 0.6271, acc: 0.67\n",
      "=================== 161 / 1000 epoch ===================\n",
      "Train  loss: 0.5706, acc: 0.77\n",
      "Valid  loss: 0.6267, acc: 0.68\n",
      "=================== 162 / 1000 epoch ===================\n",
      "Train  loss: 0.5701, acc: 0.77\n",
      "Valid  loss: 0.6264, acc: 0.68\n",
      "=================== 163 / 1000 epoch ===================\n",
      "Train  loss: 0.5696, acc: 0.77\n",
      "Valid  loss: 0.6261, acc: 0.68\n",
      "=================== 164 / 1000 epoch ===================\n",
      "Train  loss: 0.5690, acc: 0.77\n",
      "Valid  loss: 0.6258, acc: 0.68\n",
      "=================== 165 / 1000 epoch ===================\n",
      "Train  loss: 0.5685, acc: 0.77\n",
      "Valid  loss: 0.6254, acc: 0.68\n",
      "=================== 166 / 1000 epoch ===================\n",
      "Train  loss: 0.5680, acc: 0.78\n",
      "Valid  loss: 0.6251, acc: 0.68\n",
      "=================== 167 / 1000 epoch ===================\n",
      "Train  loss: 0.5675, acc: 0.78\n",
      "Valid  loss: 0.6248, acc: 0.68\n",
      "=================== 168 / 1000 epoch ===================\n",
      "Train  loss: 0.5670, acc: 0.78\n",
      "Valid  loss: 0.6245, acc: 0.69\n",
      "=================== 169 / 1000 epoch ===================\n",
      "Train  loss: 0.5665, acc: 0.78\n",
      "Valid  loss: 0.6242, acc: 0.69\n",
      "=================== 170 / 1000 epoch ===================\n",
      "Train  loss: 0.5660, acc: 0.78\n",
      "Valid  loss: 0.6238, acc: 0.69\n",
      "=================== 171 / 1000 epoch ===================\n",
      "Train  loss: 0.5655, acc: 0.78\n",
      "Valid  loss: 0.6235, acc: 0.69\n",
      "=================== 172 / 1000 epoch ===================\n",
      "Train  loss: 0.5651, acc: 0.78\n",
      "Valid  loss: 0.6232, acc: 0.69\n",
      "=================== 173 / 1000 epoch ===================\n",
      "Train  loss: 0.5646, acc: 0.78\n",
      "Valid  loss: 0.6229, acc: 0.69\n",
      "=================== 174 / 1000 epoch ===================\n",
      "Train  loss: 0.5641, acc: 0.78\n",
      "Valid  loss: 0.6226, acc: 0.70\n",
      "=================== 175 / 1000 epoch ===================\n",
      "Train  loss: 0.5636, acc: 0.78\n",
      "Valid  loss: 0.6223, acc: 0.70\n",
      "=================== 176 / 1000 epoch ===================\n",
      "Train  loss: 0.5631, acc: 0.78\n",
      "Valid  loss: 0.6220, acc: 0.70\n",
      "=================== 177 / 1000 epoch ===================\n",
      "Train  loss: 0.5626, acc: 0.78\n",
      "Valid  loss: 0.6217, acc: 0.70\n",
      "=================== 178 / 1000 epoch ===================\n",
      "Train  loss: 0.5621, acc: 0.78\n",
      "Valid  loss: 0.6213, acc: 0.70\n",
      "=================== 179 / 1000 epoch ===================\n",
      "Train  loss: 0.5617, acc: 0.78\n",
      "Valid  loss: 0.6210, acc: 0.70\n",
      "=================== 180 / 1000 epoch ===================\n",
      "Train  loss: 0.5612, acc: 0.78\n",
      "Valid  loss: 0.6207, acc: 0.70\n",
      "=================== 181 / 1000 epoch ===================\n",
      "Train  loss: 0.5607, acc: 0.78\n",
      "Valid  loss: 0.6204, acc: 0.70\n",
      "=================== 182 / 1000 epoch ===================\n",
      "Train  loss: 0.5603, acc: 0.78\n",
      "Valid  loss: 0.6201, acc: 0.70\n",
      "=================== 183 / 1000 epoch ===================\n",
      "Train  loss: 0.5598, acc: 0.78\n",
      "Valid  loss: 0.6198, acc: 0.70\n",
      "=================== 184 / 1000 epoch ===================\n",
      "Train  loss: 0.5593, acc: 0.78\n",
      "Valid  loss: 0.6195, acc: 0.71\n",
      "=================== 185 / 1000 epoch ===================\n",
      "Train  loss: 0.5588, acc: 0.78\n",
      "Valid  loss: 0.6192, acc: 0.71\n",
      "=================== 186 / 1000 epoch ===================\n",
      "Train  loss: 0.5584, acc: 0.78\n",
      "Valid  loss: 0.6189, acc: 0.71\n",
      "=================== 187 / 1000 epoch ===================\n",
      "Train  loss: 0.5579, acc: 0.78\n",
      "Valid  loss: 0.6186, acc: 0.71\n",
      "=================== 188 / 1000 epoch ===================\n",
      "Train  loss: 0.5575, acc: 0.78\n",
      "Valid  loss: 0.6183, acc: 0.71\n",
      "=================== 189 / 1000 epoch ===================\n",
      "Train  loss: 0.5570, acc: 0.78\n",
      "Valid  loss: 0.6180, acc: 0.71\n",
      "=================== 190 / 1000 epoch ===================\n",
      "Train  loss: 0.5566, acc: 0.78\n",
      "Valid  loss: 0.6177, acc: 0.71\n",
      "=================== 191 / 1000 epoch ===================\n",
      "Train  loss: 0.5561, acc: 0.78\n",
      "Valid  loss: 0.6174, acc: 0.71\n",
      "=================== 192 / 1000 epoch ===================\n",
      "Train  loss: 0.5556, acc: 0.78\n",
      "Valid  loss: 0.6171, acc: 0.71\n",
      "=================== 193 / 1000 epoch ===================\n",
      "Train  loss: 0.5552, acc: 0.78\n",
      "Valid  loss: 0.6168, acc: 0.71\n",
      "=================== 194 / 1000 epoch ===================\n",
      "Train  loss: 0.5547, acc: 0.78\n",
      "Valid  loss: 0.6165, acc: 0.71\n",
      "=================== 195 / 1000 epoch ===================\n",
      "Train  loss: 0.5543, acc: 0.79\n",
      "Valid  loss: 0.6162, acc: 0.71\n",
      "=================== 196 / 1000 epoch ===================\n",
      "Train  loss: 0.5539, acc: 0.79\n",
      "Valid  loss: 0.6159, acc: 0.71\n",
      "=================== 197 / 1000 epoch ===================\n",
      "Train  loss: 0.5534, acc: 0.79\n",
      "Valid  loss: 0.6157, acc: 0.71\n",
      "=================== 198 / 1000 epoch ===================\n",
      "Train  loss: 0.5530, acc: 0.79\n",
      "Valid  loss: 0.6154, acc: 0.71\n",
      "=================== 199 / 1000 epoch ===================\n",
      "Train  loss: 0.5525, acc: 0.79\n",
      "Valid  loss: 0.6151, acc: 0.71\n",
      "=================== 200 / 1000 epoch ===================\n",
      "Train  loss: 0.5521, acc: 0.79\n",
      "Valid  loss: 0.6148, acc: 0.72\n",
      "=================== 201 / 1000 epoch ===================\n",
      "Train  loss: 0.5517, acc: 0.79\n",
      "Valid  loss: 0.6145, acc: 0.72\n",
      "=================== 202 / 1000 epoch ===================\n",
      "Train  loss: 0.5512, acc: 0.79\n",
      "Valid  loss: 0.6142, acc: 0.72\n",
      "=================== 203 / 1000 epoch ===================\n",
      "Train  loss: 0.5508, acc: 0.79\n",
      "Valid  loss: 0.6139, acc: 0.72\n",
      "=================== 204 / 1000 epoch ===================\n",
      "Train  loss: 0.5504, acc: 0.79\n",
      "Valid  loss: 0.6136, acc: 0.72\n",
      "=================== 205 / 1000 epoch ===================\n",
      "Train  loss: 0.5499, acc: 0.79\n",
      "Valid  loss: 0.6134, acc: 0.72\n",
      "=================== 206 / 1000 epoch ===================\n",
      "Train  loss: 0.5495, acc: 0.79\n",
      "Valid  loss: 0.6131, acc: 0.72\n",
      "=================== 207 / 1000 epoch ===================\n",
      "Train  loss: 0.5491, acc: 0.79\n",
      "Valid  loss: 0.6128, acc: 0.72\n",
      "=================== 208 / 1000 epoch ===================\n",
      "Train  loss: 0.5487, acc: 0.79\n",
      "Valid  loss: 0.6125, acc: 0.72\n",
      "=================== 209 / 1000 epoch ===================\n",
      "Train  loss: 0.5482, acc: 0.79\n",
      "Valid  loss: 0.6122, acc: 0.72\n",
      "=================== 210 / 1000 epoch ===================\n",
      "Train  loss: 0.5478, acc: 0.79\n",
      "Valid  loss: 0.6120, acc: 0.72\n",
      "=================== 211 / 1000 epoch ===================\n",
      "Train  loss: 0.5474, acc: 0.79\n",
      "Valid  loss: 0.6117, acc: 0.72\n",
      "=================== 212 / 1000 epoch ===================\n",
      "Train  loss: 0.5470, acc: 0.79\n",
      "Valid  loss: 0.6114, acc: 0.72\n",
      "=================== 213 / 1000 epoch ===================\n",
      "Train  loss: 0.5466, acc: 0.79\n",
      "Valid  loss: 0.6111, acc: 0.72\n",
      "=================== 214 / 1000 epoch ===================\n",
      "Train  loss: 0.5461, acc: 0.79\n",
      "Valid  loss: 0.6108, acc: 0.72\n",
      "=================== 215 / 1000 epoch ===================\n",
      "Train  loss: 0.5457, acc: 0.79\n",
      "Valid  loss: 0.6106, acc: 0.72\n",
      "=================== 216 / 1000 epoch ===================\n",
      "Train  loss: 0.5453, acc: 0.79\n",
      "Valid  loss: 0.6103, acc: 0.72\n",
      "=================== 217 / 1000 epoch ===================\n",
      "Train  loss: 0.5449, acc: 0.79\n",
      "Valid  loss: 0.6100, acc: 0.72\n",
      "=================== 218 / 1000 epoch ===================\n",
      "Train  loss: 0.5445, acc: 0.79\n",
      "Valid  loss: 0.6097, acc: 0.72\n",
      "=================== 219 / 1000 epoch ===================\n",
      "Train  loss: 0.5441, acc: 0.79\n",
      "Valid  loss: 0.6095, acc: 0.72\n",
      "=================== 220 / 1000 epoch ===================\n",
      "Train  loss: 0.5437, acc: 0.79\n",
      "Valid  loss: 0.6092, acc: 0.73\n",
      "=================== 221 / 1000 epoch ===================\n",
      "Train  loss: 0.5433, acc: 0.79\n",
      "Valid  loss: 0.6089, acc: 0.73\n",
      "=================== 222 / 1000 epoch ===================\n",
      "Train  loss: 0.5429, acc: 0.79\n",
      "Valid  loss: 0.6087, acc: 0.73\n",
      "=================== 223 / 1000 epoch ===================\n",
      "Train  loss: 0.5425, acc: 0.79\n",
      "Valid  loss: 0.6084, acc: 0.73\n",
      "=================== 224 / 1000 epoch ===================\n",
      "Train  loss: 0.5421, acc: 0.79\n",
      "Valid  loss: 0.6081, acc: 0.73\n",
      "=================== 225 / 1000 epoch ===================\n",
      "Train  loss: 0.5417, acc: 0.79\n",
      "Valid  loss: 0.6079, acc: 0.73\n",
      "=================== 226 / 1000 epoch ===================\n",
      "Train  loss: 0.5413, acc: 0.79\n",
      "Valid  loss: 0.6076, acc: 0.73\n",
      "=================== 227 / 1000 epoch ===================\n",
      "Train  loss: 0.5409, acc: 0.79\n",
      "Valid  loss: 0.6073, acc: 0.73\n",
      "=================== 228 / 1000 epoch ===================\n",
      "Train  loss: 0.5405, acc: 0.79\n",
      "Valid  loss: 0.6071, acc: 0.73\n",
      "=================== 229 / 1000 epoch ===================\n",
      "Train  loss: 0.5401, acc: 0.79\n",
      "Valid  loss: 0.6068, acc: 0.73\n",
      "=================== 230 / 1000 epoch ===================\n",
      "Train  loss: 0.5397, acc: 0.79\n",
      "Valid  loss: 0.6065, acc: 0.73\n",
      "=================== 231 / 1000 epoch ===================\n",
      "Train  loss: 0.5394, acc: 0.79\n",
      "Valid  loss: 0.6063, acc: 0.73\n",
      "=================== 232 / 1000 epoch ===================\n",
      "Train  loss: 0.5390, acc: 0.79\n",
      "Valid  loss: 0.6060, acc: 0.73\n",
      "=================== 233 / 1000 epoch ===================\n",
      "Train  loss: 0.5386, acc: 0.79\n",
      "Valid  loss: 0.6058, acc: 0.73\n",
      "=================== 234 / 1000 epoch ===================\n",
      "Train  loss: 0.5382, acc: 0.80\n",
      "Valid  loss: 0.6055, acc: 0.73\n",
      "=================== 235 / 1000 epoch ===================\n",
      "Train  loss: 0.5378, acc: 0.80\n",
      "Valid  loss: 0.6052, acc: 0.73\n",
      "=================== 236 / 1000 epoch ===================\n",
      "Train  loss: 0.5374, acc: 0.80\n",
      "Valid  loss: 0.6050, acc: 0.73\n",
      "=================== 237 / 1000 epoch ===================\n",
      "Train  loss: 0.5371, acc: 0.80\n",
      "Valid  loss: 0.6047, acc: 0.73\n",
      "=================== 238 / 1000 epoch ===================\n",
      "Train  loss: 0.5367, acc: 0.80\n",
      "Valid  loss: 0.6045, acc: 0.73\n",
      "=================== 239 / 1000 epoch ===================\n",
      "Train  loss: 0.5363, acc: 0.80\n",
      "Valid  loss: 0.6042, acc: 0.73\n",
      "=================== 240 / 1000 epoch ===================\n",
      "Train  loss: 0.5359, acc: 0.80\n",
      "Valid  loss: 0.6040, acc: 0.73\n",
      "=================== 241 / 1000 epoch ===================\n",
      "Train  loss: 0.5356, acc: 0.80\n",
      "Valid  loss: 0.6037, acc: 0.73\n",
      "=================== 242 / 1000 epoch ===================\n",
      "Train  loss: 0.5352, acc: 0.80\n",
      "Valid  loss: 0.6034, acc: 0.73\n",
      "=================== 243 / 1000 epoch ===================\n",
      "Train  loss: 0.5348, acc: 0.80\n",
      "Valid  loss: 0.6032, acc: 0.73\n",
      "=================== 244 / 1000 epoch ===================\n",
      "Train  loss: 0.5345, acc: 0.80\n",
      "Valid  loss: 0.6029, acc: 0.73\n",
      "=================== 245 / 1000 epoch ===================\n",
      "Train  loss: 0.5341, acc: 0.80\n",
      "Valid  loss: 0.6027, acc: 0.73\n",
      "=================== 246 / 1000 epoch ===================\n",
      "Train  loss: 0.5337, acc: 0.80\n",
      "Valid  loss: 0.6024, acc: 0.73\n",
      "=================== 247 / 1000 epoch ===================\n",
      "Train  loss: 0.5334, acc: 0.80\n",
      "Valid  loss: 0.6022, acc: 0.73\n",
      "=================== 248 / 1000 epoch ===================\n",
      "Train  loss: 0.5330, acc: 0.80\n",
      "Valid  loss: 0.6019, acc: 0.73\n",
      "=================== 249 / 1000 epoch ===================\n",
      "Train  loss: 0.5326, acc: 0.80\n",
      "Valid  loss: 0.6017, acc: 0.73\n",
      "=================== 250 / 1000 epoch ===================\n",
      "Train  loss: 0.5323, acc: 0.80\n",
      "Valid  loss: 0.6014, acc: 0.73\n",
      "=================== 251 / 1000 epoch ===================\n",
      "Train  loss: 0.5319, acc: 0.80\n",
      "Valid  loss: 0.6012, acc: 0.73\n",
      "=================== 252 / 1000 epoch ===================\n",
      "Train  loss: 0.5315, acc: 0.80\n",
      "Valid  loss: 0.6009, acc: 0.73\n",
      "=================== 253 / 1000 epoch ===================\n",
      "Train  loss: 0.5312, acc: 0.80\n",
      "Valid  loss: 0.6007, acc: 0.73\n",
      "=================== 254 / 1000 epoch ===================\n",
      "Train  loss: 0.5308, acc: 0.80\n",
      "Valid  loss: 0.6005, acc: 0.73\n",
      "=================== 255 / 1000 epoch ===================\n",
      "Train  loss: 0.5305, acc: 0.80\n",
      "Valid  loss: 0.6002, acc: 0.73\n",
      "=================== 256 / 1000 epoch ===================\n",
      "Train  loss: 0.5301, acc: 0.80\n",
      "Valid  loss: 0.6000, acc: 0.73\n",
      "=================== 257 / 1000 epoch ===================\n",
      "Train  loss: 0.5298, acc: 0.80\n",
      "Valid  loss: 0.5997, acc: 0.73\n",
      "=================== 258 / 1000 epoch ===================\n",
      "Train  loss: 0.5294, acc: 0.80\n",
      "Valid  loss: 0.5995, acc: 0.73\n",
      "=================== 259 / 1000 epoch ===================\n",
      "Train  loss: 0.5291, acc: 0.80\n",
      "Valid  loss: 0.5992, acc: 0.73\n",
      "=================== 260 / 1000 epoch ===================\n",
      "Train  loss: 0.5287, acc: 0.80\n",
      "Valid  loss: 0.5990, acc: 0.73\n",
      "=================== 261 / 1000 epoch ===================\n",
      "Train  loss: 0.5284, acc: 0.80\n",
      "Valid  loss: 0.5988, acc: 0.73\n",
      "=================== 262 / 1000 epoch ===================\n",
      "Train  loss: 0.5280, acc: 0.80\n",
      "Valid  loss: 0.5985, acc: 0.73\n",
      "=================== 263 / 1000 epoch ===================\n",
      "Train  loss: 0.5277, acc: 0.80\n",
      "Valid  loss: 0.5983, acc: 0.73\n",
      "=================== 264 / 1000 epoch ===================\n",
      "Train  loss: 0.5274, acc: 0.80\n",
      "Valid  loss: 0.5980, acc: 0.73\n",
      "=================== 265 / 1000 epoch ===================\n",
      "Train  loss: 0.5270, acc: 0.80\n",
      "Valid  loss: 0.5978, acc: 0.73\n",
      "=================== 266 / 1000 epoch ===================\n",
      "Train  loss: 0.5267, acc: 0.80\n",
      "Valid  loss: 0.5976, acc: 0.73\n",
      "=================== 267 / 1000 epoch ===================\n",
      "Train  loss: 0.5263, acc: 0.80\n",
      "Valid  loss: 0.5973, acc: 0.73\n",
      "=================== 268 / 1000 epoch ===================\n",
      "Train  loss: 0.5260, acc: 0.80\n",
      "Valid  loss: 0.5971, acc: 0.73\n",
      "=================== 269 / 1000 epoch ===================\n",
      "Train  loss: 0.5257, acc: 0.80\n",
      "Valid  loss: 0.5969, acc: 0.73\n",
      "=================== 270 / 1000 epoch ===================\n",
      "Train  loss: 0.5253, acc: 0.80\n",
      "Valid  loss: 0.5966, acc: 0.73\n",
      "=================== 271 / 1000 epoch ===================\n",
      "Train  loss: 0.5250, acc: 0.80\n",
      "Valid  loss: 0.5964, acc: 0.73\n",
      "=================== 272 / 1000 epoch ===================\n",
      "Train  loss: 0.5247, acc: 0.80\n",
      "Valid  loss: 0.5962, acc: 0.74\n",
      "=================== 273 / 1000 epoch ===================\n",
      "Train  loss: 0.5243, acc: 0.80\n",
      "Valid  loss: 0.5959, acc: 0.74\n",
      "=================== 274 / 1000 epoch ===================\n",
      "Train  loss: 0.5240, acc: 0.80\n",
      "Valid  loss: 0.5957, acc: 0.74\n",
      "=================== 275 / 1000 epoch ===================\n",
      "Train  loss: 0.5237, acc: 0.80\n",
      "Valid  loss: 0.5955, acc: 0.74\n",
      "=================== 276 / 1000 epoch ===================\n",
      "Train  loss: 0.5233, acc: 0.80\n",
      "Valid  loss: 0.5952, acc: 0.74\n",
      "=================== 277 / 1000 epoch ===================\n",
      "Train  loss: 0.5230, acc: 0.80\n",
      "Valid  loss: 0.5950, acc: 0.74\n",
      "=================== 278 / 1000 epoch ===================\n",
      "Train  loss: 0.5227, acc: 0.80\n",
      "Valid  loss: 0.5948, acc: 0.74\n",
      "=================== 279 / 1000 epoch ===================\n",
      "Train  loss: 0.5224, acc: 0.80\n",
      "Valid  loss: 0.5945, acc: 0.74\n",
      "=================== 280 / 1000 epoch ===================\n",
      "Train  loss: 0.5220, acc: 0.80\n",
      "Valid  loss: 0.5943, acc: 0.74\n",
      "=================== 281 / 1000 epoch ===================\n",
      "Train  loss: 0.5217, acc: 0.80\n",
      "Valid  loss: 0.5941, acc: 0.74\n",
      "=================== 282 / 1000 epoch ===================\n",
      "Train  loss: 0.5214, acc: 0.80\n",
      "Valid  loss: 0.5939, acc: 0.74\n",
      "=================== 283 / 1000 epoch ===================\n",
      "Train  loss: 0.5211, acc: 0.80\n",
      "Valid  loss: 0.5936, acc: 0.74\n",
      "=================== 284 / 1000 epoch ===================\n",
      "Train  loss: 0.5208, acc: 0.80\n",
      "Valid  loss: 0.5934, acc: 0.74\n",
      "=================== 285 / 1000 epoch ===================\n",
      "Train  loss: 0.5204, acc: 0.80\n",
      "Valid  loss: 0.5932, acc: 0.74\n",
      "=================== 286 / 1000 epoch ===================\n",
      "Train  loss: 0.5201, acc: 0.80\n",
      "Valid  loss: 0.5930, acc: 0.74\n",
      "=================== 287 / 1000 epoch ===================\n",
      "Train  loss: 0.5198, acc: 0.80\n",
      "Valid  loss: 0.5927, acc: 0.74\n",
      "=================== 288 / 1000 epoch ===================\n",
      "Train  loss: 0.5195, acc: 0.80\n",
      "Valid  loss: 0.5925, acc: 0.74\n",
      "=================== 289 / 1000 epoch ===================\n",
      "Train  loss: 0.5192, acc: 0.80\n",
      "Valid  loss: 0.5923, acc: 0.74\n",
      "=================== 290 / 1000 epoch ===================\n",
      "Train  loss: 0.5189, acc: 0.80\n",
      "Valid  loss: 0.5921, acc: 0.74\n",
      "=================== 291 / 1000 epoch ===================\n",
      "Train  loss: 0.5186, acc: 0.80\n",
      "Valid  loss: 0.5919, acc: 0.74\n",
      "=================== 292 / 1000 epoch ===================\n",
      "Train  loss: 0.5182, acc: 0.80\n",
      "Valid  loss: 0.5916, acc: 0.74\n",
      "=================== 293 / 1000 epoch ===================\n",
      "Train  loss: 0.5179, acc: 0.80\n",
      "Valid  loss: 0.5914, acc: 0.74\n",
      "=================== 294 / 1000 epoch ===================\n",
      "Train  loss: 0.5176, acc: 0.80\n",
      "Valid  loss: 0.5912, acc: 0.74\n",
      "=================== 295 / 1000 epoch ===================\n",
      "Train  loss: 0.5173, acc: 0.80\n",
      "Valid  loss: 0.5910, acc: 0.74\n",
      "=================== 296 / 1000 epoch ===================\n",
      "Train  loss: 0.5170, acc: 0.80\n",
      "Valid  loss: 0.5908, acc: 0.74\n",
      "=================== 297 / 1000 epoch ===================\n",
      "Train  loss: 0.5167, acc: 0.80\n",
      "Valid  loss: 0.5905, acc: 0.74\n",
      "=================== 298 / 1000 epoch ===================\n",
      "Train  loss: 0.5164, acc: 0.80\n",
      "Valid  loss: 0.5903, acc: 0.74\n",
      "=================== 299 / 1000 epoch ===================\n",
      "Train  loss: 0.5161, acc: 0.80\n",
      "Valid  loss: 0.5901, acc: 0.74\n",
      "=================== 300 / 1000 epoch ===================\n",
      "Train  loss: 0.5158, acc: 0.80\n",
      "Valid  loss: 0.5899, acc: 0.74\n",
      "=================== 301 / 1000 epoch ===================\n",
      "Train  loss: 0.5155, acc: 0.80\n",
      "Valid  loss: 0.5897, acc: 0.74\n",
      "=================== 302 / 1000 epoch ===================\n",
      "Train  loss: 0.5152, acc: 0.80\n",
      "Valid  loss: 0.5895, acc: 0.74\n",
      "=================== 303 / 1000 epoch ===================\n",
      "Train  loss: 0.5149, acc: 0.81\n",
      "Valid  loss: 0.5892, acc: 0.74\n",
      "=================== 304 / 1000 epoch ===================\n",
      "Train  loss: 0.5146, acc: 0.81\n",
      "Valid  loss: 0.5890, acc: 0.74\n",
      "=================== 305 / 1000 epoch ===================\n",
      "Train  loss: 0.5143, acc: 0.81\n",
      "Valid  loss: 0.5888, acc: 0.74\n",
      "=================== 306 / 1000 epoch ===================\n",
      "Train  loss: 0.5140, acc: 0.81\n",
      "Valid  loss: 0.5886, acc: 0.74\n",
      "=================== 307 / 1000 epoch ===================\n",
      "Train  loss: 0.5137, acc: 0.81\n",
      "Valid  loss: 0.5884, acc: 0.74\n",
      "=================== 308 / 1000 epoch ===================\n",
      "Train  loss: 0.5134, acc: 0.81\n",
      "Valid  loss: 0.5882, acc: 0.74\n",
      "=================== 309 / 1000 epoch ===================\n",
      "Train  loss: 0.5131, acc: 0.81\n",
      "Valid  loss: 0.5880, acc: 0.74\n",
      "=================== 310 / 1000 epoch ===================\n",
      "Train  loss: 0.5128, acc: 0.81\n",
      "Valid  loss: 0.5878, acc: 0.74\n",
      "=================== 311 / 1000 epoch ===================\n",
      "Train  loss: 0.5125, acc: 0.81\n",
      "Valid  loss: 0.5876, acc: 0.74\n",
      "=================== 312 / 1000 epoch ===================\n",
      "Train  loss: 0.5123, acc: 0.81\n",
      "Valid  loss: 0.5873, acc: 0.74\n",
      "=================== 313 / 1000 epoch ===================\n",
      "Train  loss: 0.5120, acc: 0.81\n",
      "Valid  loss: 0.5871, acc: 0.74\n",
      "=================== 314 / 1000 epoch ===================\n",
      "Train  loss: 0.5117, acc: 0.81\n",
      "Valid  loss: 0.5869, acc: 0.74\n",
      "=================== 315 / 1000 epoch ===================\n",
      "Train  loss: 0.5114, acc: 0.81\n",
      "Valid  loss: 0.5867, acc: 0.74\n",
      "=================== 316 / 1000 epoch ===================\n",
      "Train  loss: 0.5111, acc: 0.81\n",
      "Valid  loss: 0.5865, acc: 0.74\n",
      "=================== 317 / 1000 epoch ===================\n",
      "Train  loss: 0.5108, acc: 0.81\n",
      "Valid  loss: 0.5863, acc: 0.74\n",
      "=================== 318 / 1000 epoch ===================\n",
      "Train  loss: 0.5105, acc: 0.81\n",
      "Valid  loss: 0.5861, acc: 0.74\n",
      "=================== 319 / 1000 epoch ===================\n",
      "Train  loss: 0.5103, acc: 0.81\n",
      "Valid  loss: 0.5859, acc: 0.74\n",
      "=================== 320 / 1000 epoch ===================\n",
      "Train  loss: 0.5100, acc: 0.81\n",
      "Valid  loss: 0.5857, acc: 0.74\n",
      "=================== 321 / 1000 epoch ===================\n",
      "Train  loss: 0.5097, acc: 0.81\n",
      "Valid  loss: 0.5855, acc: 0.74\n",
      "=================== 322 / 1000 epoch ===================\n",
      "Train  loss: 0.5094, acc: 0.81\n",
      "Valid  loss: 0.5853, acc: 0.74\n",
      "=================== 323 / 1000 epoch ===================\n",
      "Train  loss: 0.5091, acc: 0.81\n",
      "Valid  loss: 0.5851, acc: 0.74\n",
      "=================== 324 / 1000 epoch ===================\n",
      "Train  loss: 0.5089, acc: 0.81\n",
      "Valid  loss: 0.5849, acc: 0.74\n",
      "=================== 325 / 1000 epoch ===================\n",
      "Train  loss: 0.5086, acc: 0.81\n",
      "Valid  loss: 0.5847, acc: 0.74\n",
      "=================== 326 / 1000 epoch ===================\n",
      "Train  loss: 0.5083, acc: 0.81\n",
      "Valid  loss: 0.5845, acc: 0.74\n",
      "=================== 327 / 1000 epoch ===================\n",
      "Train  loss: 0.5080, acc: 0.81\n",
      "Valid  loss: 0.5843, acc: 0.74\n",
      "=================== 328 / 1000 epoch ===================\n",
      "Train  loss: 0.5078, acc: 0.81\n",
      "Valid  loss: 0.5841, acc: 0.74\n",
      "=================== 329 / 1000 epoch ===================\n",
      "Train  loss: 0.5075, acc: 0.81\n",
      "Valid  loss: 0.5839, acc: 0.74\n",
      "=================== 330 / 1000 epoch ===================\n",
      "Train  loss: 0.5072, acc: 0.81\n",
      "Valid  loss: 0.5837, acc: 0.74\n",
      "=================== 331 / 1000 epoch ===================\n",
      "Train  loss: 0.5069, acc: 0.81\n",
      "Valid  loss: 0.5835, acc: 0.74\n",
      "=================== 332 / 1000 epoch ===================\n",
      "Train  loss: 0.5067, acc: 0.81\n",
      "Valid  loss: 0.5833, acc: 0.74\n",
      "=================== 333 / 1000 epoch ===================\n",
      "Train  loss: 0.5064, acc: 0.81\n",
      "Valid  loss: 0.5831, acc: 0.74\n",
      "=================== 334 / 1000 epoch ===================\n",
      "Train  loss: 0.5061, acc: 0.81\n",
      "Valid  loss: 0.5829, acc: 0.74\n",
      "=================== 335 / 1000 epoch ===================\n",
      "Train  loss: 0.5059, acc: 0.81\n",
      "Valid  loss: 0.5827, acc: 0.74\n",
      "=================== 336 / 1000 epoch ===================\n",
      "Train  loss: 0.5056, acc: 0.81\n",
      "Valid  loss: 0.5825, acc: 0.74\n",
      "=================== 337 / 1000 epoch ===================\n",
      "Train  loss: 0.5053, acc: 0.81\n",
      "Valid  loss: 0.5823, acc: 0.74\n",
      "=================== 338 / 1000 epoch ===================\n",
      "Train  loss: 0.5051, acc: 0.81\n",
      "Valid  loss: 0.5821, acc: 0.74\n",
      "=================== 339 / 1000 epoch ===================\n",
      "Train  loss: 0.5048, acc: 0.81\n",
      "Valid  loss: 0.5819, acc: 0.74\n",
      "=================== 340 / 1000 epoch ===================\n",
      "Train  loss: 0.5045, acc: 0.81\n",
      "Valid  loss: 0.5817, acc: 0.74\n",
      "=================== 341 / 1000 epoch ===================\n",
      "Train  loss: 0.5043, acc: 0.81\n",
      "Valid  loss: 0.5815, acc: 0.74\n",
      "=================== 342 / 1000 epoch ===================\n",
      "Train  loss: 0.5040, acc: 0.81\n",
      "Valid  loss: 0.5813, acc: 0.74\n",
      "=================== 343 / 1000 epoch ===================\n",
      "Train  loss: 0.5037, acc: 0.81\n",
      "Valid  loss: 0.5811, acc: 0.74\n",
      "=================== 344 / 1000 epoch ===================\n",
      "Train  loss: 0.5035, acc: 0.81\n",
      "Valid  loss: 0.5809, acc: 0.74\n",
      "=================== 345 / 1000 epoch ===================\n",
      "Train  loss: 0.5032, acc: 0.81\n",
      "Valid  loss: 0.5807, acc: 0.74\n",
      "=================== 346 / 1000 epoch ===================\n",
      "Train  loss: 0.5030, acc: 0.81\n",
      "Valid  loss: 0.5806, acc: 0.74\n",
      "=================== 347 / 1000 epoch ===================\n",
      "Train  loss: 0.5027, acc: 0.81\n",
      "Valid  loss: 0.5804, acc: 0.74\n",
      "=================== 348 / 1000 epoch ===================\n",
      "Train  loss: 0.5024, acc: 0.81\n",
      "Valid  loss: 0.5802, acc: 0.74\n",
      "=================== 349 / 1000 epoch ===================\n",
      "Train  loss: 0.5022, acc: 0.81\n",
      "Valid  loss: 0.5800, acc: 0.74\n",
      "=================== 350 / 1000 epoch ===================\n",
      "Train  loss: 0.5019, acc: 0.81\n",
      "Valid  loss: 0.5798, acc: 0.74\n",
      "=================== 351 / 1000 epoch ===================\n",
      "Train  loss: 0.5017, acc: 0.81\n",
      "Valid  loss: 0.5796, acc: 0.74\n",
      "=================== 352 / 1000 epoch ===================\n",
      "Train  loss: 0.5014, acc: 0.81\n",
      "Valid  loss: 0.5794, acc: 0.74\n",
      "=================== 353 / 1000 epoch ===================\n",
      "Train  loss: 0.5012, acc: 0.81\n",
      "Valid  loss: 0.5792, acc: 0.74\n",
      "=================== 354 / 1000 epoch ===================\n",
      "Train  loss: 0.5009, acc: 0.81\n",
      "Valid  loss: 0.5790, acc: 0.74\n",
      "=================== 355 / 1000 epoch ===================\n",
      "Train  loss: 0.5007, acc: 0.81\n",
      "Valid  loss: 0.5788, acc: 0.74\n",
      "=================== 356 / 1000 epoch ===================\n",
      "Train  loss: 0.5004, acc: 0.81\n",
      "Valid  loss: 0.5787, acc: 0.74\n",
      "=================== 357 / 1000 epoch ===================\n",
      "Train  loss: 0.5002, acc: 0.81\n",
      "Valid  loss: 0.5785, acc: 0.74\n",
      "=================== 358 / 1000 epoch ===================\n",
      "Train  loss: 0.4999, acc: 0.81\n",
      "Valid  loss: 0.5783, acc: 0.75\n",
      "=================== 359 / 1000 epoch ===================\n",
      "Train  loss: 0.4997, acc: 0.81\n",
      "Valid  loss: 0.5781, acc: 0.75\n",
      "=================== 360 / 1000 epoch ===================\n",
      "Train  loss: 0.4994, acc: 0.81\n",
      "Valid  loss: 0.5779, acc: 0.74\n",
      "=================== 361 / 1000 epoch ===================\n",
      "Train  loss: 0.4992, acc: 0.81\n",
      "Valid  loss: 0.5777, acc: 0.74\n",
      "=================== 362 / 1000 epoch ===================\n",
      "Train  loss: 0.4989, acc: 0.81\n",
      "Valid  loss: 0.5776, acc: 0.75\n",
      "=================== 363 / 1000 epoch ===================\n",
      "Train  loss: 0.4987, acc: 0.81\n",
      "Valid  loss: 0.5774, acc: 0.75\n",
      "=================== 364 / 1000 epoch ===================\n",
      "Train  loss: 0.4984, acc: 0.81\n",
      "Valid  loss: 0.5772, acc: 0.75\n",
      "=================== 365 / 1000 epoch ===================\n",
      "Train  loss: 0.4982, acc: 0.81\n",
      "Valid  loss: 0.5770, acc: 0.75\n",
      "=================== 366 / 1000 epoch ===================\n",
      "Train  loss: 0.4979, acc: 0.81\n",
      "Valid  loss: 0.5768, acc: 0.75\n",
      "=================== 367 / 1000 epoch ===================\n",
      "Train  loss: 0.4977, acc: 0.81\n",
      "Valid  loss: 0.5766, acc: 0.75\n",
      "=================== 368 / 1000 epoch ===================\n",
      "Train  loss: 0.4975, acc: 0.81\n",
      "Valid  loss: 0.5765, acc: 0.75\n",
      "=================== 369 / 1000 epoch ===================\n",
      "Train  loss: 0.4972, acc: 0.81\n",
      "Valid  loss: 0.5763, acc: 0.75\n",
      "=================== 370 / 1000 epoch ===================\n",
      "Train  loss: 0.4970, acc: 0.81\n",
      "Valid  loss: 0.5761, acc: 0.75\n",
      "=================== 371 / 1000 epoch ===================\n",
      "Train  loss: 0.4967, acc: 0.81\n",
      "Valid  loss: 0.5759, acc: 0.75\n",
      "=================== 372 / 1000 epoch ===================\n",
      "Train  loss: 0.4965, acc: 0.81\n",
      "Valid  loss: 0.5757, acc: 0.75\n",
      "=================== 373 / 1000 epoch ===================\n",
      "Train  loss: 0.4963, acc: 0.81\n",
      "Valid  loss: 0.5756, acc: 0.75\n",
      "=================== 374 / 1000 epoch ===================\n",
      "Train  loss: 0.4960, acc: 0.81\n",
      "Valid  loss: 0.5754, acc: 0.75\n",
      "=================== 375 / 1000 epoch ===================\n",
      "Train  loss: 0.4958, acc: 0.81\n",
      "Valid  loss: 0.5752, acc: 0.75\n",
      "=================== 376 / 1000 epoch ===================\n",
      "Train  loss: 0.4955, acc: 0.81\n",
      "Valid  loss: 0.5750, acc: 0.75\n",
      "=================== 377 / 1000 epoch ===================\n",
      "Train  loss: 0.4953, acc: 0.81\n",
      "Valid  loss: 0.5748, acc: 0.75\n",
      "=================== 378 / 1000 epoch ===================\n",
      "Train  loss: 0.4951, acc: 0.81\n",
      "Valid  loss: 0.5747, acc: 0.75\n",
      "=================== 379 / 1000 epoch ===================\n",
      "Train  loss: 0.4948, acc: 0.81\n",
      "Valid  loss: 0.5745, acc: 0.75\n",
      "=================== 380 / 1000 epoch ===================\n",
      "Train  loss: 0.4946, acc: 0.81\n",
      "Valid  loss: 0.5743, acc: 0.75\n",
      "=================== 381 / 1000 epoch ===================\n",
      "Train  loss: 0.4944, acc: 0.81\n",
      "Valid  loss: 0.5741, acc: 0.75\n",
      "=================== 382 / 1000 epoch ===================\n",
      "Train  loss: 0.4941, acc: 0.81\n",
      "Valid  loss: 0.5740, acc: 0.75\n",
      "=================== 383 / 1000 epoch ===================\n",
      "Train  loss: 0.4939, acc: 0.81\n",
      "Valid  loss: 0.5738, acc: 0.75\n",
      "=================== 384 / 1000 epoch ===================\n",
      "Train  loss: 0.4937, acc: 0.81\n",
      "Valid  loss: 0.5736, acc: 0.75\n",
      "=================== 385 / 1000 epoch ===================\n",
      "Train  loss: 0.4934, acc: 0.81\n",
      "Valid  loss: 0.5734, acc: 0.75\n",
      "=================== 386 / 1000 epoch ===================\n",
      "Train  loss: 0.4932, acc: 0.81\n",
      "Valid  loss: 0.5733, acc: 0.75\n",
      "=================== 387 / 1000 epoch ===================\n",
      "Train  loss: 0.4930, acc: 0.81\n",
      "Valid  loss: 0.5731, acc: 0.75\n",
      "=================== 388 / 1000 epoch ===================\n",
      "Train  loss: 0.4928, acc: 0.81\n",
      "Valid  loss: 0.5729, acc: 0.75\n",
      "=================== 389 / 1000 epoch ===================\n",
      "Train  loss: 0.4925, acc: 0.81\n",
      "Valid  loss: 0.5727, acc: 0.75\n",
      "=================== 390 / 1000 epoch ===================\n",
      "Train  loss: 0.4923, acc: 0.81\n",
      "Valid  loss: 0.5726, acc: 0.75\n",
      "=================== 391 / 1000 epoch ===================\n",
      "Train  loss: 0.4921, acc: 0.81\n",
      "Valid  loss: 0.5724, acc: 0.75\n",
      "=================== 392 / 1000 epoch ===================\n",
      "Train  loss: 0.4919, acc: 0.81\n",
      "Valid  loss: 0.5722, acc: 0.75\n",
      "=================== 393 / 1000 epoch ===================\n",
      "Train  loss: 0.4916, acc: 0.81\n",
      "Valid  loss: 0.5721, acc: 0.75\n",
      "=================== 394 / 1000 epoch ===================\n",
      "Train  loss: 0.4914, acc: 0.81\n",
      "Valid  loss: 0.5719, acc: 0.75\n",
      "=================== 395 / 1000 epoch ===================\n",
      "Train  loss: 0.4912, acc: 0.81\n",
      "Valid  loss: 0.5717, acc: 0.75\n",
      "=================== 396 / 1000 epoch ===================\n",
      "Train  loss: 0.4910, acc: 0.81\n",
      "Valid  loss: 0.5715, acc: 0.75\n",
      "=================== 397 / 1000 epoch ===================\n",
      "Train  loss: 0.4907, acc: 0.81\n",
      "Valid  loss: 0.5714, acc: 0.75\n",
      "=================== 398 / 1000 epoch ===================\n",
      "Train  loss: 0.4905, acc: 0.81\n",
      "Valid  loss: 0.5712, acc: 0.75\n",
      "=================== 399 / 1000 epoch ===================\n",
      "Train  loss: 0.4903, acc: 0.81\n",
      "Valid  loss: 0.5710, acc: 0.75\n",
      "=================== 400 / 1000 epoch ===================\n",
      "Train  loss: 0.4901, acc: 0.81\n",
      "Valid  loss: 0.5709, acc: 0.75\n",
      "=================== 401 / 1000 epoch ===================\n",
      "Train  loss: 0.4899, acc: 0.81\n",
      "Valid  loss: 0.5707, acc: 0.75\n",
      "=================== 402 / 1000 epoch ===================\n",
      "Train  loss: 0.4896, acc: 0.81\n",
      "Valid  loss: 0.5705, acc: 0.75\n",
      "=================== 403 / 1000 epoch ===================\n",
      "Train  loss: 0.4894, acc: 0.81\n",
      "Valid  loss: 0.5704, acc: 0.75\n",
      "=================== 404 / 1000 epoch ===================\n",
      "Train  loss: 0.4892, acc: 0.81\n",
      "Valid  loss: 0.5702, acc: 0.75\n",
      "=================== 405 / 1000 epoch ===================\n",
      "Train  loss: 0.4890, acc: 0.81\n",
      "Valid  loss: 0.5700, acc: 0.75\n",
      "=================== 406 / 1000 epoch ===================\n",
      "Train  loss: 0.4888, acc: 0.81\n",
      "Valid  loss: 0.5699, acc: 0.75\n",
      "=================== 407 / 1000 epoch ===================\n",
      "Train  loss: 0.4886, acc: 0.81\n",
      "Valid  loss: 0.5697, acc: 0.75\n",
      "=================== 408 / 1000 epoch ===================\n",
      "Train  loss: 0.4883, acc: 0.81\n",
      "Valid  loss: 0.5695, acc: 0.75\n",
      "=================== 409 / 1000 epoch ===================\n",
      "Train  loss: 0.4881, acc: 0.81\n",
      "Valid  loss: 0.5694, acc: 0.75\n",
      "=================== 410 / 1000 epoch ===================\n",
      "Train  loss: 0.4879, acc: 0.81\n",
      "Valid  loss: 0.5692, acc: 0.75\n",
      "=================== 411 / 1000 epoch ===================\n",
      "Train  loss: 0.4877, acc: 0.81\n",
      "Valid  loss: 0.5690, acc: 0.75\n",
      "=================== 412 / 1000 epoch ===================\n",
      "Train  loss: 0.4875, acc: 0.81\n",
      "Valid  loss: 0.5689, acc: 0.75\n",
      "=================== 413 / 1000 epoch ===================\n",
      "Train  loss: 0.4873, acc: 0.81\n",
      "Valid  loss: 0.5687, acc: 0.75\n",
      "=================== 414 / 1000 epoch ===================\n",
      "Train  loss: 0.4871, acc: 0.81\n",
      "Valid  loss: 0.5686, acc: 0.75\n",
      "=================== 415 / 1000 epoch ===================\n",
      "Train  loss: 0.4869, acc: 0.81\n",
      "Valid  loss: 0.5684, acc: 0.75\n",
      "=================== 416 / 1000 epoch ===================\n",
      "Train  loss: 0.4866, acc: 0.81\n",
      "Valid  loss: 0.5682, acc: 0.75\n",
      "=================== 417 / 1000 epoch ===================\n",
      "Train  loss: 0.4864, acc: 0.81\n",
      "Valid  loss: 0.5681, acc: 0.75\n",
      "=================== 418 / 1000 epoch ===================\n",
      "Train  loss: 0.4862, acc: 0.81\n",
      "Valid  loss: 0.5679, acc: 0.75\n",
      "=================== 419 / 1000 epoch ===================\n",
      "Train  loss: 0.4860, acc: 0.81\n",
      "Valid  loss: 0.5677, acc: 0.75\n",
      "=================== 420 / 1000 epoch ===================\n",
      "Train  loss: 0.4858, acc: 0.81\n",
      "Valid  loss: 0.5676, acc: 0.75\n",
      "=================== 421 / 1000 epoch ===================\n",
      "Train  loss: 0.4856, acc: 0.81\n",
      "Valid  loss: 0.5674, acc: 0.75\n",
      "=================== 422 / 1000 epoch ===================\n",
      "Train  loss: 0.4854, acc: 0.81\n",
      "Valid  loss: 0.5673, acc: 0.75\n",
      "=================== 423 / 1000 epoch ===================\n",
      "Train  loss: 0.4852, acc: 0.81\n",
      "Valid  loss: 0.5671, acc: 0.75\n",
      "=================== 424 / 1000 epoch ===================\n",
      "Train  loss: 0.4850, acc: 0.81\n",
      "Valid  loss: 0.5669, acc: 0.75\n",
      "=================== 425 / 1000 epoch ===================\n",
      "Train  loss: 0.4848, acc: 0.81\n",
      "Valid  loss: 0.5668, acc: 0.75\n",
      "=================== 426 / 1000 epoch ===================\n",
      "Train  loss: 0.4846, acc: 0.81\n",
      "Valid  loss: 0.5666, acc: 0.75\n",
      "=================== 427 / 1000 epoch ===================\n",
      "Train  loss: 0.4844, acc: 0.81\n",
      "Valid  loss: 0.5665, acc: 0.75\n",
      "=================== 428 / 1000 epoch ===================\n",
      "Train  loss: 0.4842, acc: 0.81\n",
      "Valid  loss: 0.5663, acc: 0.76\n",
      "=================== 429 / 1000 epoch ===================\n",
      "Train  loss: 0.4840, acc: 0.81\n",
      "Valid  loss: 0.5662, acc: 0.76\n",
      "=================== 430 / 1000 epoch ===================\n",
      "Train  loss: 0.4838, acc: 0.81\n",
      "Valid  loss: 0.5660, acc: 0.76\n",
      "=================== 431 / 1000 epoch ===================\n",
      "Train  loss: 0.4836, acc: 0.81\n",
      "Valid  loss: 0.5658, acc: 0.76\n",
      "=================== 432 / 1000 epoch ===================\n",
      "Train  loss: 0.4834, acc: 0.81\n",
      "Valid  loss: 0.5657, acc: 0.76\n",
      "=================== 433 / 1000 epoch ===================\n",
      "Train  loss: 0.4832, acc: 0.81\n",
      "Valid  loss: 0.5655, acc: 0.76\n",
      "=================== 434 / 1000 epoch ===================\n",
      "Train  loss: 0.4830, acc: 0.81\n",
      "Valid  loss: 0.5654, acc: 0.76\n",
      "=================== 435 / 1000 epoch ===================\n",
      "Train  loss: 0.4828, acc: 0.81\n",
      "Valid  loss: 0.5652, acc: 0.76\n",
      "=================== 436 / 1000 epoch ===================\n",
      "Train  loss: 0.4826, acc: 0.81\n",
      "Valid  loss: 0.5651, acc: 0.76\n",
      "=================== 437 / 1000 epoch ===================\n",
      "Train  loss: 0.4824, acc: 0.81\n",
      "Valid  loss: 0.5649, acc: 0.76\n",
      "=================== 438 / 1000 epoch ===================\n",
      "Train  loss: 0.4822, acc: 0.81\n",
      "Valid  loss: 0.5648, acc: 0.76\n",
      "=================== 439 / 1000 epoch ===================\n",
      "Train  loss: 0.4820, acc: 0.81\n",
      "Valid  loss: 0.5646, acc: 0.76\n",
      "=================== 440 / 1000 epoch ===================\n",
      "Train  loss: 0.4818, acc: 0.81\n",
      "Valid  loss: 0.5645, acc: 0.76\n",
      "=================== 441 / 1000 epoch ===================\n",
      "Train  loss: 0.4816, acc: 0.81\n",
      "Valid  loss: 0.5643, acc: 0.76\n",
      "=================== 442 / 1000 epoch ===================\n",
      "Train  loss: 0.4814, acc: 0.81\n",
      "Valid  loss: 0.5641, acc: 0.76\n",
      "=================== 443 / 1000 epoch ===================\n",
      "Train  loss: 0.4812, acc: 0.81\n",
      "Valid  loss: 0.5640, acc: 0.76\n",
      "=================== 444 / 1000 epoch ===================\n",
      "Train  loss: 0.4810, acc: 0.81\n",
      "Valid  loss: 0.5638, acc: 0.76\n",
      "=================== 445 / 1000 epoch ===================\n",
      "Train  loss: 0.4808, acc: 0.81\n",
      "Valid  loss: 0.5637, acc: 0.76\n",
      "=================== 446 / 1000 epoch ===================\n",
      "Train  loss: 0.4806, acc: 0.81\n",
      "Valid  loss: 0.5635, acc: 0.76\n",
      "=================== 447 / 1000 epoch ===================\n",
      "Train  loss: 0.4804, acc: 0.81\n",
      "Valid  loss: 0.5634, acc: 0.76\n",
      "=================== 448 / 1000 epoch ===================\n",
      "Train  loss: 0.4802, acc: 0.81\n",
      "Valid  loss: 0.5632, acc: 0.76\n",
      "=================== 449 / 1000 epoch ===================\n",
      "Train  loss: 0.4800, acc: 0.81\n",
      "Valid  loss: 0.5631, acc: 0.76\n",
      "=================== 450 / 1000 epoch ===================\n",
      "Train  loss: 0.4799, acc: 0.81\n",
      "Valid  loss: 0.5629, acc: 0.76\n",
      "=================== 451 / 1000 epoch ===================\n",
      "Train  loss: 0.4797, acc: 0.81\n",
      "Valid  loss: 0.5628, acc: 0.76\n",
      "=================== 452 / 1000 epoch ===================\n",
      "Train  loss: 0.4795, acc: 0.82\n",
      "Valid  loss: 0.5626, acc: 0.76\n",
      "=================== 453 / 1000 epoch ===================\n",
      "Train  loss: 0.4793, acc: 0.82\n",
      "Valid  loss: 0.5625, acc: 0.76\n",
      "=================== 454 / 1000 epoch ===================\n",
      "Train  loss: 0.4791, acc: 0.82\n",
      "Valid  loss: 0.5623, acc: 0.76\n",
      "=================== 455 / 1000 epoch ===================\n",
      "Train  loss: 0.4789, acc: 0.82\n",
      "Valid  loss: 0.5622, acc: 0.76\n",
      "=================== 456 / 1000 epoch ===================\n",
      "Train  loss: 0.4787, acc: 0.82\n",
      "Valid  loss: 0.5620, acc: 0.76\n",
      "=================== 457 / 1000 epoch ===================\n",
      "Train  loss: 0.4785, acc: 0.82\n",
      "Valid  loss: 0.5619, acc: 0.76\n",
      "=================== 458 / 1000 epoch ===================\n",
      "Train  loss: 0.4783, acc: 0.82\n",
      "Valid  loss: 0.5617, acc: 0.76\n",
      "=================== 459 / 1000 epoch ===================\n",
      "Train  loss: 0.4782, acc: 0.82\n",
      "Valid  loss: 0.5616, acc: 0.76\n",
      "=================== 460 / 1000 epoch ===================\n",
      "Train  loss: 0.4780, acc: 0.82\n",
      "Valid  loss: 0.5614, acc: 0.76\n",
      "=================== 461 / 1000 epoch ===================\n",
      "Train  loss: 0.4778, acc: 0.82\n",
      "Valid  loss: 0.5613, acc: 0.76\n",
      "=================== 462 / 1000 epoch ===================\n",
      "Train  loss: 0.4776, acc: 0.82\n",
      "Valid  loss: 0.5612, acc: 0.76\n",
      "=================== 463 / 1000 epoch ===================\n",
      "Train  loss: 0.4774, acc: 0.82\n",
      "Valid  loss: 0.5610, acc: 0.76\n",
      "=================== 464 / 1000 epoch ===================\n",
      "Train  loss: 0.4772, acc: 0.82\n",
      "Valid  loss: 0.5609, acc: 0.76\n",
      "=================== 465 / 1000 epoch ===================\n",
      "Train  loss: 0.4771, acc: 0.82\n",
      "Valid  loss: 0.5607, acc: 0.76\n",
      "=================== 466 / 1000 epoch ===================\n",
      "Train  loss: 0.4769, acc: 0.82\n",
      "Valid  loss: 0.5606, acc: 0.76\n",
      "=================== 467 / 1000 epoch ===================\n",
      "Train  loss: 0.4767, acc: 0.82\n",
      "Valid  loss: 0.5604, acc: 0.76\n",
      "=================== 468 / 1000 epoch ===================\n",
      "Train  loss: 0.4765, acc: 0.82\n",
      "Valid  loss: 0.5603, acc: 0.76\n",
      "=================== 469 / 1000 epoch ===================\n",
      "Train  loss: 0.4763, acc: 0.82\n",
      "Valid  loss: 0.5601, acc: 0.76\n",
      "=================== 470 / 1000 epoch ===================\n",
      "Train  loss: 0.4761, acc: 0.82\n",
      "Valid  loss: 0.5600, acc: 0.76\n",
      "=================== 471 / 1000 epoch ===================\n",
      "Train  loss: 0.4760, acc: 0.82\n",
      "Valid  loss: 0.5599, acc: 0.76\n",
      "=================== 472 / 1000 epoch ===================\n",
      "Train  loss: 0.4758, acc: 0.82\n",
      "Valid  loss: 0.5597, acc: 0.76\n",
      "=================== 473 / 1000 epoch ===================\n",
      "Train  loss: 0.4756, acc: 0.82\n",
      "Valid  loss: 0.5596, acc: 0.76\n",
      "=================== 474 / 1000 epoch ===================\n",
      "Train  loss: 0.4754, acc: 0.82\n",
      "Valid  loss: 0.5594, acc: 0.76\n",
      "=================== 475 / 1000 epoch ===================\n",
      "Train  loss: 0.4752, acc: 0.82\n",
      "Valid  loss: 0.5593, acc: 0.76\n",
      "=================== 476 / 1000 epoch ===================\n",
      "Train  loss: 0.4751, acc: 0.82\n",
      "Valid  loss: 0.5591, acc: 0.76\n",
      "=================== 477 / 1000 epoch ===================\n",
      "Train  loss: 0.4749, acc: 0.82\n",
      "Valid  loss: 0.5590, acc: 0.76\n",
      "=================== 478 / 1000 epoch ===================\n",
      "Train  loss: 0.4747, acc: 0.82\n",
      "Valid  loss: 0.5589, acc: 0.76\n",
      "=================== 479 / 1000 epoch ===================\n",
      "Train  loss: 0.4745, acc: 0.82\n",
      "Valid  loss: 0.5587, acc: 0.76\n",
      "=================== 480 / 1000 epoch ===================\n",
      "Train  loss: 0.4744, acc: 0.82\n",
      "Valid  loss: 0.5586, acc: 0.76\n",
      "=================== 481 / 1000 epoch ===================\n",
      "Train  loss: 0.4742, acc: 0.82\n",
      "Valid  loss: 0.5584, acc: 0.76\n",
      "=================== 482 / 1000 epoch ===================\n",
      "Train  loss: 0.4740, acc: 0.82\n",
      "Valid  loss: 0.5583, acc: 0.76\n",
      "=================== 483 / 1000 epoch ===================\n",
      "Train  loss: 0.4738, acc: 0.82\n",
      "Valid  loss: 0.5582, acc: 0.76\n",
      "=================== 484 / 1000 epoch ===================\n",
      "Train  loss: 0.4737, acc: 0.82\n",
      "Valid  loss: 0.5580, acc: 0.76\n",
      "=================== 485 / 1000 epoch ===================\n",
      "Train  loss: 0.4735, acc: 0.82\n",
      "Valid  loss: 0.5579, acc: 0.76\n",
      "=================== 486 / 1000 epoch ===================\n",
      "Train  loss: 0.4733, acc: 0.82\n",
      "Valid  loss: 0.5577, acc: 0.76\n",
      "=================== 487 / 1000 epoch ===================\n",
      "Train  loss: 0.4731, acc: 0.82\n",
      "Valid  loss: 0.5576, acc: 0.76\n",
      "=================== 488 / 1000 epoch ===================\n",
      "Train  loss: 0.4730, acc: 0.82\n",
      "Valid  loss: 0.5575, acc: 0.76\n",
      "=================== 489 / 1000 epoch ===================\n",
      "Train  loss: 0.4728, acc: 0.82\n",
      "Valid  loss: 0.5573, acc: 0.76\n",
      "=================== 490 / 1000 epoch ===================\n",
      "Train  loss: 0.4726, acc: 0.82\n",
      "Valid  loss: 0.5572, acc: 0.76\n",
      "=================== 491 / 1000 epoch ===================\n",
      "Train  loss: 0.4725, acc: 0.82\n",
      "Valid  loss: 0.5570, acc: 0.76\n",
      "=================== 492 / 1000 epoch ===================\n",
      "Train  loss: 0.4723, acc: 0.82\n",
      "Valid  loss: 0.5569, acc: 0.76\n",
      "=================== 493 / 1000 epoch ===================\n",
      "Train  loss: 0.4721, acc: 0.82\n",
      "Valid  loss: 0.5568, acc: 0.76\n",
      "=================== 494 / 1000 epoch ===================\n",
      "Train  loss: 0.4719, acc: 0.82\n",
      "Valid  loss: 0.5566, acc: 0.76\n",
      "=================== 495 / 1000 epoch ===================\n",
      "Train  loss: 0.4718, acc: 0.82\n",
      "Valid  loss: 0.5565, acc: 0.76\n",
      "=================== 496 / 1000 epoch ===================\n",
      "Train  loss: 0.4716, acc: 0.82\n",
      "Valid  loss: 0.5564, acc: 0.76\n",
      "=================== 497 / 1000 epoch ===================\n",
      "Train  loss: 0.4714, acc: 0.82\n",
      "Valid  loss: 0.5562, acc: 0.76\n",
      "=================== 498 / 1000 epoch ===================\n",
      "Train  loss: 0.4713, acc: 0.82\n",
      "Valid  loss: 0.5561, acc: 0.76\n",
      "=================== 499 / 1000 epoch ===================\n",
      "Train  loss: 0.4711, acc: 0.82\n",
      "Valid  loss: 0.5559, acc: 0.76\n",
      "=================== 500 / 1000 epoch ===================\n",
      "Train  loss: 0.4709, acc: 0.82\n",
      "Valid  loss: 0.5558, acc: 0.76\n",
      "=================== 501 / 1000 epoch ===================\n",
      "Train  loss: 0.4708, acc: 0.82\n",
      "Valid  loss: 0.5557, acc: 0.76\n",
      "=================== 502 / 1000 epoch ===================\n",
      "Train  loss: 0.4706, acc: 0.82\n",
      "Valid  loss: 0.5555, acc: 0.76\n",
      "=================== 503 / 1000 epoch ===================\n",
      "Train  loss: 0.4704, acc: 0.82\n",
      "Valid  loss: 0.5554, acc: 0.76\n",
      "=================== 504 / 1000 epoch ===================\n",
      "Train  loss: 0.4703, acc: 0.82\n",
      "Valid  loss: 0.5553, acc: 0.76\n",
      "=================== 505 / 1000 epoch ===================\n",
      "Train  loss: 0.4701, acc: 0.82\n",
      "Valid  loss: 0.5551, acc: 0.76\n",
      "=================== 506 / 1000 epoch ===================\n",
      "Train  loss: 0.4699, acc: 0.82\n",
      "Valid  loss: 0.5550, acc: 0.76\n",
      "=================== 507 / 1000 epoch ===================\n",
      "Train  loss: 0.4698, acc: 0.82\n",
      "Valid  loss: 0.5549, acc: 0.76\n",
      "=================== 508 / 1000 epoch ===================\n",
      "Train  loss: 0.4696, acc: 0.82\n",
      "Valid  loss: 0.5547, acc: 0.76\n",
      "=================== 509 / 1000 epoch ===================\n",
      "Train  loss: 0.4694, acc: 0.82\n",
      "Valid  loss: 0.5546, acc: 0.76\n",
      "=================== 510 / 1000 epoch ===================\n",
      "Train  loss: 0.4693, acc: 0.82\n",
      "Valid  loss: 0.5545, acc: 0.76\n",
      "=================== 511 / 1000 epoch ===================\n",
      "Train  loss: 0.4691, acc: 0.82\n",
      "Valid  loss: 0.5543, acc: 0.76\n",
      "=================== 512 / 1000 epoch ===================\n",
      "Train  loss: 0.4690, acc: 0.82\n",
      "Valid  loss: 0.5542, acc: 0.76\n",
      "=================== 513 / 1000 epoch ===================\n",
      "Train  loss: 0.4688, acc: 0.82\n",
      "Valid  loss: 0.5541, acc: 0.76\n",
      "=================== 514 / 1000 epoch ===================\n",
      "Train  loss: 0.4686, acc: 0.82\n",
      "Valid  loss: 0.5540, acc: 0.76\n",
      "=================== 515 / 1000 epoch ===================\n",
      "Train  loss: 0.4685, acc: 0.82\n",
      "Valid  loss: 0.5538, acc: 0.76\n",
      "=================== 516 / 1000 epoch ===================\n",
      "Train  loss: 0.4683, acc: 0.82\n",
      "Valid  loss: 0.5537, acc: 0.76\n",
      "=================== 517 / 1000 epoch ===================\n",
      "Train  loss: 0.4682, acc: 0.82\n",
      "Valid  loss: 0.5536, acc: 0.76\n",
      "=================== 518 / 1000 epoch ===================\n",
      "Train  loss: 0.4680, acc: 0.82\n",
      "Valid  loss: 0.5534, acc: 0.76\n",
      "=================== 519 / 1000 epoch ===================\n",
      "Train  loss: 0.4678, acc: 0.82\n",
      "Valid  loss: 0.5533, acc: 0.76\n",
      "=================== 520 / 1000 epoch ===================\n",
      "Train  loss: 0.4677, acc: 0.82\n",
      "Valid  loss: 0.5532, acc: 0.76\n",
      "=================== 521 / 1000 epoch ===================\n",
      "Train  loss: 0.4675, acc: 0.82\n",
      "Valid  loss: 0.5530, acc: 0.76\n",
      "=================== 522 / 1000 epoch ===================\n",
      "Train  loss: 0.4674, acc: 0.82\n",
      "Valid  loss: 0.5529, acc: 0.76\n",
      "=================== 523 / 1000 epoch ===================\n",
      "Train  loss: 0.4672, acc: 0.82\n",
      "Valid  loss: 0.5528, acc: 0.76\n",
      "=================== 524 / 1000 epoch ===================\n",
      "Train  loss: 0.4670, acc: 0.82\n",
      "Valid  loss: 0.5527, acc: 0.76\n",
      "=================== 525 / 1000 epoch ===================\n",
      "Train  loss: 0.4669, acc: 0.82\n",
      "Valid  loss: 0.5525, acc: 0.76\n",
      "=================== 526 / 1000 epoch ===================\n",
      "Train  loss: 0.4667, acc: 0.82\n",
      "Valid  loss: 0.5524, acc: 0.76\n",
      "=================== 527 / 1000 epoch ===================\n",
      "Train  loss: 0.4666, acc: 0.82\n",
      "Valid  loss: 0.5523, acc: 0.76\n",
      "=================== 528 / 1000 epoch ===================\n",
      "Train  loss: 0.4664, acc: 0.82\n",
      "Valid  loss: 0.5521, acc: 0.76\n",
      "=================== 529 / 1000 epoch ===================\n",
      "Train  loss: 0.4663, acc: 0.82\n",
      "Valid  loss: 0.5520, acc: 0.76\n",
      "=================== 530 / 1000 epoch ===================\n",
      "Train  loss: 0.4661, acc: 0.82\n",
      "Valid  loss: 0.5519, acc: 0.76\n",
      "=================== 531 / 1000 epoch ===================\n",
      "Train  loss: 0.4660, acc: 0.82\n",
      "Valid  loss: 0.5518, acc: 0.76\n",
      "=================== 532 / 1000 epoch ===================\n",
      "Train  loss: 0.4658, acc: 0.82\n",
      "Valid  loss: 0.5516, acc: 0.76\n",
      "=================== 533 / 1000 epoch ===================\n",
      "Train  loss: 0.4657, acc: 0.82\n",
      "Valid  loss: 0.5515, acc: 0.76\n",
      "=================== 534 / 1000 epoch ===================\n",
      "Train  loss: 0.4655, acc: 0.82\n",
      "Valid  loss: 0.5514, acc: 0.76\n",
      "=================== 535 / 1000 epoch ===================\n",
      "Train  loss: 0.4653, acc: 0.82\n",
      "Valid  loss: 0.5513, acc: 0.76\n",
      "=================== 536 / 1000 epoch ===================\n",
      "Train  loss: 0.4652, acc: 0.82\n",
      "Valid  loss: 0.5511, acc: 0.76\n",
      "=================== 537 / 1000 epoch ===================\n",
      "Train  loss: 0.4650, acc: 0.82\n",
      "Valid  loss: 0.5510, acc: 0.76\n",
      "=================== 538 / 1000 epoch ===================\n",
      "Train  loss: 0.4649, acc: 0.82\n",
      "Valid  loss: 0.5509, acc: 0.76\n",
      "=================== 539 / 1000 epoch ===================\n",
      "Train  loss: 0.4647, acc: 0.82\n",
      "Valid  loss: 0.5508, acc: 0.76\n",
      "=================== 540 / 1000 epoch ===================\n",
      "Train  loss: 0.4646, acc: 0.82\n",
      "Valid  loss: 0.5506, acc: 0.76\n",
      "=================== 541 / 1000 epoch ===================\n",
      "Train  loss: 0.4644, acc: 0.82\n",
      "Valid  loss: 0.5505, acc: 0.76\n",
      "=================== 542 / 1000 epoch ===================\n",
      "Train  loss: 0.4643, acc: 0.82\n",
      "Valid  loss: 0.5504, acc: 0.76\n",
      "=================== 543 / 1000 epoch ===================\n",
      "Train  loss: 0.4641, acc: 0.82\n",
      "Valid  loss: 0.5503, acc: 0.76\n",
      "=================== 544 / 1000 epoch ===================\n",
      "Train  loss: 0.4640, acc: 0.82\n",
      "Valid  loss: 0.5501, acc: 0.76\n",
      "=================== 545 / 1000 epoch ===================\n",
      "Train  loss: 0.4638, acc: 0.82\n",
      "Valid  loss: 0.5500, acc: 0.76\n",
      "=================== 546 / 1000 epoch ===================\n",
      "Train  loss: 0.4637, acc: 0.82\n",
      "Valid  loss: 0.5499, acc: 0.76\n",
      "=================== 547 / 1000 epoch ===================\n",
      "Train  loss: 0.4635, acc: 0.82\n",
      "Valid  loss: 0.5498, acc: 0.76\n",
      "=================== 548 / 1000 epoch ===================\n",
      "Train  loss: 0.4634, acc: 0.82\n",
      "Valid  loss: 0.5496, acc: 0.76\n",
      "=================== 549 / 1000 epoch ===================\n",
      "Train  loss: 0.4632, acc: 0.82\n",
      "Valid  loss: 0.5495, acc: 0.76\n",
      "=================== 550 / 1000 epoch ===================\n",
      "Train  loss: 0.4631, acc: 0.82\n",
      "Valid  loss: 0.5494, acc: 0.76\n",
      "=================== 551 / 1000 epoch ===================\n",
      "Train  loss: 0.4629, acc: 0.82\n",
      "Valid  loss: 0.5493, acc: 0.76\n",
      "=================== 552 / 1000 epoch ===================\n",
      "Train  loss: 0.4628, acc: 0.82\n",
      "Valid  loss: 0.5491, acc: 0.76\n",
      "=================== 553 / 1000 epoch ===================\n",
      "Train  loss: 0.4627, acc: 0.82\n",
      "Valid  loss: 0.5490, acc: 0.76\n",
      "=================== 554 / 1000 epoch ===================\n",
      "Train  loss: 0.4625, acc: 0.82\n",
      "Valid  loss: 0.5489, acc: 0.76\n",
      "=================== 555 / 1000 epoch ===================\n",
      "Train  loss: 0.4624, acc: 0.82\n",
      "Valid  loss: 0.5488, acc: 0.76\n",
      "=================== 556 / 1000 epoch ===================\n",
      "Train  loss: 0.4622, acc: 0.82\n",
      "Valid  loss: 0.5487, acc: 0.76\n",
      "=================== 557 / 1000 epoch ===================\n",
      "Train  loss: 0.4621, acc: 0.82\n",
      "Valid  loss: 0.5485, acc: 0.76\n",
      "=================== 558 / 1000 epoch ===================\n",
      "Train  loss: 0.4619, acc: 0.82\n",
      "Valid  loss: 0.5484, acc: 0.76\n",
      "=================== 559 / 1000 epoch ===================\n",
      "Train  loss: 0.4618, acc: 0.82\n",
      "Valid  loss: 0.5483, acc: 0.76\n",
      "=================== 560 / 1000 epoch ===================\n",
      "Train  loss: 0.4616, acc: 0.82\n",
      "Valid  loss: 0.5482, acc: 0.76\n",
      "=================== 561 / 1000 epoch ===================\n",
      "Train  loss: 0.4615, acc: 0.82\n",
      "Valid  loss: 0.5481, acc: 0.76\n",
      "=================== 562 / 1000 epoch ===================\n",
      "Train  loss: 0.4613, acc: 0.82\n",
      "Valid  loss: 0.5479, acc: 0.76\n",
      "=================== 563 / 1000 epoch ===================\n",
      "Train  loss: 0.4612, acc: 0.82\n",
      "Valid  loss: 0.5478, acc: 0.76\n",
      "=================== 564 / 1000 epoch ===================\n",
      "Train  loss: 0.4611, acc: 0.82\n",
      "Valid  loss: 0.5477, acc: 0.76\n",
      "=================== 565 / 1000 epoch ===================\n",
      "Train  loss: 0.4609, acc: 0.82\n",
      "Valid  loss: 0.5476, acc: 0.76\n",
      "=================== 566 / 1000 epoch ===================\n",
      "Train  loss: 0.4608, acc: 0.82\n",
      "Valid  loss: 0.5475, acc: 0.76\n",
      "=================== 567 / 1000 epoch ===================\n",
      "Train  loss: 0.4606, acc: 0.82\n",
      "Valid  loss: 0.5473, acc: 0.76\n",
      "=================== 568 / 1000 epoch ===================\n",
      "Train  loss: 0.4605, acc: 0.82\n",
      "Valid  loss: 0.5472, acc: 0.76\n",
      "=================== 569 / 1000 epoch ===================\n",
      "Train  loss: 0.4604, acc: 0.82\n",
      "Valid  loss: 0.5471, acc: 0.76\n",
      "=================== 570 / 1000 epoch ===================\n",
      "Train  loss: 0.4602, acc: 0.82\n",
      "Valid  loss: 0.5470, acc: 0.76\n",
      "=================== 571 / 1000 epoch ===================\n",
      "Train  loss: 0.4601, acc: 0.82\n",
      "Valid  loss: 0.5469, acc: 0.76\n",
      "=================== 572 / 1000 epoch ===================\n",
      "Train  loss: 0.4599, acc: 0.82\n",
      "Valid  loss: 0.5468, acc: 0.76\n",
      "=================== 573 / 1000 epoch ===================\n",
      "Train  loss: 0.4598, acc: 0.82\n",
      "Valid  loss: 0.5466, acc: 0.76\n",
      "=================== 574 / 1000 epoch ===================\n",
      "Train  loss: 0.4597, acc: 0.82\n",
      "Valid  loss: 0.5465, acc: 0.76\n",
      "=================== 575 / 1000 epoch ===================\n",
      "Train  loss: 0.4595, acc: 0.82\n",
      "Valid  loss: 0.5464, acc: 0.76\n",
      "=================== 576 / 1000 epoch ===================\n",
      "Train  loss: 0.4594, acc: 0.82\n",
      "Valid  loss: 0.5463, acc: 0.76\n",
      "=================== 577 / 1000 epoch ===================\n",
      "Train  loss: 0.4592, acc: 0.82\n",
      "Valid  loss: 0.5462, acc: 0.76\n",
      "=================== 578 / 1000 epoch ===================\n",
      "Train  loss: 0.4591, acc: 0.82\n",
      "Valid  loss: 0.5461, acc: 0.76\n",
      "=================== 579 / 1000 epoch ===================\n",
      "Train  loss: 0.4590, acc: 0.82\n",
      "Valid  loss: 0.5459, acc: 0.76\n",
      "=================== 580 / 1000 epoch ===================\n",
      "Train  loss: 0.4588, acc: 0.82\n",
      "Valid  loss: 0.5458, acc: 0.76\n",
      "=================== 581 / 1000 epoch ===================\n",
      "Train  loss: 0.4587, acc: 0.82\n",
      "Valid  loss: 0.5457, acc: 0.76\n",
      "=================== 582 / 1000 epoch ===================\n",
      "Train  loss: 0.4586, acc: 0.82\n",
      "Valid  loss: 0.5456, acc: 0.76\n",
      "=================== 583 / 1000 epoch ===================\n",
      "Train  loss: 0.4584, acc: 0.82\n",
      "Valid  loss: 0.5455, acc: 0.76\n",
      "=================== 584 / 1000 epoch ===================\n",
      "Train  loss: 0.4583, acc: 0.82\n",
      "Valid  loss: 0.5454, acc: 0.76\n",
      "=================== 585 / 1000 epoch ===================\n",
      "Train  loss: 0.4581, acc: 0.82\n",
      "Valid  loss: 0.5453, acc: 0.76\n",
      "=================== 586 / 1000 epoch ===================\n",
      "Train  loss: 0.4580, acc: 0.82\n",
      "Valid  loss: 0.5451, acc: 0.76\n",
      "=================== 587 / 1000 epoch ===================\n",
      "Train  loss: 0.4579, acc: 0.82\n",
      "Valid  loss: 0.5450, acc: 0.77\n",
      "=================== 588 / 1000 epoch ===================\n",
      "Train  loss: 0.4577, acc: 0.82\n",
      "Valid  loss: 0.5449, acc: 0.77\n",
      "=================== 589 / 1000 epoch ===================\n",
      "Train  loss: 0.4576, acc: 0.82\n",
      "Valid  loss: 0.5448, acc: 0.77\n",
      "=================== 590 / 1000 epoch ===================\n",
      "Train  loss: 0.4575, acc: 0.82\n",
      "Valid  loss: 0.5447, acc: 0.77\n",
      "=================== 591 / 1000 epoch ===================\n",
      "Train  loss: 0.4573, acc: 0.82\n",
      "Valid  loss: 0.5446, acc: 0.77\n",
      "=================== 592 / 1000 epoch ===================\n",
      "Train  loss: 0.4572, acc: 0.82\n",
      "Valid  loss: 0.5445, acc: 0.77\n",
      "=================== 593 / 1000 epoch ===================\n",
      "Train  loss: 0.4571, acc: 0.82\n",
      "Valid  loss: 0.5443, acc: 0.77\n",
      "=================== 594 / 1000 epoch ===================\n",
      "Train  loss: 0.4569, acc: 0.82\n",
      "Valid  loss: 0.5442, acc: 0.77\n",
      "=================== 595 / 1000 epoch ===================\n",
      "Train  loss: 0.4568, acc: 0.82\n",
      "Valid  loss: 0.5441, acc: 0.77\n",
      "=================== 596 / 1000 epoch ===================\n",
      "Train  loss: 0.4567, acc: 0.82\n",
      "Valid  loss: 0.5440, acc: 0.77\n",
      "=================== 597 / 1000 epoch ===================\n",
      "Train  loss: 0.4565, acc: 0.82\n",
      "Valid  loss: 0.5439, acc: 0.77\n",
      "=================== 598 / 1000 epoch ===================\n",
      "Train  loss: 0.4564, acc: 0.82\n",
      "Valid  loss: 0.5438, acc: 0.77\n",
      "=================== 599 / 1000 epoch ===================\n",
      "Train  loss: 0.4563, acc: 0.82\n",
      "Valid  loss: 0.5437, acc: 0.77\n",
      "=================== 600 / 1000 epoch ===================\n",
      "Train  loss: 0.4561, acc: 0.82\n",
      "Valid  loss: 0.5436, acc: 0.77\n",
      "=================== 601 / 1000 epoch ===================\n",
      "Train  loss: 0.4560, acc: 0.82\n",
      "Valid  loss: 0.5435, acc: 0.77\n",
      "=================== 602 / 1000 epoch ===================\n",
      "Train  loss: 0.4559, acc: 0.82\n",
      "Valid  loss: 0.5433, acc: 0.77\n",
      "=================== 603 / 1000 epoch ===================\n",
      "Train  loss: 0.4558, acc: 0.82\n",
      "Valid  loss: 0.5432, acc: 0.77\n",
      "=================== 604 / 1000 epoch ===================\n",
      "Train  loss: 0.4556, acc: 0.82\n",
      "Valid  loss: 0.5431, acc: 0.77\n",
      "=================== 605 / 1000 epoch ===================\n",
      "Train  loss: 0.4555, acc: 0.82\n",
      "Valid  loss: 0.5430, acc: 0.76\n",
      "=================== 606 / 1000 epoch ===================\n",
      "Train  loss: 0.4554, acc: 0.82\n",
      "Valid  loss: 0.5429, acc: 0.76\n",
      "=================== 607 / 1000 epoch ===================\n",
      "Train  loss: 0.4552, acc: 0.82\n",
      "Valid  loss: 0.5428, acc: 0.76\n",
      "=================== 608 / 1000 epoch ===================\n",
      "Train  loss: 0.4551, acc: 0.82\n",
      "Valid  loss: 0.5427, acc: 0.76\n",
      "=================== 609 / 1000 epoch ===================\n",
      "Train  loss: 0.4550, acc: 0.82\n",
      "Valid  loss: 0.5426, acc: 0.76\n",
      "=================== 610 / 1000 epoch ===================\n",
      "Train  loss: 0.4548, acc: 0.82\n",
      "Valid  loss: 0.5425, acc: 0.76\n",
      "=================== 611 / 1000 epoch ===================\n",
      "Train  loss: 0.4547, acc: 0.82\n",
      "Valid  loss: 0.5424, acc: 0.76\n",
      "=================== 612 / 1000 epoch ===================\n",
      "Train  loss: 0.4546, acc: 0.82\n",
      "Valid  loss: 0.5422, acc: 0.76\n",
      "=================== 613 / 1000 epoch ===================\n",
      "Train  loss: 0.4545, acc: 0.82\n",
      "Valid  loss: 0.5421, acc: 0.76\n",
      "=================== 614 / 1000 epoch ===================\n",
      "Train  loss: 0.4543, acc: 0.82\n",
      "Valid  loss: 0.5420, acc: 0.76\n",
      "=================== 615 / 1000 epoch ===================\n",
      "Train  loss: 0.4542, acc: 0.82\n",
      "Valid  loss: 0.5419, acc: 0.76\n",
      "=================== 616 / 1000 epoch ===================\n",
      "Train  loss: 0.4541, acc: 0.82\n",
      "Valid  loss: 0.5418, acc: 0.76\n",
      "=================== 617 / 1000 epoch ===================\n",
      "Train  loss: 0.4540, acc: 0.82\n",
      "Valid  loss: 0.5417, acc: 0.76\n",
      "=================== 618 / 1000 epoch ===================\n",
      "Train  loss: 0.4538, acc: 0.82\n",
      "Valid  loss: 0.5416, acc: 0.76\n",
      "=================== 619 / 1000 epoch ===================\n",
      "Train  loss: 0.4537, acc: 0.82\n",
      "Valid  loss: 0.5415, acc: 0.76\n",
      "=================== 620 / 1000 epoch ===================\n",
      "Train  loss: 0.4536, acc: 0.82\n",
      "Valid  loss: 0.5414, acc: 0.76\n",
      "=================== 621 / 1000 epoch ===================\n",
      "Train  loss: 0.4535, acc: 0.82\n",
      "Valid  loss: 0.5413, acc: 0.76\n",
      "=================== 622 / 1000 epoch ===================\n",
      "Train  loss: 0.4533, acc: 0.82\n",
      "Valid  loss: 0.5412, acc: 0.76\n",
      "=================== 623 / 1000 epoch ===================\n",
      "Train  loss: 0.4532, acc: 0.82\n",
      "Valid  loss: 0.5411, acc: 0.76\n",
      "=================== 624 / 1000 epoch ===================\n",
      "Train  loss: 0.4531, acc: 0.82\n",
      "Valid  loss: 0.5410, acc: 0.77\n",
      "=================== 625 / 1000 epoch ===================\n",
      "Train  loss: 0.4530, acc: 0.82\n",
      "Valid  loss: 0.5409, acc: 0.77\n",
      "=================== 626 / 1000 epoch ===================\n",
      "Train  loss: 0.4528, acc: 0.82\n",
      "Valid  loss: 0.5407, acc: 0.77\n",
      "=================== 627 / 1000 epoch ===================\n",
      "Train  loss: 0.4527, acc: 0.82\n",
      "Valid  loss: 0.5406, acc: 0.77\n",
      "=================== 628 / 1000 epoch ===================\n",
      "Train  loss: 0.4526, acc: 0.82\n",
      "Valid  loss: 0.5405, acc: 0.77\n",
      "=================== 629 / 1000 epoch ===================\n",
      "Train  loss: 0.4525, acc: 0.82\n",
      "Valid  loss: 0.5404, acc: 0.77\n",
      "=================== 630 / 1000 epoch ===================\n",
      "Train  loss: 0.4523, acc: 0.82\n",
      "Valid  loss: 0.5403, acc: 0.77\n",
      "=================== 631 / 1000 epoch ===================\n",
      "Train  loss: 0.4522, acc: 0.82\n",
      "Valid  loss: 0.5402, acc: 0.77\n",
      "=================== 632 / 1000 epoch ===================\n",
      "Train  loss: 0.4521, acc: 0.82\n",
      "Valid  loss: 0.5401, acc: 0.76\n",
      "=================== 633 / 1000 epoch ===================\n",
      "Train  loss: 0.4520, acc: 0.82\n",
      "Valid  loss: 0.5400, acc: 0.76\n",
      "=================== 634 / 1000 epoch ===================\n",
      "Train  loss: 0.4519, acc: 0.82\n",
      "Valid  loss: 0.5399, acc: 0.76\n",
      "=================== 635 / 1000 epoch ===================\n",
      "Train  loss: 0.4517, acc: 0.82\n",
      "Valid  loss: 0.5398, acc: 0.76\n",
      "=================== 636 / 1000 epoch ===================\n",
      "Train  loss: 0.4516, acc: 0.82\n",
      "Valid  loss: 0.5397, acc: 0.76\n",
      "=================== 637 / 1000 epoch ===================\n",
      "Train  loss: 0.4515, acc: 0.82\n",
      "Valid  loss: 0.5396, acc: 0.77\n",
      "=================== 638 / 1000 epoch ===================\n",
      "Train  loss: 0.4514, acc: 0.82\n",
      "Valid  loss: 0.5395, acc: 0.77\n",
      "=================== 639 / 1000 epoch ===================\n",
      "Train  loss: 0.4512, acc: 0.82\n",
      "Valid  loss: 0.5394, acc: 0.77\n",
      "=================== 640 / 1000 epoch ===================\n",
      "Train  loss: 0.4511, acc: 0.82\n",
      "Valid  loss: 0.5393, acc: 0.77\n",
      "=================== 641 / 1000 epoch ===================\n",
      "Train  loss: 0.4510, acc: 0.82\n",
      "Valid  loss: 0.5392, acc: 0.77\n",
      "=================== 642 / 1000 epoch ===================\n",
      "Train  loss: 0.4509, acc: 0.82\n",
      "Valid  loss: 0.5391, acc: 0.77\n",
      "=================== 643 / 1000 epoch ===================\n",
      "Train  loss: 0.4508, acc: 0.82\n",
      "Valid  loss: 0.5390, acc: 0.77\n",
      "=================== 644 / 1000 epoch ===================\n",
      "Train  loss: 0.4507, acc: 0.82\n",
      "Valid  loss: 0.5389, acc: 0.77\n",
      "=================== 645 / 1000 epoch ===================\n",
      "Train  loss: 0.4505, acc: 0.82\n",
      "Valid  loss: 0.5388, acc: 0.77\n",
      "=================== 646 / 1000 epoch ===================\n",
      "Train  loss: 0.4504, acc: 0.82\n",
      "Valid  loss: 0.5387, acc: 0.77\n",
      "=================== 647 / 1000 epoch ===================\n",
      "Train  loss: 0.4503, acc: 0.82\n",
      "Valid  loss: 0.5386, acc: 0.77\n",
      "=================== 648 / 1000 epoch ===================\n",
      "Train  loss: 0.4502, acc: 0.82\n",
      "Valid  loss: 0.5385, acc: 0.77\n",
      "=================== 649 / 1000 epoch ===================\n",
      "Train  loss: 0.4501, acc: 0.82\n",
      "Valid  loss: 0.5384, acc: 0.77\n",
      "=================== 650 / 1000 epoch ===================\n",
      "Train  loss: 0.4499, acc: 0.82\n",
      "Valid  loss: 0.5383, acc: 0.77\n",
      "=================== 651 / 1000 epoch ===================\n",
      "Train  loss: 0.4498, acc: 0.82\n",
      "Valid  loss: 0.5382, acc: 0.77\n",
      "=================== 652 / 1000 epoch ===================\n",
      "Train  loss: 0.4497, acc: 0.82\n",
      "Valid  loss: 0.5381, acc: 0.77\n",
      "=================== 653 / 1000 epoch ===================\n",
      "Train  loss: 0.4496, acc: 0.82\n",
      "Valid  loss: 0.5380, acc: 0.77\n",
      "=================== 654 / 1000 epoch ===================\n",
      "Train  loss: 0.4495, acc: 0.82\n",
      "Valid  loss: 0.5378, acc: 0.77\n",
      "=================== 655 / 1000 epoch ===================\n",
      "Train  loss: 0.4494, acc: 0.82\n",
      "Valid  loss: 0.5377, acc: 0.77\n",
      "=================== 656 / 1000 epoch ===================\n",
      "Train  loss: 0.4492, acc: 0.82\n",
      "Valid  loss: 0.5376, acc: 0.77\n",
      "=================== 657 / 1000 epoch ===================\n",
      "Train  loss: 0.4491, acc: 0.82\n",
      "Valid  loss: 0.5375, acc: 0.77\n",
      "=================== 658 / 1000 epoch ===================\n",
      "Train  loss: 0.4490, acc: 0.82\n",
      "Valid  loss: 0.5374, acc: 0.77\n",
      "=================== 659 / 1000 epoch ===================\n",
      "Train  loss: 0.4489, acc: 0.82\n",
      "Valid  loss: 0.5373, acc: 0.77\n",
      "=================== 660 / 1000 epoch ===================\n",
      "Train  loss: 0.4488, acc: 0.82\n",
      "Valid  loss: 0.5372, acc: 0.77\n",
      "=================== 661 / 1000 epoch ===================\n",
      "Train  loss: 0.4487, acc: 0.82\n",
      "Valid  loss: 0.5371, acc: 0.77\n",
      "=================== 662 / 1000 epoch ===================\n",
      "Train  loss: 0.4486, acc: 0.82\n",
      "Valid  loss: 0.5370, acc: 0.77\n",
      "=================== 663 / 1000 epoch ===================\n",
      "Train  loss: 0.4484, acc: 0.82\n",
      "Valid  loss: 0.5369, acc: 0.77\n",
      "=================== 664 / 1000 epoch ===================\n",
      "Train  loss: 0.4483, acc: 0.82\n",
      "Valid  loss: 0.5368, acc: 0.77\n",
      "=================== 665 / 1000 epoch ===================\n",
      "Train  loss: 0.4482, acc: 0.82\n",
      "Valid  loss: 0.5368, acc: 0.77\n",
      "=================== 666 / 1000 epoch ===================\n",
      "Train  loss: 0.4481, acc: 0.82\n",
      "Valid  loss: 0.5367, acc: 0.77\n",
      "=================== 667 / 1000 epoch ===================\n",
      "Train  loss: 0.4480, acc: 0.82\n",
      "Valid  loss: 0.5366, acc: 0.77\n",
      "=================== 668 / 1000 epoch ===================\n",
      "Train  loss: 0.4479, acc: 0.82\n",
      "Valid  loss: 0.5365, acc: 0.77\n",
      "=================== 669 / 1000 epoch ===================\n",
      "Train  loss: 0.4478, acc: 0.82\n",
      "Valid  loss: 0.5364, acc: 0.77\n",
      "=================== 670 / 1000 epoch ===================\n",
      "Train  loss: 0.4476, acc: 0.82\n",
      "Valid  loss: 0.5363, acc: 0.77\n",
      "=================== 671 / 1000 epoch ===================\n",
      "Train  loss: 0.4475, acc: 0.82\n",
      "Valid  loss: 0.5362, acc: 0.77\n",
      "=================== 672 / 1000 epoch ===================\n",
      "Train  loss: 0.4474, acc: 0.82\n",
      "Valid  loss: 0.5361, acc: 0.77\n",
      "=================== 673 / 1000 epoch ===================\n",
      "Train  loss: 0.4473, acc: 0.82\n",
      "Valid  loss: 0.5360, acc: 0.77\n",
      "=================== 674 / 1000 epoch ===================\n",
      "Train  loss: 0.4472, acc: 0.82\n",
      "Valid  loss: 0.5359, acc: 0.77\n",
      "=================== 675 / 1000 epoch ===================\n",
      "Train  loss: 0.4471, acc: 0.82\n",
      "Valid  loss: 0.5358, acc: 0.77\n",
      "=================== 676 / 1000 epoch ===================\n",
      "Train  loss: 0.4470, acc: 0.82\n",
      "Valid  loss: 0.5357, acc: 0.77\n",
      "=================== 677 / 1000 epoch ===================\n",
      "Train  loss: 0.4469, acc: 0.82\n",
      "Valid  loss: 0.5356, acc: 0.77\n",
      "=================== 678 / 1000 epoch ===================\n",
      "Train  loss: 0.4468, acc: 0.82\n",
      "Valid  loss: 0.5355, acc: 0.77\n",
      "=================== 679 / 1000 epoch ===================\n",
      "Train  loss: 0.4466, acc: 0.82\n",
      "Valid  loss: 0.5354, acc: 0.77\n",
      "=================== 680 / 1000 epoch ===================\n",
      "Train  loss: 0.4465, acc: 0.82\n",
      "Valid  loss: 0.5353, acc: 0.77\n",
      "=================== 681 / 1000 epoch ===================\n",
      "Train  loss: 0.4464, acc: 0.82\n",
      "Valid  loss: 0.5352, acc: 0.77\n",
      "=================== 682 / 1000 epoch ===================\n",
      "Train  loss: 0.4463, acc: 0.82\n",
      "Valid  loss: 0.5351, acc: 0.77\n",
      "=================== 683 / 1000 epoch ===================\n",
      "Train  loss: 0.4462, acc: 0.82\n",
      "Valid  loss: 0.5350, acc: 0.77\n",
      "=================== 684 / 1000 epoch ===================\n",
      "Train  loss: 0.4461, acc: 0.82\n",
      "Valid  loss: 0.5349, acc: 0.77\n",
      "=================== 685 / 1000 epoch ===================\n",
      "Train  loss: 0.4460, acc: 0.82\n",
      "Valid  loss: 0.5348, acc: 0.77\n",
      "=================== 686 / 1000 epoch ===================\n",
      "Train  loss: 0.4459, acc: 0.82\n",
      "Valid  loss: 0.5347, acc: 0.77\n",
      "=================== 687 / 1000 epoch ===================\n",
      "Train  loss: 0.4458, acc: 0.82\n",
      "Valid  loss: 0.5346, acc: 0.77\n",
      "=================== 688 / 1000 epoch ===================\n",
      "Train  loss: 0.4457, acc: 0.82\n",
      "Valid  loss: 0.5345, acc: 0.77\n",
      "=================== 689 / 1000 epoch ===================\n",
      "Train  loss: 0.4456, acc: 0.82\n",
      "Valid  loss: 0.5344, acc: 0.77\n",
      "=================== 690 / 1000 epoch ===================\n",
      "Train  loss: 0.4454, acc: 0.82\n",
      "Valid  loss: 0.5343, acc: 0.77\n",
      "=================== 691 / 1000 epoch ===================\n",
      "Train  loss: 0.4453, acc: 0.82\n",
      "Valid  loss: 0.5342, acc: 0.77\n",
      "=================== 692 / 1000 epoch ===================\n",
      "Train  loss: 0.4452, acc: 0.82\n",
      "Valid  loss: 0.5341, acc: 0.77\n",
      "=================== 693 / 1000 epoch ===================\n",
      "Train  loss: 0.4451, acc: 0.82\n",
      "Valid  loss: 0.5340, acc: 0.77\n",
      "=================== 694 / 1000 epoch ===================\n",
      "Train  loss: 0.4450, acc: 0.82\n",
      "Valid  loss: 0.5340, acc: 0.77\n",
      "=================== 695 / 1000 epoch ===================\n",
      "Train  loss: 0.4449, acc: 0.82\n",
      "Valid  loss: 0.5339, acc: 0.77\n",
      "=================== 696 / 1000 epoch ===================\n",
      "Train  loss: 0.4448, acc: 0.82\n",
      "Valid  loss: 0.5338, acc: 0.77\n",
      "=================== 697 / 1000 epoch ===================\n",
      "Train  loss: 0.4447, acc: 0.82\n",
      "Valid  loss: 0.5337, acc: 0.77\n",
      "=================== 698 / 1000 epoch ===================\n",
      "Train  loss: 0.4446, acc: 0.82\n",
      "Valid  loss: 0.5336, acc: 0.77\n",
      "=================== 699 / 1000 epoch ===================\n",
      "Train  loss: 0.4445, acc: 0.82\n",
      "Valid  loss: 0.5335, acc: 0.77\n",
      "=================== 700 / 1000 epoch ===================\n",
      "Train  loss: 0.4444, acc: 0.82\n",
      "Valid  loss: 0.5334, acc: 0.77\n",
      "=================== 701 / 1000 epoch ===================\n",
      "Train  loss: 0.4443, acc: 0.82\n",
      "Valid  loss: 0.5333, acc: 0.77\n",
      "=================== 702 / 1000 epoch ===================\n",
      "Train  loss: 0.4442, acc: 0.82\n",
      "Valid  loss: 0.5332, acc: 0.77\n",
      "=================== 703 / 1000 epoch ===================\n",
      "Train  loss: 0.4441, acc: 0.82\n",
      "Valid  loss: 0.5331, acc: 0.77\n",
      "=================== 704 / 1000 epoch ===================\n",
      "Train  loss: 0.4440, acc: 0.82\n",
      "Valid  loss: 0.5330, acc: 0.77\n",
      "=================== 705 / 1000 epoch ===================\n",
      "Train  loss: 0.4439, acc: 0.82\n",
      "Valid  loss: 0.5329, acc: 0.77\n",
      "=================== 706 / 1000 epoch ===================\n",
      "Train  loss: 0.4437, acc: 0.82\n",
      "Valid  loss: 0.5328, acc: 0.77\n",
      "=================== 707 / 1000 epoch ===================\n",
      "Train  loss: 0.4436, acc: 0.82\n",
      "Valid  loss: 0.5327, acc: 0.77\n",
      "=================== 708 / 1000 epoch ===================\n",
      "Train  loss: 0.4435, acc: 0.82\n",
      "Valid  loss: 0.5326, acc: 0.77\n",
      "=================== 709 / 1000 epoch ===================\n",
      "Train  loss: 0.4434, acc: 0.82\n",
      "Valid  loss: 0.5326, acc: 0.77\n",
      "=================== 710 / 1000 epoch ===================\n",
      "Train  loss: 0.4433, acc: 0.82\n",
      "Valid  loss: 0.5325, acc: 0.77\n",
      "=================== 711 / 1000 epoch ===================\n",
      "Train  loss: 0.4432, acc: 0.82\n",
      "Valid  loss: 0.5324, acc: 0.77\n",
      "=================== 712 / 1000 epoch ===================\n",
      "Train  loss: 0.4431, acc: 0.82\n",
      "Valid  loss: 0.5323, acc: 0.77\n",
      "=================== 713 / 1000 epoch ===================\n",
      "Train  loss: 0.4430, acc: 0.82\n",
      "Valid  loss: 0.5322, acc: 0.77\n",
      "=================== 714 / 1000 epoch ===================\n",
      "Train  loss: 0.4429, acc: 0.82\n",
      "Valid  loss: 0.5321, acc: 0.77\n",
      "=================== 715 / 1000 epoch ===================\n",
      "Train  loss: 0.4428, acc: 0.82\n",
      "Valid  loss: 0.5320, acc: 0.77\n",
      "=================== 716 / 1000 epoch ===================\n",
      "Train  loss: 0.4427, acc: 0.82\n",
      "Valid  loss: 0.5319, acc: 0.77\n",
      "=================== 717 / 1000 epoch ===================\n",
      "Train  loss: 0.4426, acc: 0.82\n",
      "Valid  loss: 0.5318, acc: 0.77\n",
      "=================== 718 / 1000 epoch ===================\n",
      "Train  loss: 0.4425, acc: 0.82\n",
      "Valid  loss: 0.5317, acc: 0.77\n",
      "=================== 719 / 1000 epoch ===================\n",
      "Train  loss: 0.4424, acc: 0.82\n",
      "Valid  loss: 0.5316, acc: 0.77\n",
      "=================== 720 / 1000 epoch ===================\n",
      "Train  loss: 0.4423, acc: 0.82\n",
      "Valid  loss: 0.5316, acc: 0.77\n",
      "=================== 721 / 1000 epoch ===================\n",
      "Train  loss: 0.4422, acc: 0.82\n",
      "Valid  loss: 0.5315, acc: 0.77\n",
      "=================== 722 / 1000 epoch ===================\n",
      "Train  loss: 0.4421, acc: 0.82\n",
      "Valid  loss: 0.5314, acc: 0.77\n",
      "=================== 723 / 1000 epoch ===================\n",
      "Train  loss: 0.4420, acc: 0.82\n",
      "Valid  loss: 0.5313, acc: 0.77\n",
      "=================== 724 / 1000 epoch ===================\n",
      "Train  loss: 0.4419, acc: 0.82\n",
      "Valid  loss: 0.5312, acc: 0.77\n",
      "=================== 725 / 1000 epoch ===================\n",
      "Train  loss: 0.4418, acc: 0.82\n",
      "Valid  loss: 0.5311, acc: 0.77\n",
      "=================== 726 / 1000 epoch ===================\n",
      "Train  loss: 0.4417, acc: 0.82\n",
      "Valid  loss: 0.5310, acc: 0.77\n",
      "=================== 727 / 1000 epoch ===================\n",
      "Train  loss: 0.4416, acc: 0.82\n",
      "Valid  loss: 0.5309, acc: 0.77\n",
      "=================== 728 / 1000 epoch ===================\n",
      "Train  loss: 0.4415, acc: 0.82\n",
      "Valid  loss: 0.5308, acc: 0.77\n",
      "=================== 729 / 1000 epoch ===================\n",
      "Train  loss: 0.4414, acc: 0.82\n",
      "Valid  loss: 0.5308, acc: 0.77\n",
      "=================== 730 / 1000 epoch ===================\n",
      "Train  loss: 0.4413, acc: 0.82\n",
      "Valid  loss: 0.5307, acc: 0.77\n",
      "=================== 731 / 1000 epoch ===================\n",
      "Train  loss: 0.4412, acc: 0.82\n",
      "Valid  loss: 0.5306, acc: 0.77\n",
      "=================== 732 / 1000 epoch ===================\n",
      "Train  loss: 0.4411, acc: 0.82\n",
      "Valid  loss: 0.5305, acc: 0.77\n",
      "=================== 733 / 1000 epoch ===================\n",
      "Train  loss: 0.4410, acc: 0.82\n",
      "Valid  loss: 0.5304, acc: 0.77\n",
      "=================== 734 / 1000 epoch ===================\n",
      "Train  loss: 0.4409, acc: 0.82\n",
      "Valid  loss: 0.5303, acc: 0.77\n",
      "=================== 735 / 1000 epoch ===================\n",
      "Train  loss: 0.4408, acc: 0.82\n",
      "Valid  loss: 0.5302, acc: 0.77\n",
      "=================== 736 / 1000 epoch ===================\n",
      "Train  loss: 0.4407, acc: 0.82\n",
      "Valid  loss: 0.5301, acc: 0.77\n",
      "=================== 737 / 1000 epoch ===================\n",
      "Train  loss: 0.4406, acc: 0.82\n",
      "Valid  loss: 0.5300, acc: 0.77\n",
      "=================== 738 / 1000 epoch ===================\n",
      "Train  loss: 0.4405, acc: 0.82\n",
      "Valid  loss: 0.5300, acc: 0.77\n",
      "=================== 739 / 1000 epoch ===================\n",
      "Train  loss: 0.4404, acc: 0.82\n",
      "Valid  loss: 0.5299, acc: 0.77\n",
      "=================== 740 / 1000 epoch ===================\n",
      "Train  loss: 0.4403, acc: 0.82\n",
      "Valid  loss: 0.5298, acc: 0.77\n",
      "=================== 741 / 1000 epoch ===================\n",
      "Train  loss: 0.4402, acc: 0.82\n",
      "Valid  loss: 0.5297, acc: 0.77\n",
      "=================== 742 / 1000 epoch ===================\n",
      "Train  loss: 0.4401, acc: 0.82\n",
      "Valid  loss: 0.5296, acc: 0.77\n",
      "=================== 743 / 1000 epoch ===================\n",
      "Train  loss: 0.4400, acc: 0.82\n",
      "Valid  loss: 0.5295, acc: 0.77\n",
      "=================== 744 / 1000 epoch ===================\n",
      "Train  loss: 0.4399, acc: 0.82\n",
      "Valid  loss: 0.5294, acc: 0.77\n",
      "=================== 745 / 1000 epoch ===================\n",
      "Train  loss: 0.4398, acc: 0.82\n",
      "Valid  loss: 0.5293, acc: 0.77\n",
      "=================== 746 / 1000 epoch ===================\n",
      "Train  loss: 0.4397, acc: 0.82\n",
      "Valid  loss: 0.5293, acc: 0.77\n",
      "=================== 747 / 1000 epoch ===================\n",
      "Train  loss: 0.4396, acc: 0.82\n",
      "Valid  loss: 0.5292, acc: 0.77\n",
      "=================== 748 / 1000 epoch ===================\n",
      "Train  loss: 0.4395, acc: 0.82\n",
      "Valid  loss: 0.5291, acc: 0.77\n",
      "=================== 749 / 1000 epoch ===================\n",
      "Train  loss: 0.4395, acc: 0.82\n",
      "Valid  loss: 0.5290, acc: 0.77\n",
      "=================== 750 / 1000 epoch ===================\n",
      "Train  loss: 0.4394, acc: 0.82\n",
      "Valid  loss: 0.5289, acc: 0.77\n",
      "=================== 751 / 1000 epoch ===================\n",
      "Train  loss: 0.4393, acc: 0.82\n",
      "Valid  loss: 0.5288, acc: 0.77\n",
      "=================== 752 / 1000 epoch ===================\n",
      "Train  loss: 0.4392, acc: 0.82\n",
      "Valid  loss: 0.5287, acc: 0.77\n",
      "=================== 753 / 1000 epoch ===================\n",
      "Train  loss: 0.4391, acc: 0.82\n",
      "Valid  loss: 0.5287, acc: 0.77\n",
      "=================== 754 / 1000 epoch ===================\n",
      "Train  loss: 0.4390, acc: 0.82\n",
      "Valid  loss: 0.5286, acc: 0.77\n",
      "=================== 755 / 1000 epoch ===================\n",
      "Train  loss: 0.4389, acc: 0.82\n",
      "Valid  loss: 0.5285, acc: 0.77\n",
      "=================== 756 / 1000 epoch ===================\n",
      "Train  loss: 0.4388, acc: 0.82\n",
      "Valid  loss: 0.5284, acc: 0.77\n",
      "=================== 757 / 1000 epoch ===================\n",
      "Train  loss: 0.4387, acc: 0.82\n",
      "Valid  loss: 0.5283, acc: 0.77\n",
      "=================== 758 / 1000 epoch ===================\n",
      "Train  loss: 0.4386, acc: 0.82\n",
      "Valid  loss: 0.5282, acc: 0.77\n",
      "=================== 759 / 1000 epoch ===================\n",
      "Train  loss: 0.4385, acc: 0.82\n",
      "Valid  loss: 0.5281, acc: 0.77\n",
      "=================== 760 / 1000 epoch ===================\n",
      "Train  loss: 0.4384, acc: 0.82\n",
      "Valid  loss: 0.5281, acc: 0.77\n",
      "=================== 761 / 1000 epoch ===================\n",
      "Train  loss: 0.4383, acc: 0.82\n",
      "Valid  loss: 0.5280, acc: 0.77\n",
      "=================== 762 / 1000 epoch ===================\n",
      "Train  loss: 0.4382, acc: 0.82\n",
      "Valid  loss: 0.5279, acc: 0.77\n",
      "=================== 763 / 1000 epoch ===================\n",
      "Train  loss: 0.4381, acc: 0.82\n",
      "Valid  loss: 0.5278, acc: 0.77\n",
      "=================== 764 / 1000 epoch ===================\n",
      "Train  loss: 0.4380, acc: 0.82\n",
      "Valid  loss: 0.5277, acc: 0.77\n",
      "=================== 765 / 1000 epoch ===================\n",
      "Train  loss: 0.4379, acc: 0.82\n",
      "Valid  loss: 0.5276, acc: 0.77\n",
      "=================== 766 / 1000 epoch ===================\n",
      "Train  loss: 0.4379, acc: 0.82\n",
      "Valid  loss: 0.5276, acc: 0.77\n",
      "=================== 767 / 1000 epoch ===================\n",
      "Train  loss: 0.4378, acc: 0.82\n",
      "Valid  loss: 0.5275, acc: 0.77\n",
      "=================== 768 / 1000 epoch ===================\n",
      "Train  loss: 0.4377, acc: 0.82\n",
      "Valid  loss: 0.5274, acc: 0.77\n",
      "=================== 769 / 1000 epoch ===================\n",
      "Train  loss: 0.4376, acc: 0.82\n",
      "Valid  loss: 0.5273, acc: 0.77\n",
      "=================== 770 / 1000 epoch ===================\n",
      "Train  loss: 0.4375, acc: 0.82\n",
      "Valid  loss: 0.5272, acc: 0.77\n",
      "=================== 771 / 1000 epoch ===================\n",
      "Train  loss: 0.4374, acc: 0.82\n",
      "Valid  loss: 0.5271, acc: 0.77\n",
      "=================== 772 / 1000 epoch ===================\n",
      "Train  loss: 0.4373, acc: 0.82\n",
      "Valid  loss: 0.5271, acc: 0.77\n",
      "=================== 773 / 1000 epoch ===================\n",
      "Train  loss: 0.4372, acc: 0.82\n",
      "Valid  loss: 0.5270, acc: 0.77\n",
      "=================== 774 / 1000 epoch ===================\n",
      "Train  loss: 0.4371, acc: 0.82\n",
      "Valid  loss: 0.5269, acc: 0.77\n",
      "=================== 775 / 1000 epoch ===================\n",
      "Train  loss: 0.4370, acc: 0.82\n",
      "Valid  loss: 0.5268, acc: 0.77\n",
      "=================== 776 / 1000 epoch ===================\n",
      "Train  loss: 0.4369, acc: 0.82\n",
      "Valid  loss: 0.5267, acc: 0.77\n",
      "=================== 777 / 1000 epoch ===================\n",
      "Train  loss: 0.4368, acc: 0.82\n",
      "Valid  loss: 0.5266, acc: 0.77\n",
      "=================== 778 / 1000 epoch ===================\n",
      "Train  loss: 0.4368, acc: 0.82\n",
      "Valid  loss: 0.5266, acc: 0.77\n",
      "=================== 779 / 1000 epoch ===================\n",
      "Train  loss: 0.4367, acc: 0.82\n",
      "Valid  loss: 0.5265, acc: 0.77\n",
      "=================== 780 / 1000 epoch ===================\n",
      "Train  loss: 0.4366, acc: 0.82\n",
      "Valid  loss: 0.5264, acc: 0.77\n",
      "=================== 781 / 1000 epoch ===================\n",
      "Train  loss: 0.4365, acc: 0.82\n",
      "Valid  loss: 0.5263, acc: 0.77\n",
      "=================== 782 / 1000 epoch ===================\n",
      "Train  loss: 0.4364, acc: 0.82\n",
      "Valid  loss: 0.5262, acc: 0.77\n",
      "=================== 783 / 1000 epoch ===================\n",
      "Train  loss: 0.4363, acc: 0.82\n",
      "Valid  loss: 0.5262, acc: 0.77\n",
      "=================== 784 / 1000 epoch ===================\n",
      "Train  loss: 0.4362, acc: 0.82\n",
      "Valid  loss: 0.5261, acc: 0.77\n",
      "=================== 785 / 1000 epoch ===================\n",
      "Train  loss: 0.4361, acc: 0.82\n",
      "Valid  loss: 0.5260, acc: 0.77\n",
      "=================== 786 / 1000 epoch ===================\n",
      "Train  loss: 0.4360, acc: 0.82\n",
      "Valid  loss: 0.5259, acc: 0.77\n",
      "=================== 787 / 1000 epoch ===================\n",
      "Train  loss: 0.4359, acc: 0.82\n",
      "Valid  loss: 0.5258, acc: 0.77\n",
      "=================== 788 / 1000 epoch ===================\n",
      "Train  loss: 0.4359, acc: 0.82\n",
      "Valid  loss: 0.5258, acc: 0.77\n",
      "=================== 789 / 1000 epoch ===================\n",
      "Train  loss: 0.4358, acc: 0.82\n",
      "Valid  loss: 0.5257, acc: 0.77\n",
      "=================== 790 / 1000 epoch ===================\n",
      "Train  loss: 0.4357, acc: 0.82\n",
      "Valid  loss: 0.5256, acc: 0.77\n",
      "=================== 791 / 1000 epoch ===================\n",
      "Train  loss: 0.4356, acc: 0.82\n",
      "Valid  loss: 0.5255, acc: 0.77\n",
      "=================== 792 / 1000 epoch ===================\n",
      "Train  loss: 0.4355, acc: 0.82\n",
      "Valid  loss: 0.5254, acc: 0.77\n",
      "=================== 793 / 1000 epoch ===================\n",
      "Train  loss: 0.4354, acc: 0.82\n",
      "Valid  loss: 0.5253, acc: 0.77\n",
      "=================== 794 / 1000 epoch ===================\n",
      "Train  loss: 0.4353, acc: 0.82\n",
      "Valid  loss: 0.5253, acc: 0.77\n",
      "=================== 795 / 1000 epoch ===================\n",
      "Train  loss: 0.4352, acc: 0.82\n",
      "Valid  loss: 0.5252, acc: 0.77\n",
      "=================== 796 / 1000 epoch ===================\n",
      "Train  loss: 0.4352, acc: 0.82\n",
      "Valid  loss: 0.5251, acc: 0.77\n",
      "=================== 797 / 1000 epoch ===================\n",
      "Train  loss: 0.4351, acc: 0.82\n",
      "Valid  loss: 0.5250, acc: 0.77\n",
      "=================== 798 / 1000 epoch ===================\n",
      "Train  loss: 0.4350, acc: 0.82\n",
      "Valid  loss: 0.5249, acc: 0.77\n",
      "=================== 799 / 1000 epoch ===================\n",
      "Train  loss: 0.4349, acc: 0.82\n",
      "Valid  loss: 0.5249, acc: 0.77\n",
      "=================== 800 / 1000 epoch ===================\n",
      "Train  loss: 0.4348, acc: 0.82\n",
      "Valid  loss: 0.5248, acc: 0.77\n",
      "=================== 801 / 1000 epoch ===================\n",
      "Train  loss: 0.4347, acc: 0.82\n",
      "Valid  loss: 0.5247, acc: 0.77\n",
      "=================== 802 / 1000 epoch ===================\n",
      "Train  loss: 0.4346, acc: 0.82\n",
      "Valid  loss: 0.5246, acc: 0.77\n",
      "=================== 803 / 1000 epoch ===================\n",
      "Train  loss: 0.4345, acc: 0.82\n",
      "Valid  loss: 0.5246, acc: 0.77\n",
      "=================== 804 / 1000 epoch ===================\n",
      "Train  loss: 0.4345, acc: 0.82\n",
      "Valid  loss: 0.5245, acc: 0.77\n",
      "=================== 805 / 1000 epoch ===================\n",
      "Train  loss: 0.4344, acc: 0.82\n",
      "Valid  loss: 0.5244, acc: 0.77\n",
      "=================== 806 / 1000 epoch ===================\n",
      "Train  loss: 0.4343, acc: 0.82\n",
      "Valid  loss: 0.5243, acc: 0.77\n",
      "=================== 807 / 1000 epoch ===================\n",
      "Train  loss: 0.4342, acc: 0.82\n",
      "Valid  loss: 0.5242, acc: 0.77\n",
      "=================== 808 / 1000 epoch ===================\n",
      "Train  loss: 0.4341, acc: 0.82\n",
      "Valid  loss: 0.5242, acc: 0.77\n",
      "=================== 809 / 1000 epoch ===================\n",
      "Train  loss: 0.4340, acc: 0.82\n",
      "Valid  loss: 0.5241, acc: 0.77\n",
      "=================== 810 / 1000 epoch ===================\n",
      "Train  loss: 0.4339, acc: 0.82\n",
      "Valid  loss: 0.5240, acc: 0.77\n",
      "=================== 811 / 1000 epoch ===================\n",
      "Train  loss: 0.4339, acc: 0.82\n",
      "Valid  loss: 0.5239, acc: 0.77\n",
      "=================== 812 / 1000 epoch ===================\n",
      "Train  loss: 0.4338, acc: 0.82\n",
      "Valid  loss: 0.5238, acc: 0.77\n",
      "=================== 813 / 1000 epoch ===================\n",
      "Train  loss: 0.4337, acc: 0.82\n",
      "Valid  loss: 0.5238, acc: 0.77\n",
      "=================== 814 / 1000 epoch ===================\n",
      "Train  loss: 0.4336, acc: 0.83\n",
      "Valid  loss: 0.5237, acc: 0.77\n",
      "=================== 815 / 1000 epoch ===================\n",
      "Train  loss: 0.4335, acc: 0.83\n",
      "Valid  loss: 0.5236, acc: 0.77\n",
      "=================== 816 / 1000 epoch ===================\n",
      "Train  loss: 0.4334, acc: 0.83\n",
      "Valid  loss: 0.5235, acc: 0.77\n",
      "=================== 817 / 1000 epoch ===================\n",
      "Train  loss: 0.4334, acc: 0.83\n",
      "Valid  loss: 0.5235, acc: 0.77\n",
      "=================== 818 / 1000 epoch ===================\n",
      "Train  loss: 0.4333, acc: 0.83\n",
      "Valid  loss: 0.5234, acc: 0.78\n",
      "=================== 819 / 1000 epoch ===================\n",
      "Train  loss: 0.4332, acc: 0.83\n",
      "Valid  loss: 0.5233, acc: 0.78\n",
      "=================== 820 / 1000 epoch ===================\n",
      "Train  loss: 0.4331, acc: 0.83\n",
      "Valid  loss: 0.5232, acc: 0.78\n",
      "=================== 821 / 1000 epoch ===================\n",
      "Train  loss: 0.4330, acc: 0.83\n",
      "Valid  loss: 0.5231, acc: 0.78\n",
      "=================== 822 / 1000 epoch ===================\n",
      "Train  loss: 0.4329, acc: 0.83\n",
      "Valid  loss: 0.5231, acc: 0.78\n",
      "=================== 823 / 1000 epoch ===================\n",
      "Train  loss: 0.4328, acc: 0.83\n",
      "Valid  loss: 0.5230, acc: 0.78\n",
      "=================== 824 / 1000 epoch ===================\n",
      "Train  loss: 0.4328, acc: 0.83\n",
      "Valid  loss: 0.5229, acc: 0.78\n",
      "=================== 825 / 1000 epoch ===================\n",
      "Train  loss: 0.4327, acc: 0.83\n",
      "Valid  loss: 0.5228, acc: 0.78\n",
      "=================== 826 / 1000 epoch ===================\n",
      "Train  loss: 0.4326, acc: 0.83\n",
      "Valid  loss: 0.5228, acc: 0.78\n",
      "=================== 827 / 1000 epoch ===================\n",
      "Train  loss: 0.4325, acc: 0.83\n",
      "Valid  loss: 0.5227, acc: 0.78\n",
      "=================== 828 / 1000 epoch ===================\n",
      "Train  loss: 0.4324, acc: 0.83\n",
      "Valid  loss: 0.5226, acc: 0.78\n",
      "=================== 829 / 1000 epoch ===================\n",
      "Train  loss: 0.4324, acc: 0.83\n",
      "Valid  loss: 0.5225, acc: 0.78\n",
      "=================== 830 / 1000 epoch ===================\n",
      "Train  loss: 0.4323, acc: 0.83\n",
      "Valid  loss: 0.5225, acc: 0.78\n",
      "=================== 831 / 1000 epoch ===================\n",
      "Train  loss: 0.4322, acc: 0.83\n",
      "Valid  loss: 0.5224, acc: 0.78\n",
      "=================== 832 / 1000 epoch ===================\n",
      "Train  loss: 0.4321, acc: 0.83\n",
      "Valid  loss: 0.5223, acc: 0.78\n",
      "=================== 833 / 1000 epoch ===================\n",
      "Train  loss: 0.4320, acc: 0.83\n",
      "Valid  loss: 0.5222, acc: 0.77\n",
      "=================== 834 / 1000 epoch ===================\n",
      "Train  loss: 0.4319, acc: 0.83\n",
      "Valid  loss: 0.5222, acc: 0.77\n",
      "=================== 835 / 1000 epoch ===================\n",
      "Train  loss: 0.4319, acc: 0.83\n",
      "Valid  loss: 0.5221, acc: 0.77\n",
      "=================== 836 / 1000 epoch ===================\n",
      "Train  loss: 0.4318, acc: 0.83\n",
      "Valid  loss: 0.5220, acc: 0.77\n",
      "=================== 837 / 1000 epoch ===================\n",
      "Train  loss: 0.4317, acc: 0.83\n",
      "Valid  loss: 0.5219, acc: 0.77\n",
      "=================== 838 / 1000 epoch ===================\n",
      "Train  loss: 0.4316, acc: 0.83\n",
      "Valid  loss: 0.5219, acc: 0.77\n",
      "=================== 839 / 1000 epoch ===================\n",
      "Train  loss: 0.4315, acc: 0.83\n",
      "Valid  loss: 0.5218, acc: 0.77\n",
      "=================== 840 / 1000 epoch ===================\n",
      "Train  loss: 0.4315, acc: 0.83\n",
      "Valid  loss: 0.5217, acc: 0.77\n",
      "=================== 841 / 1000 epoch ===================\n",
      "Train  loss: 0.4314, acc: 0.83\n",
      "Valid  loss: 0.5216, acc: 0.77\n",
      "=================== 842 / 1000 epoch ===================\n",
      "Train  loss: 0.4313, acc: 0.83\n",
      "Valid  loss: 0.5216, acc: 0.77\n",
      "=================== 843 / 1000 epoch ===================\n",
      "Train  loss: 0.4312, acc: 0.83\n",
      "Valid  loss: 0.5215, acc: 0.77\n",
      "=================== 844 / 1000 epoch ===================\n",
      "Train  loss: 0.4311, acc: 0.83\n",
      "Valid  loss: 0.5214, acc: 0.77\n",
      "=================== 845 / 1000 epoch ===================\n",
      "Train  loss: 0.4311, acc: 0.83\n",
      "Valid  loss: 0.5213, acc: 0.77\n",
      "=================== 846 / 1000 epoch ===================\n",
      "Train  loss: 0.4310, acc: 0.83\n",
      "Valid  loss: 0.5213, acc: 0.77\n",
      "=================== 847 / 1000 epoch ===================\n",
      "Train  loss: 0.4309, acc: 0.83\n",
      "Valid  loss: 0.5212, acc: 0.77\n",
      "=================== 848 / 1000 epoch ===================\n",
      "Train  loss: 0.4308, acc: 0.83\n",
      "Valid  loss: 0.5211, acc: 0.77\n",
      "=================== 849 / 1000 epoch ===================\n",
      "Train  loss: 0.4307, acc: 0.83\n",
      "Valid  loss: 0.5210, acc: 0.77\n",
      "=================== 850 / 1000 epoch ===================\n",
      "Train  loss: 0.4307, acc: 0.83\n",
      "Valid  loss: 0.5210, acc: 0.77\n",
      "=================== 851 / 1000 epoch ===================\n",
      "Train  loss: 0.4306, acc: 0.83\n",
      "Valid  loss: 0.5209, acc: 0.77\n",
      "=================== 852 / 1000 epoch ===================\n",
      "Train  loss: 0.4305, acc: 0.83\n",
      "Valid  loss: 0.5208, acc: 0.77\n",
      "=================== 853 / 1000 epoch ===================\n",
      "Train  loss: 0.4304, acc: 0.83\n",
      "Valid  loss: 0.5207, acc: 0.77\n",
      "=================== 854 / 1000 epoch ===================\n",
      "Train  loss: 0.4303, acc: 0.83\n",
      "Valid  loss: 0.5207, acc: 0.77\n",
      "=================== 855 / 1000 epoch ===================\n",
      "Train  loss: 0.4303, acc: 0.83\n",
      "Valid  loss: 0.5206, acc: 0.77\n",
      "=================== 856 / 1000 epoch ===================\n",
      "Train  loss: 0.4302, acc: 0.83\n",
      "Valid  loss: 0.5205, acc: 0.77\n",
      "=================== 857 / 1000 epoch ===================\n",
      "Train  loss: 0.4301, acc: 0.83\n",
      "Valid  loss: 0.5205, acc: 0.77\n",
      "=================== 858 / 1000 epoch ===================\n",
      "Train  loss: 0.4300, acc: 0.83\n",
      "Valid  loss: 0.5204, acc: 0.77\n",
      "=================== 859 / 1000 epoch ===================\n",
      "Train  loss: 0.4300, acc: 0.83\n",
      "Valid  loss: 0.5203, acc: 0.77\n",
      "=================== 860 / 1000 epoch ===================\n",
      "Train  loss: 0.4299, acc: 0.83\n",
      "Valid  loss: 0.5202, acc: 0.77\n",
      "=================== 861 / 1000 epoch ===================\n",
      "Train  loss: 0.4298, acc: 0.83\n",
      "Valid  loss: 0.5202, acc: 0.77\n",
      "=================== 862 / 1000 epoch ===================\n",
      "Train  loss: 0.4297, acc: 0.83\n",
      "Valid  loss: 0.5201, acc: 0.77\n",
      "=================== 863 / 1000 epoch ===================\n",
      "Train  loss: 0.4296, acc: 0.83\n",
      "Valid  loss: 0.5200, acc: 0.77\n",
      "=================== 864 / 1000 epoch ===================\n",
      "Train  loss: 0.4296, acc: 0.83\n",
      "Valid  loss: 0.5199, acc: 0.77\n",
      "=================== 865 / 1000 epoch ===================\n",
      "Train  loss: 0.4295, acc: 0.83\n",
      "Valid  loss: 0.5199, acc: 0.77\n",
      "=================== 866 / 1000 epoch ===================\n",
      "Train  loss: 0.4294, acc: 0.83\n",
      "Valid  loss: 0.5198, acc: 0.77\n",
      "=================== 867 / 1000 epoch ===================\n",
      "Train  loss: 0.4293, acc: 0.83\n",
      "Valid  loss: 0.5197, acc: 0.77\n",
      "=================== 868 / 1000 epoch ===================\n",
      "Train  loss: 0.4293, acc: 0.83\n",
      "Valid  loss: 0.5197, acc: 0.77\n",
      "=================== 869 / 1000 epoch ===================\n",
      "Train  loss: 0.4292, acc: 0.83\n",
      "Valid  loss: 0.5196, acc: 0.77\n",
      "=================== 870 / 1000 epoch ===================\n",
      "Train  loss: 0.4291, acc: 0.83\n",
      "Valid  loss: 0.5195, acc: 0.77\n",
      "=================== 871 / 1000 epoch ===================\n",
      "Train  loss: 0.4290, acc: 0.83\n",
      "Valid  loss: 0.5194, acc: 0.77\n",
      "=================== 872 / 1000 epoch ===================\n",
      "Train  loss: 0.4289, acc: 0.83\n",
      "Valid  loss: 0.5194, acc: 0.77\n",
      "=================== 873 / 1000 epoch ===================\n",
      "Train  loss: 0.4289, acc: 0.83\n",
      "Valid  loss: 0.5193, acc: 0.77\n",
      "=================== 874 / 1000 epoch ===================\n",
      "Train  loss: 0.4288, acc: 0.83\n",
      "Valid  loss: 0.5192, acc: 0.77\n",
      "=================== 875 / 1000 epoch ===================\n",
      "Train  loss: 0.4287, acc: 0.83\n",
      "Valid  loss: 0.5192, acc: 0.77\n",
      "=================== 876 / 1000 epoch ===================\n",
      "Train  loss: 0.4286, acc: 0.83\n",
      "Valid  loss: 0.5191, acc: 0.77\n",
      "=================== 877 / 1000 epoch ===================\n",
      "Train  loss: 0.4286, acc: 0.83\n",
      "Valid  loss: 0.5190, acc: 0.77\n",
      "=================== 878 / 1000 epoch ===================\n",
      "Train  loss: 0.4285, acc: 0.83\n",
      "Valid  loss: 0.5189, acc: 0.77\n",
      "=================== 879 / 1000 epoch ===================\n",
      "Train  loss: 0.4284, acc: 0.83\n",
      "Valid  loss: 0.5189, acc: 0.77\n",
      "=================== 880 / 1000 epoch ===================\n",
      "Train  loss: 0.4283, acc: 0.83\n",
      "Valid  loss: 0.5188, acc: 0.77\n",
      "=================== 881 / 1000 epoch ===================\n",
      "Train  loss: 0.4283, acc: 0.83\n",
      "Valid  loss: 0.5187, acc: 0.77\n",
      "=================== 882 / 1000 epoch ===================\n",
      "Train  loss: 0.4282, acc: 0.83\n",
      "Valid  loss: 0.5187, acc: 0.77\n",
      "=================== 883 / 1000 epoch ===================\n",
      "Train  loss: 0.4281, acc: 0.83\n",
      "Valid  loss: 0.5186, acc: 0.77\n",
      "=================== 884 / 1000 epoch ===================\n",
      "Train  loss: 0.4280, acc: 0.83\n",
      "Valid  loss: 0.5185, acc: 0.77\n",
      "=================== 885 / 1000 epoch ===================\n",
      "Train  loss: 0.4280, acc: 0.83\n",
      "Valid  loss: 0.5185, acc: 0.77\n",
      "=================== 886 / 1000 epoch ===================\n",
      "Train  loss: 0.4279, acc: 0.83\n",
      "Valid  loss: 0.5184, acc: 0.77\n",
      "=================== 887 / 1000 epoch ===================\n",
      "Train  loss: 0.4278, acc: 0.83\n",
      "Valid  loss: 0.5183, acc: 0.77\n",
      "=================== 888 / 1000 epoch ===================\n",
      "Train  loss: 0.4277, acc: 0.83\n",
      "Valid  loss: 0.5182, acc: 0.77\n",
      "=================== 889 / 1000 epoch ===================\n",
      "Train  loss: 0.4277, acc: 0.83\n",
      "Valid  loss: 0.5182, acc: 0.77\n",
      "=================== 890 / 1000 epoch ===================\n",
      "Train  loss: 0.4276, acc: 0.83\n",
      "Valid  loss: 0.5181, acc: 0.77\n",
      "=================== 891 / 1000 epoch ===================\n",
      "Train  loss: 0.4275, acc: 0.83\n",
      "Valid  loss: 0.5180, acc: 0.77\n",
      "=================== 892 / 1000 epoch ===================\n",
      "Train  loss: 0.4275, acc: 0.83\n",
      "Valid  loss: 0.5180, acc: 0.77\n",
      "=================== 893 / 1000 epoch ===================\n",
      "Train  loss: 0.4274, acc: 0.83\n",
      "Valid  loss: 0.5179, acc: 0.77\n",
      "=================== 894 / 1000 epoch ===================\n",
      "Train  loss: 0.4273, acc: 0.83\n",
      "Valid  loss: 0.5178, acc: 0.77\n",
      "=================== 895 / 1000 epoch ===================\n",
      "Train  loss: 0.4272, acc: 0.83\n",
      "Valid  loss: 0.5178, acc: 0.77\n",
      "=================== 896 / 1000 epoch ===================\n",
      "Train  loss: 0.4272, acc: 0.83\n",
      "Valid  loss: 0.5177, acc: 0.77\n",
      "=================== 897 / 1000 epoch ===================\n",
      "Train  loss: 0.4271, acc: 0.83\n",
      "Valid  loss: 0.5176, acc: 0.77\n",
      "=================== 898 / 1000 epoch ===================\n",
      "Train  loss: 0.4270, acc: 0.83\n",
      "Valid  loss: 0.5176, acc: 0.77\n",
      "=================== 899 / 1000 epoch ===================\n",
      "Train  loss: 0.4269, acc: 0.83\n",
      "Valid  loss: 0.5175, acc: 0.77\n",
      "=================== 900 / 1000 epoch ===================\n",
      "Train  loss: 0.4269, acc: 0.83\n",
      "Valid  loss: 0.5174, acc: 0.77\n",
      "=================== 901 / 1000 epoch ===================\n",
      "Train  loss: 0.4268, acc: 0.83\n",
      "Valid  loss: 0.5174, acc: 0.77\n",
      "=================== 902 / 1000 epoch ===================\n",
      "Train  loss: 0.4267, acc: 0.83\n",
      "Valid  loss: 0.5173, acc: 0.77\n",
      "=================== 903 / 1000 epoch ===================\n",
      "Train  loss: 0.4267, acc: 0.83\n",
      "Valid  loss: 0.5172, acc: 0.77\n",
      "=================== 904 / 1000 epoch ===================\n",
      "Train  loss: 0.4266, acc: 0.83\n",
      "Valid  loss: 0.5171, acc: 0.77\n",
      "=================== 905 / 1000 epoch ===================\n",
      "Train  loss: 0.4265, acc: 0.83\n",
      "Valid  loss: 0.5171, acc: 0.77\n",
      "=================== 906 / 1000 epoch ===================\n",
      "Train  loss: 0.4264, acc: 0.83\n",
      "Valid  loss: 0.5170, acc: 0.77\n",
      "=================== 907 / 1000 epoch ===================\n",
      "Train  loss: 0.4264, acc: 0.83\n",
      "Valid  loss: 0.5169, acc: 0.77\n",
      "=================== 908 / 1000 epoch ===================\n",
      "Train  loss: 0.4263, acc: 0.83\n",
      "Valid  loss: 0.5169, acc: 0.77\n",
      "=================== 909 / 1000 epoch ===================\n",
      "Train  loss: 0.4262, acc: 0.83\n",
      "Valid  loss: 0.5168, acc: 0.77\n",
      "=================== 910 / 1000 epoch ===================\n",
      "Train  loss: 0.4261, acc: 0.83\n",
      "Valid  loss: 0.5167, acc: 0.77\n",
      "=================== 911 / 1000 epoch ===================\n",
      "Train  loss: 0.4261, acc: 0.83\n",
      "Valid  loss: 0.5167, acc: 0.77\n",
      "=================== 912 / 1000 epoch ===================\n",
      "Train  loss: 0.4260, acc: 0.83\n",
      "Valid  loss: 0.5166, acc: 0.77\n",
      "=================== 913 / 1000 epoch ===================\n",
      "Train  loss: 0.4259, acc: 0.83\n",
      "Valid  loss: 0.5165, acc: 0.77\n",
      "=================== 914 / 1000 epoch ===================\n",
      "Train  loss: 0.4259, acc: 0.83\n",
      "Valid  loss: 0.5165, acc: 0.77\n",
      "=================== 915 / 1000 epoch ===================\n",
      "Train  loss: 0.4258, acc: 0.83\n",
      "Valid  loss: 0.5164, acc: 0.77\n",
      "=================== 916 / 1000 epoch ===================\n",
      "Train  loss: 0.4257, acc: 0.83\n",
      "Valid  loss: 0.5163, acc: 0.77\n",
      "=================== 917 / 1000 epoch ===================\n",
      "Train  loss: 0.4257, acc: 0.83\n",
      "Valid  loss: 0.5163, acc: 0.77\n",
      "=================== 918 / 1000 epoch ===================\n",
      "Train  loss: 0.4256, acc: 0.83\n",
      "Valid  loss: 0.5162, acc: 0.77\n",
      "=================== 919 / 1000 epoch ===================\n",
      "Train  loss: 0.4255, acc: 0.83\n",
      "Valid  loss: 0.5161, acc: 0.77\n",
      "=================== 920 / 1000 epoch ===================\n",
      "Train  loss: 0.4254, acc: 0.83\n",
      "Valid  loss: 0.5161, acc: 0.77\n",
      "=================== 921 / 1000 epoch ===================\n",
      "Train  loss: 0.4254, acc: 0.83\n",
      "Valid  loss: 0.5160, acc: 0.77\n",
      "=================== 922 / 1000 epoch ===================\n",
      "Train  loss: 0.4253, acc: 0.83\n",
      "Valid  loss: 0.5159, acc: 0.77\n",
      "=================== 923 / 1000 epoch ===================\n",
      "Train  loss: 0.4252, acc: 0.83\n",
      "Valid  loss: 0.5159, acc: 0.77\n",
      "=================== 924 / 1000 epoch ===================\n",
      "Train  loss: 0.4252, acc: 0.83\n",
      "Valid  loss: 0.5158, acc: 0.77\n",
      "=================== 925 / 1000 epoch ===================\n",
      "Train  loss: 0.4251, acc: 0.83\n",
      "Valid  loss: 0.5157, acc: 0.77\n",
      "=================== 926 / 1000 epoch ===================\n",
      "Train  loss: 0.4250, acc: 0.83\n",
      "Valid  loss: 0.5157, acc: 0.77\n",
      "=================== 927 / 1000 epoch ===================\n",
      "Train  loss: 0.4250, acc: 0.83\n",
      "Valid  loss: 0.5156, acc: 0.77\n",
      "=================== 928 / 1000 epoch ===================\n",
      "Train  loss: 0.4249, acc: 0.83\n",
      "Valid  loss: 0.5155, acc: 0.77\n",
      "=================== 929 / 1000 epoch ===================\n",
      "Train  loss: 0.4248, acc: 0.83\n",
      "Valid  loss: 0.5155, acc: 0.77\n",
      "=================== 930 / 1000 epoch ===================\n",
      "Train  loss: 0.4247, acc: 0.83\n",
      "Valid  loss: 0.5154, acc: 0.77\n",
      "=================== 931 / 1000 epoch ===================\n",
      "Train  loss: 0.4247, acc: 0.83\n",
      "Valid  loss: 0.5153, acc: 0.77\n",
      "=================== 932 / 1000 epoch ===================\n",
      "Train  loss: 0.4246, acc: 0.83\n",
      "Valid  loss: 0.5153, acc: 0.77\n",
      "=================== 933 / 1000 epoch ===================\n",
      "Train  loss: 0.4245, acc: 0.83\n",
      "Valid  loss: 0.5152, acc: 0.77\n",
      "=================== 934 / 1000 epoch ===================\n",
      "Train  loss: 0.4245, acc: 0.83\n",
      "Valid  loss: 0.5151, acc: 0.77\n",
      "=================== 935 / 1000 epoch ===================\n",
      "Train  loss: 0.4244, acc: 0.83\n",
      "Valid  loss: 0.5151, acc: 0.77\n",
      "=================== 936 / 1000 epoch ===================\n",
      "Train  loss: 0.4243, acc: 0.83\n",
      "Valid  loss: 0.5150, acc: 0.77\n",
      "=================== 937 / 1000 epoch ===================\n",
      "Train  loss: 0.4243, acc: 0.83\n",
      "Valid  loss: 0.5150, acc: 0.77\n",
      "=================== 938 / 1000 epoch ===================\n",
      "Train  loss: 0.4242, acc: 0.83\n",
      "Valid  loss: 0.5149, acc: 0.77\n",
      "=================== 939 / 1000 epoch ===================\n",
      "Train  loss: 0.4241, acc: 0.83\n",
      "Valid  loss: 0.5148, acc: 0.77\n",
      "=================== 940 / 1000 epoch ===================\n",
      "Train  loss: 0.4241, acc: 0.83\n",
      "Valid  loss: 0.5148, acc: 0.77\n",
      "=================== 941 / 1000 epoch ===================\n",
      "Train  loss: 0.4240, acc: 0.83\n",
      "Valid  loss: 0.5147, acc: 0.77\n",
      "=================== 942 / 1000 epoch ===================\n",
      "Train  loss: 0.4239, acc: 0.83\n",
      "Valid  loss: 0.5146, acc: 0.77\n",
      "=================== 943 / 1000 epoch ===================\n",
      "Train  loss: 0.4239, acc: 0.83\n",
      "Valid  loss: 0.5146, acc: 0.77\n",
      "=================== 944 / 1000 epoch ===================\n",
      "Train  loss: 0.4238, acc: 0.83\n",
      "Valid  loss: 0.5145, acc: 0.77\n",
      "=================== 945 / 1000 epoch ===================\n",
      "Train  loss: 0.4237, acc: 0.83\n",
      "Valid  loss: 0.5144, acc: 0.77\n",
      "=================== 946 / 1000 epoch ===================\n",
      "Train  loss: 0.4237, acc: 0.83\n",
      "Valid  loss: 0.5144, acc: 0.77\n",
      "=================== 947 / 1000 epoch ===================\n",
      "Train  loss: 0.4236, acc: 0.83\n",
      "Valid  loss: 0.5143, acc: 0.77\n",
      "=================== 948 / 1000 epoch ===================\n",
      "Train  loss: 0.4235, acc: 0.83\n",
      "Valid  loss: 0.5142, acc: 0.77\n",
      "=================== 949 / 1000 epoch ===================\n",
      "Train  loss: 0.4235, acc: 0.83\n",
      "Valid  loss: 0.5142, acc: 0.77\n",
      "=================== 950 / 1000 epoch ===================\n",
      "Train  loss: 0.4234, acc: 0.83\n",
      "Valid  loss: 0.5141, acc: 0.77\n",
      "=================== 951 / 1000 epoch ===================\n",
      "Train  loss: 0.4233, acc: 0.83\n",
      "Valid  loss: 0.5141, acc: 0.77\n",
      "=================== 952 / 1000 epoch ===================\n",
      "Train  loss: 0.4233, acc: 0.83\n",
      "Valid  loss: 0.5140, acc: 0.77\n",
      "=================== 953 / 1000 epoch ===================\n",
      "Train  loss: 0.4232, acc: 0.83\n",
      "Valid  loss: 0.5139, acc: 0.77\n",
      "=================== 954 / 1000 epoch ===================\n",
      "Train  loss: 0.4231, acc: 0.83\n",
      "Valid  loss: 0.5139, acc: 0.77\n",
      "=================== 955 / 1000 epoch ===================\n",
      "Train  loss: 0.4231, acc: 0.83\n",
      "Valid  loss: 0.5138, acc: 0.77\n",
      "=================== 956 / 1000 epoch ===================\n",
      "Train  loss: 0.4230, acc: 0.83\n",
      "Valid  loss: 0.5137, acc: 0.77\n",
      "=================== 957 / 1000 epoch ===================\n",
      "Train  loss: 0.4229, acc: 0.83\n",
      "Valid  loss: 0.5137, acc: 0.77\n",
      "=================== 958 / 1000 epoch ===================\n",
      "Train  loss: 0.4229, acc: 0.83\n",
      "Valid  loss: 0.5136, acc: 0.77\n",
      "=================== 959 / 1000 epoch ===================\n",
      "Train  loss: 0.4228, acc: 0.83\n",
      "Valid  loss: 0.5135, acc: 0.77\n",
      "=================== 960 / 1000 epoch ===================\n",
      "Train  loss: 0.4227, acc: 0.83\n",
      "Valid  loss: 0.5135, acc: 0.78\n",
      "=================== 961 / 1000 epoch ===================\n",
      "Train  loss: 0.4227, acc: 0.83\n",
      "Valid  loss: 0.5134, acc: 0.78\n",
      "=================== 962 / 1000 epoch ===================\n",
      "Train  loss: 0.4226, acc: 0.83\n",
      "Valid  loss: 0.5134, acc: 0.78\n",
      "=================== 963 / 1000 epoch ===================\n",
      "Train  loss: 0.4225, acc: 0.83\n",
      "Valid  loss: 0.5133, acc: 0.78\n",
      "=================== 964 / 1000 epoch ===================\n",
      "Train  loss: 0.4225, acc: 0.83\n",
      "Valid  loss: 0.5132, acc: 0.78\n",
      "=================== 965 / 1000 epoch ===================\n",
      "Train  loss: 0.4224, acc: 0.83\n",
      "Valid  loss: 0.5132, acc: 0.78\n",
      "=================== 966 / 1000 epoch ===================\n",
      "Train  loss: 0.4223, acc: 0.83\n",
      "Valid  loss: 0.5131, acc: 0.78\n",
      "=================== 967 / 1000 epoch ===================\n",
      "Train  loss: 0.4223, acc: 0.83\n",
      "Valid  loss: 0.5130, acc: 0.78\n",
      "=================== 968 / 1000 epoch ===================\n",
      "Train  loss: 0.4222, acc: 0.83\n",
      "Valid  loss: 0.5130, acc: 0.78\n",
      "=================== 969 / 1000 epoch ===================\n",
      "Train  loss: 0.4221, acc: 0.83\n",
      "Valid  loss: 0.5129, acc: 0.78\n",
      "=================== 970 / 1000 epoch ===================\n",
      "Train  loss: 0.4221, acc: 0.83\n",
      "Valid  loss: 0.5129, acc: 0.78\n",
      "=================== 971 / 1000 epoch ===================\n",
      "Train  loss: 0.4220, acc: 0.83\n",
      "Valid  loss: 0.5128, acc: 0.78\n",
      "=================== 972 / 1000 epoch ===================\n",
      "Train  loss: 0.4220, acc: 0.83\n",
      "Valid  loss: 0.5127, acc: 0.78\n",
      "=================== 973 / 1000 epoch ===================\n",
      "Train  loss: 0.4219, acc: 0.83\n",
      "Valid  loss: 0.5127, acc: 0.78\n",
      "=================== 974 / 1000 epoch ===================\n",
      "Train  loss: 0.4218, acc: 0.83\n",
      "Valid  loss: 0.5126, acc: 0.78\n",
      "=================== 975 / 1000 epoch ===================\n",
      "Train  loss: 0.4218, acc: 0.83\n",
      "Valid  loss: 0.5125, acc: 0.77\n",
      "=================== 976 / 1000 epoch ===================\n",
      "Train  loss: 0.4217, acc: 0.83\n",
      "Valid  loss: 0.5125, acc: 0.77\n",
      "=================== 977 / 1000 epoch ===================\n",
      "Train  loss: 0.4216, acc: 0.83\n",
      "Valid  loss: 0.5124, acc: 0.77\n",
      "=================== 978 / 1000 epoch ===================\n",
      "Train  loss: 0.4216, acc: 0.83\n",
      "Valid  loss: 0.5124, acc: 0.77\n",
      "=================== 979 / 1000 epoch ===================\n",
      "Train  loss: 0.4215, acc: 0.83\n",
      "Valid  loss: 0.5123, acc: 0.77\n",
      "=================== 980 / 1000 epoch ===================\n",
      "Train  loss: 0.4214, acc: 0.83\n",
      "Valid  loss: 0.5122, acc: 0.77\n",
      "=================== 981 / 1000 epoch ===================\n",
      "Train  loss: 0.4214, acc: 0.83\n",
      "Valid  loss: 0.5122, acc: 0.77\n",
      "=================== 982 / 1000 epoch ===================\n",
      "Train  loss: 0.4213, acc: 0.83\n",
      "Valid  loss: 0.5121, acc: 0.77\n",
      "=================== 983 / 1000 epoch ===================\n",
      "Train  loss: 0.4213, acc: 0.83\n",
      "Valid  loss: 0.5121, acc: 0.77\n",
      "=================== 984 / 1000 epoch ===================\n",
      "Train  loss: 0.4212, acc: 0.83\n",
      "Valid  loss: 0.5120, acc: 0.77\n",
      "=================== 985 / 1000 epoch ===================\n",
      "Train  loss: 0.4211, acc: 0.83\n",
      "Valid  loss: 0.5119, acc: 0.77\n",
      "=================== 986 / 1000 epoch ===================\n",
      "Train  loss: 0.4211, acc: 0.83\n",
      "Valid  loss: 0.5119, acc: 0.77\n",
      "=================== 987 / 1000 epoch ===================\n",
      "Train  loss: 0.4210, acc: 0.83\n",
      "Valid  loss: 0.5118, acc: 0.77\n",
      "=================== 988 / 1000 epoch ===================\n",
      "Train  loss: 0.4209, acc: 0.83\n",
      "Valid  loss: 0.5118, acc: 0.77\n",
      "=================== 989 / 1000 epoch ===================\n",
      "Train  loss: 0.4209, acc: 0.83\n",
      "Valid  loss: 0.5117, acc: 0.77\n",
      "=================== 990 / 1000 epoch ===================\n",
      "Train  loss: 0.4208, acc: 0.83\n",
      "Valid  loss: 0.5116, acc: 0.77\n",
      "=================== 991 / 1000 epoch ===================\n",
      "Train  loss: 0.4207, acc: 0.83\n",
      "Valid  loss: 0.5116, acc: 0.78\n",
      "=================== 992 / 1000 epoch ===================\n",
      "Train  loss: 0.4207, acc: 0.83\n",
      "Valid  loss: 0.5115, acc: 0.78\n",
      "=================== 993 / 1000 epoch ===================\n",
      "Train  loss: 0.4206, acc: 0.83\n",
      "Valid  loss: 0.5115, acc: 0.78\n",
      "=================== 994 / 1000 epoch ===================\n",
      "Train  loss: 0.4206, acc: 0.83\n",
      "Valid  loss: 0.5114, acc: 0.78\n",
      "=================== 995 / 1000 epoch ===================\n",
      "Train  loss: 0.4205, acc: 0.83\n",
      "Valid  loss: 0.5113, acc: 0.78\n",
      "=================== 996 / 1000 epoch ===================\n",
      "Train  loss: 0.4204, acc: 0.83\n",
      "Valid  loss: 0.5113, acc: 0.78\n",
      "=================== 997 / 1000 epoch ===================\n",
      "Train  loss: 0.4204, acc: 0.83\n",
      "Valid  loss: 0.5112, acc: 0.78\n",
      "=================== 998 / 1000 epoch ===================\n",
      "Train  loss: 0.4203, acc: 0.83\n",
      "Valid  loss: 0.5112, acc: 0.78\n",
      "=================== 999 / 1000 epoch ===================\n",
      "Train  loss: 0.4203, acc: 0.83\n",
      "Valid  loss: 0.5111, acc: 0.78\n",
      "=================== 1000 / 1000 epoch ===================\n",
      "Train  loss: 0.4202, acc: 0.83\n",
      "Valid  loss: 0.5110, acc: 0.78\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "73. モデルの学習\n",
    "問題72で設計したモデルの重みベクトルを訓練セット上で学習せよ。\n",
    "ただし、学習中は単語埋め込み行列の値を固定せよ（単語埋め込み行列のファインチューニングは行わない）。\n",
    "また、学習時に損失値を表示するなど、学習の進捗状況をモニタリングできるようにせよ。\n",
    "\"\"\"\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(model, train_data, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    train_X = [d['input_ids'] for d in train_data]\n",
    "    train_Y = torch.stack([d['label'] for d in train_data])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_X)\n",
    "    loss = loss_fn(pred, train_Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pred_label = (pred >= 0.5).float()\n",
    "    corrects = torch.sum(pred_label == train_Y)\n",
    "    train_acc = corrects / len(train_X)\n",
    "\n",
    "    return loss.item(), train_acc.item()\n",
    "\n",
    "def evaluate(model, dev_data, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        dev_X = [d['input_ids'] for d in dev_data]\n",
    "        dev_Y = torch.stack([d['label'] for d in dev_data])\n",
    "        pred = model(dev_X)\n",
    "        loss = loss_fn(pred, dev_Y)\n",
    "\n",
    "        pred_label = (pred >= 0.5).float()\n",
    "        corrects = torch.sum(pred_label == dev_Y)\n",
    "        valid_acc = corrects / len(dev_Y)\n",
    "\n",
    "    return loss.item(), valid_acc.item()\n",
    "\n",
    "model = LogisticRegression(embedding_matrix, 300, 1)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "max_epochs = 1000\n",
    "best_valid_loss = float('inf')\n",
    "early_stopping_cnt = 0\n",
    "patience = 5\n",
    "save_path = 'model/LogisticRegression73.pth'\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"=================== {epoch+1} / {max_epochs} epoch ===================\")\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_ids_list, optimizer, loss_fn)\n",
    "    print(f\"Train  loss: {train_loss:.4f}, acc: {train_acc:.2f}\")\n",
    "    \n",
    "    valid_loss, valid_acc = evaluate(model, dev_ids_list, loss_fn)\n",
    "    print(f\"Valid  loss: {valid_loss:.4f}, acc: {valid_acc:.2f}\")\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        early_stopping_cnt = 0\n",
    "\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        early_stopping_cnt += 1\n",
    "        print(f\"EarlyStopping: {early_stopping_cnt} / {patience}\")\n",
    "\n",
    "        if early_stopping_cnt >= patience:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid  loss: 0.5110, acc: 0.78\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "74. モデルの評価\n",
    "問題73で学習したモデルの開発セットにおける正解率を求めよ。\n",
    "\"\"\"\n",
    "\n",
    "def evaluate(model, dev_data, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        dev_X = [d['input_ids'] for d in dev_data]\n",
    "        dev_Y = torch.stack([d['label'] for d in dev_data])\n",
    "        pred = model(dev_X)\n",
    "        loss = loss_fn(pred, dev_Y)\n",
    "\n",
    "        pred_label = (pred >= 0.5).float()\n",
    "        corrects = torch.sum(pred_label == dev_Y)\n",
    "        valid_acc = corrects / len(dev_Y)\n",
    "\n",
    "    return loss.item(), valid_acc.item()\n",
    "\n",
    "model = LogisticRegression(embedding_matrix, 300, 1, freeze=False)\n",
    "model.load_state_dict(torch.load('model/LogisticRegression73.pth'))\n",
    "model.eval()\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "valid_loss, valid_acc = evaluate(model, dev_ids_list, loss_fn)\n",
    "print(f\"Valid  loss: {valid_loss:.4f}, acc: {valid_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_ids': tensor([9071, 4483,  407, 9085, 7860, 1760, 4795]),\n",
      "  'label': tensor([0.]),\n",
      "  'text': 'hide new secretions from the parental units '},\n",
      " {'input_ids': tensor([ 3443,  7755, 11276,  6028,  8205,  6519]),\n",
      "  'label': tensor([0.]),\n",
      "  'text': 'contains no wit , only labored gags '},\n",
      " {'input_ids': tensor([ 9122,  3991,  8988,  4634,  4170,  2448,  4722,  4578,  6190, 12763,\n",
      "         5458]),\n",
      "  'label': tensor([1.]),\n",
      "  'text': 'that loves its characters and communicates something rather '\n",
      "          'beautiful about human nature '},\n",
      " {'input_ids': tensor([ 8126, 10517,  3108,   517,  7860,  3482, 10153]),\n",
      "  'label': tensor([0.]),\n",
      "  'text': 'remains utterly satisfied to remain the same throughout '}]\n",
      "\n",
      "{'input_ids': tensor([[ 9122,  3991,  8988,  4634,  4170,  2448,  4722,  4578,  6190, 12763,\n",
      "          5458],\n",
      "        [ 9071,  4483,   407,  9085,  7860,  1760,  4795,     0,     0,     0,\n",
      "             0],\n",
      "        [ 8126, 10517,  3108,   517,  7860,  3482, 10153,     0,     0,     0,\n",
      "             0],\n",
      "        [ 3443,  7755, 11276,  6028,  8205,  6519,     0,     0,     0,     0,\n",
      "             0]]),\n",
      " 'label': tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "75. パディング\n",
    "複数の事例が与えられたとき、これらをまとめて一つのテンソル・オブジェクトで表現する関数collateを実装せよ。\n",
    "与えられた複数の事例のトークン列の長さが異なるときは、トークン列の長さが最も長いものに揃え、0番のトークンIDでパディングをせよ。\n",
    "さらに、トークン列の長さが長いものから順に、事例を並び替えよ。\n",
    "\n",
    "例えば、訓練データセットの冒頭の4事例が次のように表されているとき、\n",
    "[{'text': 'hide new secretions from the parental units',\n",
    "  'label': tensor([0.]),\n",
    "  'input_ids': tensor([  5785,     66, 113845,     18,     12,  15095,   1594])},\n",
    " {'text': 'contains no wit , only labored gags',\n",
    "  'label': tensor([0.]),\n",
    "  'input_ids': tensor([ 3475,    87, 15888,    90, 27695, 42637])},\n",
    " {'text': 'that loves its characters and communicates something rather beautiful about human nature',\n",
    "  'label': tensor([1.]),\n",
    "  'input_ids': tensor([    4,  5053,    45,  3305, 31647,   348,   904,  2815,    47,  1276,  1964])},\n",
    " {'text': 'remains utterly satisfied to remain the same throughout',\n",
    "  'label': tensor([0.]),\n",
    "  'input_ids': tensor([  987, 14528,  4941,   873,    12,   208,   898])}]\n",
    "collate関数を通した結果は以下のようになることが想定される。\n",
    "{'input_ids': tensor([\n",
    "    [     4,   5053,     45,   3305,  31647,    348,    904,   2815,     47,   1276,   1964],\n",
    "    [  5785,     66, 113845,     18,     12,  15095,   1594,      0,      0,      0,      0],\n",
    "    [   987,  14528,   4941,    873,     12,    208,    898,      0,      0,      0,      0],\n",
    "    [  3475,     87,  15888,     90,  27695,  42637,      0,      0,      0,      0,      0]]),\n",
    " 'label': tensor([\n",
    "    [1.],\n",
    "    [0.],\n",
    "    [0.],\n",
    "    [0.]])}\n",
    "\"\"\"\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def collate(dec_list):\n",
    "  dec_list = sorted(dec_list, key=lambda x: len(x['input_ids']), reverse=True)\n",
    "  input_ids_list = [dec['input_ids'] for dec in dec_list]\n",
    "  label_list = torch.stack([dec['label'] for dec in dec_list])\n",
    "  padded_input_ids = pad_sequence(input_ids_list, batch_first=True)\n",
    "\n",
    "  return {\"input_ids\":padded_input_ids,\"label\":label_list}\n",
    "    \n",
    "pprint(train_ids_list[:4])\n",
    "print()\n",
    "pprint(collate(train_ids_list[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 1 / 10 epoch ===================\n",
      "Train  loss: 0.6201, acc: 0.68\n",
      "Valid  loss: 0.5729, acc: 0.75\n",
      "=================== 2 / 10 epoch ===================\n",
      "Train  loss: 0.5372, acc: 0.78\n",
      "Valid  loss: 0.5235, acc: 0.77\n",
      "=================== 3 / 10 epoch ===================\n",
      "Train  loss: 0.4937, acc: 0.81\n",
      "Valid  loss: 0.4990, acc: 0.78\n",
      "=================== 4 / 10 epoch ===================\n",
      "Train  loss: 0.4683, acc: 0.82\n",
      "Valid  loss: 0.4898, acc: 0.78\n",
      "=================== 5 / 10 epoch ===================\n",
      "Train  loss: 0.4520, acc: 0.83\n",
      "Valid  loss: 0.4825, acc: 0.78\n",
      "=================== 6 / 10 epoch ===================\n",
      "Train  loss: 0.4393, acc: 0.83\n",
      "Valid  loss: 0.4744, acc: 0.79\n",
      "=================== 7 / 10 epoch ===================\n",
      "Train  loss: 0.4320, acc: 0.83\n",
      "Valid  loss: 0.4768, acc: 0.78\n",
      "EarlyStopping: 1 / 5\n",
      "=================== 8 / 10 epoch ===================\n",
      "Train  loss: 0.4250, acc: 0.83\n",
      "Valid  loss: 0.4756, acc: 0.78\n",
      "EarlyStopping: 2 / 5\n",
      "=================== 9 / 10 epoch ===================\n",
      "Train  loss: 0.4197, acc: 0.84\n",
      "Valid  loss: 0.4733, acc: 0.78\n",
      "=================== 10 / 10 epoch ===================\n",
      "Train  loss: 0.4156, acc: 0.84\n",
      "Valid  loss: 0.4736, acc: 0.79\n",
      "EarlyStopping: 1 / 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "76. ミニバッチ学習\n",
    "問題75のパディングの処理を活用して、ミニバッチでモデルを学習せよ。また、学習したモデルの開発セットにおける正解率を求めよ。\n",
    "\"\"\"\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(model, train_loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        train_X = batch[\"input_ids\"]\n",
    "        train_Y = batch[\"label\"]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(train_X)\n",
    "        loss = loss_fn(preds, train_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * train_X.size(0)\n",
    "        pred_labels = (preds >= 0.5).float()\n",
    "        total_correct += (pred_labels == train_Y).sum().item()\n",
    "        total_samples += train_X.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def evaluate(model, valid_loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "         for batch in valid_loader:\n",
    "            dev_X = batch[\"input_ids\"]\n",
    "            dev_Y = batch[\"label\"]\n",
    "\n",
    "            preds = model(dev_X)\n",
    "            loss = loss_fn(preds, dev_Y)\n",
    "\n",
    "            total_loss += loss.item() * dev_X.size(0)\n",
    "            pred_labels = (preds >= 0.5).float()\n",
    "            total_correct += (pred_labels == dev_Y).sum().item()\n",
    "            total_samples += dev_X.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "train_loader = DataLoader(train_ids_list, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "valid_loader = DataLoader(dev_ids_list, batch_size=32, shuffle=False, collate_fn=collate)\n",
    "\n",
    "model = LogisticRegression(embedding_matrix, 300, 1)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "max_epochs = 10\n",
    "best_valid_loss = float('inf')\n",
    "early_stopping_cnt = 0\n",
    "patience = 5\n",
    "save_path = 'model/LogisticRegression76.pth'\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"=================== {epoch+1} / {max_epochs} epoch ===================\")\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, loss_fn)\n",
    "    print(f\"Train  loss: {train_loss:.4f}, acc: {train_acc:.2f}\")\n",
    "    \n",
    "    valid_loss, valid_acc = evaluate(model, valid_loader, loss_fn)\n",
    "    print(f\"Valid  loss: {valid_loss:.4f}, acc: {valid_acc:.2f}\")\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        early_stopping_cnt = 0\n",
    "\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        early_stopping_cnt += 1\n",
    "        print(f\"EarlyStopping: {early_stopping_cnt} / {patience}\")\n",
    "\n",
    "        if early_stopping_cnt >= patience:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 1 / 10 epoch ===================\n",
      "Train  loss: 0.6201, acc: 0.68\n",
      "Valid  loss: 0.5733, acc: 0.74\n",
      "=================== 2 / 10 epoch ===================\n",
      "Train  loss: 0.5370, acc: 0.78\n",
      "Valid  loss: 0.5233, acc: 0.77\n",
      "=================== 3 / 10 epoch ===================\n",
      "Train  loss: 0.4938, acc: 0.81\n",
      "Valid  loss: 0.5009, acc: 0.77\n",
      "=================== 4 / 10 epoch ===================\n",
      "Train  loss: 0.4679, acc: 0.82\n",
      "Valid  loss: 0.4871, acc: 0.78\n",
      "=================== 5 / 10 epoch ===================\n",
      "Train  loss: 0.4511, acc: 0.83\n",
      "Valid  loss: 0.4835, acc: 0.78\n",
      "=================== 6 / 10 epoch ===================\n",
      "Train  loss: 0.4401, acc: 0.83\n",
      "Valid  loss: 0.4790, acc: 0.78\n",
      "=================== 7 / 10 epoch ===================\n",
      "Train  loss: 0.4316, acc: 0.83\n",
      "Valid  loss: 0.4735, acc: 0.78\n",
      "=================== 8 / 10 epoch ===================\n",
      "Train  loss: 0.4248, acc: 0.83\n",
      "Valid  loss: 0.4702, acc: 0.79\n",
      "=================== 9 / 10 epoch ===================\n",
      "Train  loss: 0.4197, acc: 0.84\n",
      "Valid  loss: 0.4733, acc: 0.79\n",
      "EarlyStopping: 1 / 5\n",
      "=================== 10 / 10 epoch ===================\n",
      "Train  loss: 0.4162, acc: 0.84\n",
      "Valid  loss: 0.4741, acc: 0.79\n",
      "EarlyStopping: 2 / 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "77. GPU上での学習\n",
    "問題76のモデル学習をGPU上で実行せよ。また、学習したモデルの開発セットにおける正解率を求めよ。\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(model, train_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        train_X = batch[\"input_ids\"].to(device)\n",
    "        train_Y = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(train_X)\n",
    "        loss = loss_fn(preds, train_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * train_X.size(0)\n",
    "        pred_labels = (preds >= 0.5).float()\n",
    "        total_correct += (pred_labels == train_Y).sum().item()\n",
    "        total_samples += train_X.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def evaluate(model, valid_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "         for batch in valid_loader:\n",
    "            dev_X = batch[\"input_ids\"].to(device)\n",
    "            dev_Y = batch[\"label\"].to(device)\n",
    "\n",
    "            preds = model(dev_X)\n",
    "            loss = loss_fn(preds, dev_Y)\n",
    "\n",
    "            total_loss += loss.item() * dev_X.size(0)\n",
    "            pred_labels = (preds >= 0.5).float()\n",
    "            total_correct += (pred_labels == dev_Y).sum().item()\n",
    "            total_samples += dev_X.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "train_loader = DataLoader(train_ids_list, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "valid_loader = DataLoader(dev_ids_list, batch_size=32, shuffle=False, collate_fn=collate)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LogisticRegression(embedding_matrix, 300, 1).to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "max_epochs = 10\n",
    "best_valid_loss = float('inf')\n",
    "early_stopping_cnt = 0\n",
    "patience = 5\n",
    "save_path = 'model/LogisticRegression77.pth'\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"=================== {epoch+1} / {max_epochs} epoch ===================\")\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, loss_fn, device)\n",
    "    print(f\"Train  loss: {train_loss:.4f}, acc: {train_acc:.2f}\")\n",
    "    \n",
    "    valid_loss, valid_acc = evaluate(model, valid_loader, loss_fn, device)\n",
    "    print(f\"Valid  loss: {valid_loss:.4f}, acc: {valid_acc:.2f}\")\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        early_stopping_cnt = 0\n",
    "\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        early_stopping_cnt += 1\n",
    "        print(f\"EarlyStopping: {early_stopping_cnt} / {patience}\")\n",
    "\n",
    "        if early_stopping_cnt >= patience:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 1 / 10 epoch ===================\n",
      "Train  loss: 0.4183, acc: 0.81\n",
      "Valid  loss: 0.4494, acc: 0.81\n",
      "=================== 2 / 10 epoch ===================\n",
      "Train  loss: 0.2454, acc: 0.91\n",
      "Valid  loss: 0.5352, acc: 0.80\n",
      "EarlyStopping: 1 / 5\n",
      "=================== 3 / 10 epoch ===================\n",
      "Train  loss: 0.2073, acc: 0.92\n",
      "Valid  loss: 0.6154, acc: 0.81\n",
      "EarlyStopping: 2 / 5\n",
      "=================== 4 / 10 epoch ===================\n",
      "Train  loss: 0.1881, acc: 0.93\n",
      "Valid  loss: 0.7025, acc: 0.80\n",
      "EarlyStopping: 3 / 5\n",
      "=================== 5 / 10 epoch ===================\n",
      "Train  loss: 0.1769, acc: 0.93\n",
      "Valid  loss: 0.7482, acc: 0.81\n",
      "EarlyStopping: 4 / 5\n",
      "=================== 6 / 10 epoch ===================\n",
      "Train  loss: 0.1685, acc: 0.94\n",
      "Valid  loss: 0.8782, acc: 0.79\n",
      "EarlyStopping: 5 / 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "78. 単語埋め込みのファインチューニング\n",
    "問題77の学習において、単語埋め込みのパラメータも同時に更新するファインチューニングを導入せよ。また、学習したモデルの開発セットにおける正解率を求めよ。\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(model, train_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        train_X = batch[\"input_ids\"].to(device)\n",
    "        train_Y = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(train_X)\n",
    "        loss = loss_fn(preds, train_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * train_X.size(0)\n",
    "        pred_labels = (preds >= 0.5).float()\n",
    "        total_correct += (pred_labels == train_Y).sum().item()\n",
    "        total_samples += train_X.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def evaluate(model, valid_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "         for batch in valid_loader:\n",
    "            dev_X = batch[\"input_ids\"].to(device)\n",
    "            dev_Y = batch[\"label\"].to(device)\n",
    "\n",
    "            preds = model(dev_X)\n",
    "            loss = loss_fn(preds, dev_Y)\n",
    "\n",
    "            total_loss += loss.item() * dev_X.size(0)\n",
    "            pred_labels = (preds >= 0.5).float()\n",
    "            total_correct += (pred_labels == dev_Y).sum().item()\n",
    "            total_samples += dev_X.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "train_loader = DataLoader(train_ids_list, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "valid_loader = DataLoader(dev_ids_list, batch_size=32, shuffle=False, collate_fn=collate)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LogisticRegression(embedding_matrix, 300, 1, False).to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "max_epochs = 10\n",
    "best_valid_loss = float('inf')\n",
    "early_stopping_cnt = 0\n",
    "patience = 5\n",
    "save_path = 'model/LogisticRegression78.pth'\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"=================== {epoch+1} / {max_epochs} epoch ===================\")\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, loss_fn, device)\n",
    "    print(f\"Train  loss: {train_loss:.4f}, acc: {train_acc:.2f}\")\n",
    "    \n",
    "    valid_loss, valid_acc = evaluate(model, valid_loader, loss_fn, device)\n",
    "    print(f\"Valid  loss: {valid_loss:.4f}, acc: {valid_acc:.2f}\")\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        early_stopping_cnt = 0\n",
    "\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        early_stopping_cnt += 1\n",
    "        print(f\"EarlyStopping: {early_stopping_cnt} / {patience}\")\n",
    "\n",
    "        if early_stopping_cnt >= patience:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 1 / 10 epoch ===================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  loss: 0.4054, acc: 0.82\n",
      "Valid  loss: 0.4396, acc: 0.81\n",
      "=================== 2 / 10 epoch ===================\n",
      "Train  loss: 0.3405, acc: 0.85\n",
      "Valid  loss: 0.4313, acc: 0.80\n",
      "=================== 3 / 10 epoch ===================\n",
      "Train  loss: 0.3270, acc: 0.86\n",
      "Valid  loss: 0.4315, acc: 0.81\n",
      "EarlyStopping: 1 / 5\n",
      "=================== 4 / 10 epoch ===================\n",
      "Train  loss: 0.3175, acc: 0.86\n",
      "Valid  loss: 0.4281, acc: 0.81\n",
      "=================== 5 / 10 epoch ===================\n",
      "Train  loss: 0.3078, acc: 0.87\n",
      "Valid  loss: 0.4322, acc: 0.79\n",
      "EarlyStopping: 1 / 5\n",
      "=================== 6 / 10 epoch ===================\n",
      "Train  loss: 0.2987, acc: 0.87\n",
      "Valid  loss: 0.4268, acc: 0.81\n",
      "=================== 7 / 10 epoch ===================\n",
      "Train  loss: 0.2892, acc: 0.88\n",
      "Valid  loss: 0.4325, acc: 0.81\n",
      "EarlyStopping: 1 / 5\n",
      "=================== 8 / 10 epoch ===================\n",
      "Train  loss: 0.2803, acc: 0.88\n",
      "Valid  loss: 0.4433, acc: 0.81\n",
      "EarlyStopping: 2 / 5\n",
      "=================== 9 / 10 epoch ===================\n",
      "Train  loss: 0.2704, acc: 0.89\n",
      "Valid  loss: 0.4375, acc: 0.81\n",
      "EarlyStopping: 3 / 5\n",
      "=================== 10 / 10 epoch ===================\n",
      "Train  loss: 0.2614, acc: 0.89\n",
      "Valid  loss: 0.4335, acc: 0.81\n",
      "EarlyStopping: 4 / 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "79. アーキテクチャの変更\n",
    "ニューラルネットワークのアーキテクチャを自由に変更し、モデルを学習せよ。また、学習したモデルの開発セットにおける正解率を求めよ。\n",
    "例えば、テキストの特徴ベクトル（単語埋め込みの平均ベクトル）に対して多層のニューラルネットワークを通したり、\n",
    "畳み込みニューラルネットワーク（CNN; Convolutional Neural Network）や再帰型ニューラルネットワーク（RNN; Recurrent Neural Network）などの\n",
    "モデルの学習に挑戦するとよい。\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, embedding_matrix, vec_dim, hidden_dim, output_dim, freeze=True):\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_weights = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_weights, freeze=freeze)\n",
    "\n",
    "        self.hidden = nn.Linear(vec_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_ids_list):\n",
    "        batch_vectors = []\n",
    "        \n",
    "        for input_ids in input_ids_list:\n",
    "            emb = self.embedding(input_ids)\n",
    "            avg_vec = torch.mean(emb, dim=0)\n",
    "            hidden_output = self.relu(self.hidden(avg_vec))\n",
    "            output = torch.sigmoid(self.linear(hidden_output))\n",
    "            \n",
    "            batch_vectors.append(output)\n",
    "\n",
    "        batch_tensor = torch.stack(batch_vectors)\n",
    "        return batch_tensor\n",
    "\n",
    "def train(model, train_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        train_X = batch[\"input_ids\"].to(device)\n",
    "        train_Y = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(train_X)\n",
    "        loss = loss_fn(preds, train_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * train_X.size(0)\n",
    "        pred_labels = (preds >= 0.5).float()\n",
    "        total_correct += (pred_labels == train_Y).sum().item()\n",
    "        total_samples += train_X.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def evaluate(model, valid_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "         for batch in valid_loader:\n",
    "            dev_X = batch[\"input_ids\"].to(device)\n",
    "            dev_Y = batch[\"label\"].to(device)\n",
    "\n",
    "            preds = model(dev_X)\n",
    "            loss = loss_fn(preds, dev_Y)\n",
    "\n",
    "            total_loss += loss.item() * dev_X.size(0)\n",
    "            pred_labels = (preds >= 0.5).float()\n",
    "            total_correct += (pred_labels == dev_Y).sum().item()\n",
    "            total_samples += dev_X.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "train_loader = DataLoader(train_ids_list, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "valid_loader = DataLoader(dev_ids_list, batch_size=32, shuffle=False, collate_fn=collate)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LogisticRegression(embedding_matrix, 300, 128, 1).to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "max_epochs = 10\n",
    "best_valid_loss = float('inf')\n",
    "early_stopping_cnt = 0\n",
    "patience = 5\n",
    "save_path = 'model/LogisticRegression79.pth'\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"=================== {epoch+1} / {max_epochs} epoch ===================\")\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, loss_fn, device)\n",
    "    print(f\"Train  loss: {train_loss:.4f}, acc: {train_acc:.2f}\")\n",
    "    \n",
    "    valid_loss, valid_acc = evaluate(model, valid_loader, loss_fn, device)\n",
    "    print(f\"Valid  loss: {valid_loss:.4f}, acc: {valid_acc:.2f}\")\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        early_stopping_cnt = 0\n",
    "\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        early_stopping_cnt += 1\n",
    "        print(f\"EarlyStopping: {early_stopping_cnt} / {patience}\")\n",
    "\n",
    "        if early_stopping_cnt >= patience:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
